QuestionNum,Question,Choice_A,Choice_B,Choice_C,Choice_D,Choice_E,Answer,Explaination,ImageUrl,QuizCode,QuizTitle,QuizDescription
1,A solutions architect is designing a new service behind Amazon API Gateway. The request patterns for the service will be unpredictable and can change suddenly from 0 requests to over 500 per second. The total size of the data that needs to be persisted in a backend database is currently less than 1 GBwith unpredictable future growth Data can be queried using simple key-value requests.Which combination of AWS services would meet these requirements'? (Select TWO ),AWS Fargate,AWS Lambda,Amazon DynamoDB,Amazon EC2 Auto Scaling,MySQL-compatible Amazon Aurora,B C,,,SAA-C02,Exam Practice ( SAA-C02 ),AWS Certified Solutions Architect Associate
2,"A solutions architect needs to design a managed storage solution for a company's application that includes high-performance machine learning, Thisapplication runs on AWS Fargate and the connected storage needs to have concurrent access to files and deliver high performance.Which storage option should the solutions architect recommend?",Create an Amazon S3 bucket for the application and establish an 1AM role for Fargate to communicate with Amazon S3.,Create an Amazon FSx for Lustre file share and establish an 1AM role that allows Fargate to communicate with FSx for Lustre.,Create an Amazon Elastic File System (Amazon EFS) file share and establish an 1AM role that allows Fargate to communicate with Amazon EFS.,Create an Amazon Elastic Block Store (Amazon EBS) volume for the application and establish an 1AM role that allows Fargate to communicate with,,D,,,,,
3,A company has a multi-tier application that runs six front-end web servers in an Amazon EC2 Auto Scaling group in a single Availability Zone behind anApplication Load Balancer (ALB). A solutions architect needs to modify the infrastructure to be highly available without modifying the application.Which architecture should the solutions architect choose that provides high availability?,Create an Auto Scaling group that uses three instances across each of two Regions,Modify the Auto Scaling group to use three instances across each of two Availability Zones,Create an Auto Scaling template that can be used to quickly create more instances in another Region,Change the ALB in front of the Amazon EC2 instances in a round-robin configuration to balance traffic to the web tier,,B,,,,,
4,"A company runs an internal browser-based application The application runs on Amazon EC2 instances behind an Application Load Balancer. Theinstances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. The Auto Scaling group scales up to 20 instances during workhours, but scales down to 2 instances overnight Staff are complaining that the application is very slow when the day begins, although it runs well by mid-morning.How should the scaling be changed to address the staff complaints and keep costs to a minimum?",Implement a scheduled action that sets the desired capacity to 20 shortly before the office opens,"Implement a step scaling action triggered at a lower CPU threshold, and decrease the cooldown period",Implement a target tracking action triggered at a lower CPU threshold and decrease the cooldown period,Implement a scheduled action that sets the minimum and maximum capacity to 20 shortly before the office opens,,B,https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-purchase-options.html,,,,
5,"A solutions architect is designing a solution to access a catalog of images and provide users with the ability to submit requests to customize images.Image customization parameters will be in any request sent to an AWS API Gateway API. The customized image will be generated on demand, andusers will receive a link they can click to view or download their customized image. The solution must be highly available for viewing and customizingimagesWhat is the MOST cost-effective solution to meet these requirements?",Use Amazon EC2 instances to manipulate the original image into the requested customization.Store the original and manipulated images in Amazon S3.Configure an Elastic Load Balancer in front of the EC2 instances.,Use AWS Lambda to manipulate the original image to the requested customization.Store the original and manipulated images in Amazon S3.Configure an Amazon CloudFront distribution with the S3 bucket as the ongin.,Use AWS Lambda to manipulate the original image to the requested customization.Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB.Configure an Elastic Load Balancer in front of the Amazon EC2 instances.,Use Amazon EC2 instances to manipulate the original image into the requested customization.Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB.Configure an Amazon CloudFront distribution with the S3 bucket as the origin.,,B,,,,,
6,A bicycle sharing company is developing a multi-tier architecture to track the location of its bicycles during peak operating hours. The company wants touse these data points in its existing analytics platform A solutions architect must determine the most viable multi-tier option to support this architecture.The data points must be accessible from the REST API.Which action meets these requirements for storing and retrieving location data?,Use Amazon Athena with Amazon S3,Use Amazon API Gateway with AWS Lambda,Use Amazon QuickSight with Amazon Redshift,Use Amazon API Gateway with Amazon Kinesis Data Analytics,,D,https://aws.amazon.com/kinesis/data-analytics/,,,,
7,A solutions architect is deploying a distributed database on multiple Amazon EC2 instances. The database stores all data on multiple instances so it canwithstand the loss of an instance. The database requires block storage with latency and throughput to support several million transactions per secondper server.Which storage solution should the solutions architect use?,Amazon EBS,Amazon EC2 instance store,Amazon EFS,Amazon S3,,B,,,,,
8,A solutions architect needs to ensure that API calls to Amazon DynamoDB from Amazon EC2 instances in a VPC do not traverse the internet.What should the solutions architect do to accomplish this? (Select TWO),Create a route table entry for the endpoint,Create a gateway endpoint for DynamoDB,Create a new DynamoDB table that uses the endpoint,Create an ENI for the endpoint in each of the subnets of the VPC,Create a security group entry in the default security group to provide access,A B,,,,,
9,"A solutions architect is designing a web application that will run on Amazon EC2 instances behind an Application Load Balancer (ALB). The companystrictly requires that the application be resilient against malicious internet activity and attacks, and protect against new common vulnerabilities andexposures.What should the solutions architect recommend?",Leverage Amazon CloudFront with the ALB endpoint as the origin,Deploy an appropriate managed rule for AWS WAF and associate it with the ALB,Subscribe to AWS Shield Advanced and ensure common vulnerabilities and exposures are blocked,Configure network ACLs and security groups to allow only ports 80 and 443 to access the EC2 instances,,C,https://d1.awsstatic.com/whitepapers/Security/DDoS_White_Paper.pdf,,,,
10,A company has been storing analytics data in an Amazon RDS instance for the past few years. The company asked a solutions architect to find asolution that allows users to access this data using an API. The expectation is that the application will experience periods of inactivity but could receivebursts of traffic within seconds.Which solution should the solutions architect suggest?,Set up an Amazon API Gateway and use Amazon ECS.,Set up an Amazon API Gateway and use AWS Elastic Beanstalk.,Set up an Amazon API Gateway and use AWS Lambda functions,Set up an Amazon API Gateway and use Amazon EC2 with Auto Scaling,,C,,,,,
11,"A company's web application is using multiple Linux Amazon EC2 instances and storing data on Amazon EBS volumes. The company is looking for asolution to increase the resiliency of the application in case of a failure and to provide storage that complies with atomicity, consistency, isolation, anddurability (ACID).What should a solutions architect do to meet these requirements?",Launch the application on EC2 instances in each Availability Zone.Attach EBS volumes to each EC2 instance.,Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones.Mount an instance store on each EC2 instance.,Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones.Store data on Amazon EFS and mount a target on each instance.,Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones.Store data using Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA).,,C,,,,,
12,A company has an application that calls AWS Lambda functions. A recent code review found database credentials stored in the source code. Thedatabase credentials need to be removed from the Lambda source code. The credentials must then be securely stored and rotated on an ongoing basisto meet security policy requirements.What should a solutions architect recommend to meet these requirements?,Store the password in AWS CloudHSM.Associate the Lambda function with a role that can retrieve the password from CloudHSM given its key ID.,Store the password in AWS Secrets Manager.Associate the Lambda function with a role that can retrieve the password from Secrets Manager given its secret ID.,Move the database password to an environment variable associated with the Lambda function.Retrieve the password from the environment variable upon execution.,Store the password in AWS Key Management Service (AWS KMS).Associate the Lambda function with a role that can retrieve the password from AWS KMS given its key ID.,,B,,,,,
13,A solutions architect needs the static website within an Amazon S3 bucket.Which action will accomplish this?,Enable Amazon S3 versioning,Enable Amazon S3 Intelligent-Tiering.,Enable an Amazon S3 lifecycle policy,Enable Amazon S3 cross-Region replication.,,A,,,,,
14,"A company is managing health records on-premises. The company must keep these records indefinitely, disable any modifications to the records oncethey are stored, and granularly audit access at all levels. The chief technology officer (CTO) is concerned because there are already millions of recordsnot being used by any application, and the current infrastructure is running out of space. The CTO has requested a solutions architect design a solutionto move existing data and support future records.Which services can the solutions architect recommend to meet these requirements'?",Use AWS DataSync to move existing data to AWS.Use Amazon S3 to store existing and new data.Enable Amazon S3 object lock and enable AWS CloudTrail with data events.,Use AWS Storage Gateway to move existing data to AWS.Use Amazon S3 to store existing and new data.Enable Amazon S3 object lock and enable AWS CloudTrail with management events.,Use AWS DataSync to move existing data to AWS.Use Amazon S3 to store existing and new data.Enable Amazon S3 object lock and enable AWS CloudTrail with management events.,Use AWS Storage Gateway to move existing data to AWS.Use Amazon Elastic Block Store (Amazon EBS) to store existing and new data.Enable Amazon S3 object lock and enable Amazon S3 server access logging.,,D,,,,,
15,A company currently operates a web application backed by an Amazon RDS MySQL database. It has automated backups that are run daily and are notencrypted. A security audit requires future backups to be encrypted and the unencrypted backups to be destroyed. The company will make at least oneencrypted backup before destroying the old backups.What should be done to enable encryption for future backups?,Enable default encryption for the Amazon S3 bucket where backups are stored,Modify the backup section of the database configuration to toggle the Enable encryption check box.,Create a snapshot of the database.Copy it to an encrypted snapshot.Restore the database from the encrypted snapshot.,Enable an encrypted read replica on RDS for MySQL.Promote the encrypted read replica to primary.Remove the original database instance.,,C,,,,,
16,A client reports that they want see an audit log of any changes made to AWS resources in their account.What can the client do to achieve this?,Set up Amazon CloudWatch monitors on services they own,Enable AWS CloudTrail logs to be delivered to an Amazon S3 bucket,Use Amazon CloudWatch Events to parse logs,Use AWS OpsWorks to manage their resources,,B,,,,,
17,An application running in a private subnet accesses an Amazon DynamoDB table. There is a security requirement that the data never leave the AWSnetwork.How should this requirement be met?,Configure a network ACL on DynamoDB to limit traffic to the private subnet,Enable DynamoDB encryption at rest using an AWS KMS key,Add a NAT gateway and configure the route table on the private subnet,Create a VPC endpoint for DynamoDB and configure the endpoint policy,,D,,,,,
18,"A three-tier application is being created to host small news articles. The application is expected to serve millions of users. When breaking news occurs,the site must handle very large spikes in traffic without significantly impacting database performance.Which design meets these requirements while minimizing costs?",Use Auto Scaling groups to increase the number of Amazon EC2 instances delivering the web application,Use Auto Scaling groups to increase the size of the Amazon RDS instances delivering the database,Use Amazon DynamoDB strongly consistent reads to adjust for the increase in traffic,Use Amazon DynamoDB Accelerator (DAX) to cache read operations to the database,,D,"DAX has in memory cache. If breaking news happens, majority of the users searching will look for the exact same thing. That being said, requests willquery the Memory Cache first and will not need to fetch the data from the DB directly.",,,,
19,"During a review of business applications, a Solutions Architect identifies a critical application with a relational database that was built by a business userand is running on the user's desktop. To reduce the risk of a business interruption, the Solutions Architect wants to migrate the application to a highlyavailable, multi-tiered solution in AWS.What should the Solutions Architect do to accomplish this with the LEAST amount of disruption to the business?","Create an import package of the application code for upload to AWS Lambda, and include a function to create another Lambda function to migrate data into an Amazon RDS database","Create an image of the user's desktop, migrate it to Amazon EC2 using VM Import, and place the EC2 instance in an Auto Scaling group",Pre-stage new Amazon EC2 instances running the application code on AWS behind an Application Load Balancer and an Amazon RDS Multi-AZ DB instance,Use AWS DMS to migrate the backend database to an Amazon RDS Multi-AZ DB instance.Migrate the application code to AWS Elastic Beanstalk,,D,,,,,
20,"A company has thousands of files stored in an Amazon S3 bucket that has a well-defined access pattern. The files are accessed by an applicationmultiple times a day for the first 30 days. Files are rarely accessed within the next 90 days. After that, the files are never accessed again. During the first120 days, accessing these files should never take more than a few seconds.Which lifecycle policy should be used for the S3 objects to minimize costs based on the access pattern?",Use Amazon S3 Standard-Infrequent Access (S3 Standard-IA) storage for the first 30 days. Then move the files to the GLACIER storage class for the next 90 days. Allow the data to expire after that.,Use Amazon S3 Standard storage for the first 30 days. Then move the files to Amazon S3 Standard- Infrequent Access (S3 Standard-IA) for the next 90 days. Allow the data to expire after that.,Use Amazon S3 Standard storage for first 30 days. Then move the files to the GLACIER storage class for the next 90 days. Allow the data to expire after that.,"Use Amazon S3 Standard-Infrequent Access (S3 Standard-IA) for the first 30 days. After that, move the data to the GLACIER storage class, where is will be deleted automatically.",,B,It is mentioned that they need to access data in few seconds during the 120 days.,,,,
21,A company creates business-critical 3D images every night. The images are batch-processed every Friday and require an uninterrupted 48 hours tocomplete.What is the MOST cost-effective Amazon EC2 pricing model for this scenario?,On-Demand Instances,Scheduled Reserved Instances,Reserved Instances,Spot Instances,,B,,,,,
22,An application generates audit logs of operational activities. Compliance requirements mandate that the application retain the logs for 5 years. How can these requirements be met?,Save the logs in an Amazon S3 bucket and enable Multi-Factor Authentication Delete (MFA Delete) on the bucket.,Save the logs in an Amazon EFS volume and use Network File System version 4 (NFSv4) locking with the volume.,Save the logs in an Amazon Glacier vault and use the Vault Lock feature.,Save the logs in an Amazon EBS volume and take monthly snapshots.,,C,"Amazon Glacier, which enables long-term storage of mission-critical data, has added Vault Lock. This new feature allows you to lock your vault with a variety of compliance controls that are designed to support such long-term records retention.",,,,
23,A Solutions Architect is creating an application running in an Amazon VPC that needs to access AWS Systems Manager Parameter Store. Networksecurity rules prohibit any route table entry with a 0.0.0.0/0 destination.What infrastructure addition will allow access to the AWS service while meeting the requirements?,VPC peering,NAT instance,NAT gateway,AWS PrivateLink,,D,"You can privately access AWS Systems Manager APIs from your VPC (created using Amazon Virtual Private Cloud) by creating VPC Endpoints. With VPC Endpoints, the routing between the VPC and AWS Systems Manager is handled by the AWS network without the need for an internet gateway, NAT gateway, or VPN connection. The latest generation of VPC Endpoints used by AWS Systems Manager are powered by AWS PrivateLink, a technology that enables private connectivity between AWS services using Elastic Network Interfaces (ENIs) with private IP addresses in your VPCs. To learn more about PrivateLink, visit the PrivateLink documentation. https://docs.aws.amazon.com/vpc/latest/userguide/vpce-interface.html",,,,
24,"A photo-sharing website running on AWS allows users to generate thumbnail images of photos stored in Amazon S3. An Amazon DynamoDB table maintains the locations of photos, and thumbnails are easily re- created from the originals if they are accidentally deleted. How should the thumbnail images be stored to ensure the LOWEST cost?",Amazon S3 Standard-Infrequent Access (S3 Standard-IA) with cross-region replication,Amazon S3,Amazon Glacier,Amazon S3 with cross-region replication,,B,,,,,
25,A company is implementing a data lake solution on Amazon S3. Its security policy mandates that the data stored in Amazon S3 should be encrypted at rest. Which options can achieve this? (Select TWO.),Use S3 server-side encryption with an Amazon EC2 key pair.,Use S3 server-side encryption with customer-provided keys (SSE-C).,Use S3 bucket policies to restrict access to the data at rest.,Use client-side encryption before ingesting the data to Amazon S3 using encryption keys.,Use SSL to encrypt the data while in transit to Amazon S3.,B D,,,,,
26,A solutions architect has created a new AWS account and must secure AWS account root user access. Which combination of actions will accomplish this? (Select TWO.),Ensure the root user uses a strong password,Enable multi-factor authentication to the root user,Store root user access keys in an encrypted Amazon S3 bucket,Add the root user to a group containing administrative permissions.,Apply the required permissions to the root user with an inline policy document,A B,https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html,,,,
27,A company's application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. On the first day of every month at midnight the application becomes much slower when the month-end financial calculation batch executes. This causes the CPU utilization of the EC2 instances to immediately peak to 100% which disrupts the application. What should a solutions architect recommend to ensure the application is able to handle the workload and avoid downtime?,Configure an Amazon CloudFront distribution in front of the ALB,Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization,Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.,Configure Amazon ElastiCache to remove some of the workload from the EC2 instances,,C,,,,,
28,A company is migrating from an on-premises infrastructure to the AWS Cloud. One of the company's applications stores files on a Windows file server farm that uses Distributed File System Replication (DFSR) to keep data in sync. A solutions architect needs to replace the file server farm. Which service should the solutions architect use?,Amazon EFS,Amazon FSx,Amazon S3,AWS Storage Gateway,,B,https://docs.aws.amazon.com/fsx/latest/WindowsGuide/migrate-files-to-fsx-datasync.html,,,,
29,A company's website is used to sell products to the public. The site runs on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB). There is also an Amazon CloudFront distribution and AWS WAF is being used to protect against SQL injection attacks. The ALB is the origin for the CloudFront distribution. A recent review of security logs revealed an external malicious IP that needs to be blocked from accessing the website. What should a solutions architect do to protect the application?,Modify the network ACL on the CloudFront distribution to add a deny rule for the malicious IP address,Modify the configuration of AWS WAF to add an IP match condition to block the malicious IP address,Modify the network ACL for the EC2 instances in the target groups behind the ALB to deny the malicious IP address,Modify the security groups for the EC2 instances in the target groups behind the ALB to deny the malicious IP address,,B,https://aws.amazon.com/blogs/aws/aws-web-application-firewall-waf-for-application-loadbalancers,,,,
30,A marketing company is storing CSV files in an Amazon S3 bucket for statistical analysis. An application on an Amazon EC2 instance needs permission to efficiently process the CSV data stored in the S3 bucket. Which action will MOST securely grant the EC2 instance access to the S3 bucket?,Attach a resource-based policy to the S3 bucket,Create an IAM user for the application with specific permissions to the S3 bucket,Associate an IAM role with least privilege permissions to the EC2 instance profile,Store AWS credentials directly on the EC2 instance for applications on the instance to use for API calls,,B,https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html,,,,
31,A solutions architect is designing a solution where users will De directed to a backup static error page it the primary website is unavailable. The primary website's DNS records are hosted in Amazon Route 53 where their domain is pointing to an Application Load Balancer (ALB). Which configuration should the solutions architect use to meet the company's needs while minimizing changes and infrastructure overhead?,"Point a Route 53 alias record to an Amazon CloudFront distribution with the ALB as one of its origins. Then, create custom error pages for the distribution. ",Set up a Route 53 active-passive failover configuration. Direct traffic to a static error page hosted within an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy. ,Update the Route 53 record to use a latency-based routing policy. Add the backup static error page hosted within an Amazon S3 bucket to the record so the traffic is sent to the most responsive endpoints. ,Set up a Route 53 active-active configuration with the ALB and an Amazon EC2 instance hosting a static error page as endpoints. Route 53 will only send requests to the instance if the health checks fail for the ALB. ,,B,,,,,
32,A solutions architect is designing the cloud architecture for a new application being deployed on AWS. The process should run in parallel while adding and removing application nodes as needed based on the number of jobs to be processed. The processor application is stateless. The solutions architect must ensure that the application is loosely coupled and the job items are durably stored. Which design should the solutions architect use?,"Point a Route 53 alias record to an Amazon CloudFront distribution with the ALB as one of its origins. Then, create custom error pages for the distribution.",Set up a Route 53 active-passive failover configuration. Direct traffic to a static error page hosted within an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy.,Update the Route 53 record to use a latency-based routing policy. Add the backup static error page hosted within an Amazon S3 bucket to the record so the traffic is sent to the most responsive endpoints.,Set up a Route 53 active-active configuration with the ALB and an Amazon EC2 instance hosting a static error page as endpoints. Route 53 will only send requests to the instance if the health checks fail for the ALB.,,C,,,,,
33,"A company has a legacy application that processes data in two parts. The second part of the process takes longer than the first, so the company has decided to rewrite the application as two microservices running on Amazon ECS that can scale independently. How should a solutions architect integrate the microservices?",Implement code in microservice 1 to send data to an Amazon S3 bucket. Use S3 event notifications to invoke microservice 2.,Implement code in microservice 1 to publish data to an Amazon SNS topic. Implement code in microservice 2 to subscribe to this topic.,Implement code in microservice 1 to send data to Amazon Kinesis Data Firehose. Implement code in microservice 2 to read from Kinesis Data Firehose.,Implement code in microservice 1 to send data to an Amazon SQS queue. Implement code in microservice 2 to process messages from the queue.,,C,,,,,
34,A solutions architect at an ecommerce company wants to back up application log data to Amazon S3. The solutions architect is unsure how frequently the logs will be accessed or which logs will be accessed the most. The company wants to keep costs as low as possible by using the appropriate S3 storage class. Which S3 storage class should be implemented to meet these requirements?,S3 Glacier,S3 Intelligent-Tiering,S3 Standard-Infrequent Access (S3 Standard-IA),S3 One Zone-Infrequent Access (S3 One Zone-IA),,D,"S3 One Zone-IA is for data that is accessed less frequently, but requires rapid access when needed. Unlike other S3 Storage Classes which store data in a minimum of three Availability Zones (AZs), S3 One Zone-IA stores data in a single AZ and costs 20% less than S3 Standard-IA. S3 One Zone-IA is ideal for customers who want a lower-cost option for infrequently accessed data but do not require the availability and resilience of S3 Standard or S3 Standard-IA. It's a good choice for storing secondary backup copies of on-premises data or easily re-creatable data. You can also use it as cost-effective storage for data that is replicated from another AWS Region using S3 Cross-Region Replication.",,,,
35,A security team wants to limit access to specific services or actions in all of the team's AWS accounts. All accounts belong to a large organization in AWS Organizations. The solution must be scalable and there must be a single point where permissions can be maintained. What should a solutions architect do to accomplish this?,Create an ACL to provide access to the services or actions.,Create a security group to allow accounts and attach it to user groups,Create cross-account roles in each account to deny access to the services or actions.,Create a service control policy in the root organizational unit to deny access to the services or actions,,D,,,,,
36,"You are trying to launch an EC2 instance, however the instance seems to go into a terminated status immediately. What would probably not be a reason that this is happening?",The AMI is missing a required part.,The snapshot is corrupt.,You need to create storage in EBS first.,You've reached your volume limit.,,C,"Amazon EC2 provides a virtual computing environments, known as an instance. After you launch an instance, AWS recommends that you check its status to confirm that it goes from the pending status to the running status, the not terminated status. The following are a few reasons why an Amazon EBS-backed instance might immediately terminate: You've reached your volume limit. The AMI is missing a required part. The snapshot is corrupt. Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_InstanceStraightToTerminated.html",,,,
37,"You have set up an Auto Scaling group. The cool down period for the Auto Scaling group is 7 minutes. The first instance is launched after 3 minutes, while the second instance is launched after 4 minutes. How many minutes after the first instance is launched will Auto Scaling accept another scaling activity request?",11 minutes,7 minutes,10 minutes,14 minutes,,A,"If an Auto Scaling group is launching more than one instance, the cool down period for each instance starts after that instance is launched. The group remains locked until the last instance that was launched has completed its cool down period. In this case the cool down period for the first instance starts after 3 minutes and finishes at the 10th minute (3+7 cool down), while for the second instance it starts at the 4th minute and finishes at the 11th minute (4+7 cool down). Thus, the Auto Scaling group will receive another request only after 11 minutes. Reference: http://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/AS_Concepts.html",,,,
38,"In Amazon EC2 Container Service components, what is the name of a logical grouping of container instances on which you can place tasks?",A cluster,A container instance,A container,A task definition,,A,Amazon ECS contains the following components: A Cluster is a logical grouping of container instances that you can place tasks on. A Container instance is an Amazon EC2 instance that is running the Amazon ECS agent and has been registered into a cluster. A Task definition is a description of an application that contains one or more container definitions. A Scheduler is the method used for placing tasks on container instances. A Service is an Amazon ECS service that allows you to run and maintain a specified number of instances of a task definition simultaneously. A Task is an instantiation of a task definition that is running on a container instance. A Container is a Linux container that was created as part of a task. Reference: http://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html,,,,
39,"In the context of AWS support, why must an EC2 instance be unreachable for 20 minutes rather than allowing customers to open tickets immediately?",Because most reachability issues are resolved by automated processes in less than 20 minutes,Because all EC2 instances are unreachable for 20 minutes every day when AWS does routine maintenance,Because all EC2 instances are unreachable for 20 minutes when first launched,Because of all the reasons listed here,,A,"An EC2 instance must be unreachable for 20 minutes before opening a ticket, because most reachability issues are resolved by automated processes in less than 20 minutes and will not require any action on the part of the customer. If the instance is still unreachable after this time frame has passed, then you should open a case with support. Reference: https://aws.amazon.com/premiumsupport/faqs/",,,,
40,Can a user get a notification of each instance start / terminate configured with Auto Scaling?,"Yes, if configured with the Launch Config","Yes, always","Yes, if configured with the Auto Scaling group",No,,C,The user can get notifications using SNS if he has configured the notifications while creating the Auto Scaling group. Reference: http://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/GettingStartedTutorial.html,,,,
41,Amazon EBS provides the ability to create backups of any Amazon EC2 volume into what is known as _____.,snapshots,images,instance backups,mirrors,,A,Amazon allows you to make backups of the data stored in your EBS volumes through snapshots that can later be used to create a new EBS volume. Reference: http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/Storage.html,,,,
42,"To specify a resource in a policy statement, in Amazon EC2, can you use its Amazon Resource Name (ARN)?","Yes, you can.","No, you can't because EC2 is not related to ARN.","No, you can't because you can't specify a particular Amazon EC2 resource in an IAM policy.","Yes, you can but only for the resources that are not affected by the action.",,A,"Some Amazon EC2 API actions allow you to include specific resources in your policy that can be created or modified by the action. To specify a resource in the statement, you need to use its Amazon Resource Name (ARN). Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-ug.pdf",,,,
43,"After you recommend Amazon Redshift to a client as an alternative solution to paying data warehouses to analyze his data, your client asks you to explain why you are recommending Redshift. Which of the following would be a reasonable response to his request?",It has high performance at scale as data and query complexity grows.,It prevents reporting and analytic processing from interfering with the performance of OLTP workloads.,"You don't have the administrative burden of running your own data warehouse and dealing with setup, durability, monitoring, scaling, and patching.",All answers listed are a reasonable response to his question,,D,"Amazon Redshift delivers fast query performance by using columnar storage technology to improve I/O efficiency and parallelizing queries across multiple nodes. Redshift uses standard PostgreSQL JDBC and ODBC drivers, allowing you to use a wide range of familiar SQL clients. Data load speed scales linearly with cluster size, with integrations to Amazon S3, Amazon DynamoDB, Amazon Elastic MapReduce, Amazon Kinesis or any SSH- enabled host. AWS recommends Amazon Redshift for customers who have a combination of needs, such as: High performance at scale as data and query complexity grows Desire to prevent reporting and analytic processing from interfering with the performance of OLTP workloads Large volumes of structured data to persist and query using standard SQL and existing BI tools Desire to the administrative burden of running one's own data warehouse and dealing with setup, durability, monitoring, scaling and patching Reference: https://aws.amazon.com/running_databases/#redshift_anchor",,,,
44,One of the criteria for a new deployment is that the customer wants to use AWS Storage Gateway. However you are not sure whether you should use gateway-cached volumes or gateway-stored volumes or even what the differences are. Which statement below best describes those differences?,Gateway-cached lets you store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway-stored enables you to configure your on-premises gateway to store all your data locally and then asynchronously back up point-in-time snapshots of this data to Amazon S3.,Gateway-cached is free whilst gateway-stored is not.,Gateway-cached is up to 10 times faster than gateway-stored.,Gateway-stored lets you store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway-cached enables you to configure your on-premises gateway to store all your data locally and then asynchronously back up point-in-time,,A,"Volume gateways provide cloud-backed storage volumes that you can mount as Internet Small Computer System Interface (iSCSI) devices from your on-premises application servers. The gateway supports the following volume configurations: Gateway-cached volumes ?You store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway-cached volumes offer a substantial cost savings on primary storage and minimize the need to scale your storage on- premises. You also retain low-latency access to your frequently accessed data. Gateway-stored volumes ?If you need low-latency access to your entire data set, you can configure your on- premises gateway to store all your data locally and then asynchronously back up point-in-time snapshots of this data to Amazon S3. This configuration provides durable and inexpensive off-site backups that you can recover to your local data center or Amazon EC2. For example, if you need replacement capacity for disaster recovery, you can recover the backups to Amazon EC2. Reference: http://docs.aws.amazon.com/storagegateway/latest/userguide/volume-gateway.html",,,,
45,A user is launching an EC2 instance in the US East region. Which of the below mentioned options is recommended by AWS with respect to the selection of the availability zone?,Always select the AZ while launching an instance,Always select the US-East-1-a zone for HA,Do not select the AZ; instead let AWS select the AZ,The user can never select the availability zone while launching an instance,,C,"When launching an instance with EC2, AWS recommends not to select the availability zone (AZ). AWS specifies that the default Availability Zone should be accepted. This is because it enables AWS to select the best Availability Zone based on the system health and available capacity. If the user launches additional instances, only then an Availability Zone should be specified. This is to specify the same or different AZ from the running instances. Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html",,,,
46,A company's website runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The website has a mix of dynamic and static content Users around the globe are reporting that the website is slow. Which set of actions will improve website performance for users worldwide?,Create an Amazon CloudFront distribution and configure the ALB as an origin. Then update the Amazon Route 53 record to point to the CloudFront distribution.,Create a latency-based Amazon Route 53 record for the ALB. Then launch new EC2 instances with larger instance sizes and register the instances with the ALB.,Launch nev. EC2 instances hosting the same web application in different Regions closer to the users. Then register the instances with the same ALB using cross-Region VPC peering.,Host the website in an Amazon S3 bucket in the Regions closest to the users and delete the ALB and EC2 instances. Then update an Amazon Route 53 record to point to the S3 buckets.,,A,https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-cloudfrontdistribution.Html ,,,,
47,A company wants to migrate a high performance computing (HPC) application and data from on- premises to the AWS Cloud. The company uses tiered storage on premises with hot high-performance parallel storage to support the application during periodic runs of the application and more economical cold storage to hold the data when the application is not actively running. Which combination of solutions should a solutions architect recommend to support the storage needs of the application? (Select TWO ),Amazon S3 for cold data storage,Amazon EFS for cold data storage,Amazon S3 for high-performance parallel storage,Amazon FSx for Lustre for high-performance parallel storage,Amazon FSx for Windows for high-performance parallel storage,A D,,,,,
48,A company has on-premises servers running a relational database. The current database serves high read traffic for users in different locations. The company wants to migrate to AWS with the least amount of effort. The database solution should support disaster recovery and not affect the company's current traffic flow. Which solution meets these requirements?,Use a database in Amazon RDS with Multi-AZ and at least one read replica,Use a database in Amazon RDS with Multi-AZ and at least one standby replica,Use databases hosted on multiple Amazon EC2 instances in different AWS Regions,Use databases hosted on Amazon EC2 instances behind an Application Load Balancer in different Availability Zones,,A,https://aws.amazon.com/blogs/database/implementing-a-disaster-recovery-strategy-with-amazon-rds/,,,,
49,A media streaming company collects real-time data and stores it in a disk-optimized database system. The company is not getting the expected throughput and wants an in-memory database storage solution that performs faster and provides high availability using data replication. Which database should a solutions architect recommend'?,Amazon RDS for MySQL,Amazon RDS for PostgreSQL,Amazon ElastiCache for Redis,Amazon ElastiCache for Memcached,,C,,,,,
50,"A company's application is running on Amazon EC2 instances within an Auto Scaling group behind an Elastic Load Balancer. Based on the application's history, the company anticipates a spike in traffic during a holiday each year. A solutions architect must design a strategy to ensure that the Auto Scaling group proactively increases capacity to minimize any performance impact on application users. Which solution will meet these requirements?",Create an Amazon CloudWatch alarm to scale up the EC2 instances when CPU utilization exceeds 90%,Create a recurring scheduled action to scale up the Auto Scaling group before the expected period of peak demand,Increase the minimum and maximum number of EC2 instances in the Auto Scaling group during the peak demand period,Configure an Amazon Simple Notification Service (Amazon SNS) notification to send alerts when there are auto scaling EC2_INSTANCE_LAUNCH events,,D,https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-dg.pdf ,,,,
51,A company has a two-tier application architecture that runs in public and private subnets Amazon EC2 instances running the web application are in the public subnet and a database runs on the private subnet. The web application instances and the database are running in a single Availability Zone (AZ). Which combination of steps should a solutions architect take to provide high availability for this architecture? (Select TWO.),Create new public and private subnets in the same AZ for high availability,Create an Amazon EC2 Auto Scaling group and Application Load Balancer spanning multiple AZs,Add the existing web application instances to an Auto Scaling group behind an Application Load Balancer,Create new public and private subnets in a new AZ Create a database using Amazon EC2 in one AZ,Create new public and private subnets in the same VPC each in a new AZ Migrate the database to an Amazon RDS multi-AZ deployment,B E,You would the EC2 instances to have high availability by placing them in multiple AZs.,,,,
52,A financial services company has a web application that serves users in the United States and Europe. The application consists of a database tier and a web server tier. The database tier consists of a MySQL database hosted in us-east-1 Amazon Route 53 geoproximity routing is used to direct traffic to instances in the closest Region. A performance review of the system reveals that European users are not receiving the same level of query performance as those in the United States. Which changes should be made to the database tier to improve performance?,Migrate the database to Amazon RDS for MySQL. Configure Multi-AZ in one of the European Regions. ,Migrate the database to Amazon DynamoDB. Use DynamoDB global tables to enable replication to additional Regions. ,Deploy MySQL instances in each Region. Deploy an Application Load Balancer in front of MySQL to reduce the load on the primary instance. ,Migrate the database to an Amazon Aurora global database in MySQL compatibility mode. Configure read replicas in one of the European Regions. ,,D,,,,,
53,A solutions architect is tasked with transferring 750 TB of data from a network-attached file system located at a branch office to Amazon S3 Glacier. The solution must avoid saturating the branch office's low-bandwidth internet connection. What is the MOST cost-effective solution1?,Create a site-to-site VPN tunnel to an Amazon S3 bucket and transfer the files directly. Create a bucket policy to enforce a VPC endpoint.,Order 10 AWS Snowball appliances and select an S3 Glacier vault as the destination. Create a bucket policy to enforce a VPC endpoint.,Mount the network-attached file system to Amazon S3 and copy the files directly. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier.,Order 10 AWS Snowball appliances and select an Amazon S3 bucket as the destination. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier.,,D,,,,,
54,A company's production application runs online transaction processing (OLTP) transactions on an Amazon RDS MySQL DB instance. The company is launching a new reporting tool that will access the same data. The reporting tool must be highly available and not impact the performance of the production application. How can this be achieved'?,Create hourly snapshots of the production RDS DB instance. ,Create a Multi-AZ RDS Read Replica of the production RDS DB instance. ,Create multiple RDS Read Replicas of the production RDS DB instance. Place the Read Replicas in an Auto Scaling group. ,Create a Single-AZ RDS Read Replica of the production RDS DB instance. Create a second Single-AZ RDS Read Replica from the replica. ,,B,https://aws.amazon.com/blogs/database/best-storage-practices-for-running-production-workloadson- hosted-databases-with-amazon-rds-or-amazon- ec2/ ,,,,
55,"A company allows its developers to attach existing 1AM policies to existing 1AM roles to enable faster experimentation and agility. However the security operations team is concerned that the developers could attach the existing administrator policy, which would allow the developers to circumvent any other security policies. How should a solutions architect address this issue?",Create an Amazon SNS topic to send an alert every time a developer creates a new policy,Use service control policies to disable IAM activity across all accounts in the organizational unit,Prevent the developers from attaching any policies and assign all 1AM duties to the security operations team,Set an IAM permissions boundary on the developer 1AM role that explicitly denies attaching the administrator policy,,C,,,,,
56,A user is storing a large number of objects on AWS S3. The user wants to implement the search functionality among the objects. How can the user achieve this?,Use the indexing feature of S3.,Tag the objects with the metadata to search on that.,Use the query functionality of S3.,Make your own DB system which stores the S3 metadata for the search functionality.,,D,"In Amazon Web Services, AWS S3 does not provide any query facility. To retrieve a specific object the user needs to know the exact bucket / object key. In this case it is recommended to have an own DB system which manages the S3 metadata and key mapping. Reference: http://media.amazonwebservices.com/AWS_Storage_Options.pdf",,,,
57,"After setting up a Virtual Private Cloud (VPC) network, a more experienced cloud engineer suggests that to achieve low network latency and high network throughput you should look into setting up a placement group. You know nothing about this, but begin to do some research about it and are especially curious about its limitations. Which of the below statements is wrong in describing the limitations of a placement group?","Although launching multiple instance types into a placement group is possible, this reduces the likelihood that the required capacity will be available for your launch to succeed.",A placement group can span multiple Availability Zones.,You can't move an existing instance into a placement group.,A placement group can span peered VPCs,,B,"A placement group is a logical grouping of instances within a single Availability Zone. Using placement groups enables applications to participate in a low-latency, 10 Gbps network. Placement groups are recommended for applications that benefit from low network latency, high network throughput, or both. To provide the lowest latency, and the highest packet-per-second network performance for your placement group, choose an instance type that supports enhanced networking. Placement groups have the following limitations: The name you specify for a placement group a name must be unique within your AWS account. A placement group can't span multiple Availability Zones. Although launching multiple instance types into a placement group is possible, this reduces the likelihood that the required capacity will be available for your launch to succeed. We recommend using the same instance type for all instances in a placement group. You can't merge placement groups. Instead, you must terminate the instances in one placement group, and then relaunch those instances into the other placement group. A placement group can span peered VPCs; however, you will not get full- bisection bandwidth between instances in peered VPCs. For more information about VPC peering connections, see VPC Peering in the Amazon VPC User Guide. You can't move an existing instance into a placement group. You can create an AMI from your existing instance, and then launch a new instance from the AMI into a placement group. Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html",,,,
58,What is a placement group in Amazon EC2?,It is a group of EC2 instances within a single Availability Zone.,It the edge location of your web content.,It is the AWS region where you run the EC2 instance of your web content.,It is a group used to span multiple Availability Zones.,,A,A placement group is a logical grouping of instances within a single Availability Zone. Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html,,,,
59,You are migrating an internal server on your DC to an EC2 instance with EBS volume. Your server disk usage is around 500GB so you just copied all your data to a 2TB disk to be used with AWS Import/Export. Where will the data be imported once it arrives at Amazon?,to a 2TB EBS volume,to an S3 bucket with 2 objects of 1TB,to an 500GB EBS volume,to an S3 bucket as a 2TB snapshot,,B,"An import to Amazon EBS will have different results depending on whether the capacity of your storage device is less than or equal to 1 TB or greater than 1 TB. The maximum size of an Amazon EBS snapshot is 1 TB, so if the device image is larger than 1 TB, the image is chunked and stored on Amazon S3. The target location is determined based on the total capacity of the device, not the amount of data on the device. Reference: http://docs.aws.amazon.com/AWSImportExport/latest/DG/Concepts.html",,,,
60,"A client needs you to import some existing infrastructure from a dedicated hosting provider to AWS to try and save on the cost of running his current website. He also needs an automated process that manages backups, software patching, automatic failure detection, and recovery. You are aware that his existing set up currently uses an Oracle database. Which of the following AWS databases would be best for accomplishing this task?",Amazon RDS,Amazon Redshift,Amazon SimpleDB,Amazon ElastiCache,,A,"Amazon RDS gives you access to the capabilities of a familiar MySQL, Oracle, SQL Server, or PostgreSQL database engine. This means that the code, applications, and tools you already use today with your existing databases can be used with Amazon RDS. Amazon RDS automatically patches the database software and backs up your database, storing the backups for a user- defined retention period and enabling point-in-time recovery. Reference: http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html",,,,
61,"True or false: A VPC contains multiple subnets, where each subnet can span multiple Availability Zones.",This is true only if requested during the set-up of VPC.,This is true.,This is false.,This is true only for US regions.,,C,"A VPC can span several Availability Zones. In contrast, a subnet must reside within a single Availability Zone. Reference: https://aws.amazon.com/vpc/faqs/",,,,
62,An edge location refers to which Amazon Web Service?,An edge location is refered to the network configured within a Zone or Region,An edge location is an AWS Region,An edge location is the location of the data center used for Amazon CloudFront.,An edge location is a Zone within an AWS Region,,C,"Amazon CloudFront is a content distribution network. A content delivery network or content distribution network (CDN) is a large distributed system of servers deployed in multiple data centers across the world. The location of the data center used for CDN is called edge location. Amazon CloudFront can cache static content at each edge location. This means that your popular static content (e.g., your site's logo, navigational images, cascading style sheets, JavaScript code, etc.) will be available at a nearby edge location for the browsers to download with low latency and improved performance for viewers. Caching popular static content with Amazon CloudFront also helps you offload requests for such files from your origin sever - CloudFront serves the cached copy when available and only makes a request to your origin server if the edge location receiving the browser's request does not have a copy of the file. Reference: http://aws.amazon.com/cloudfront/",,,,
63,Which of the following statements is true in regards to ElasticCache?,You are looking at ways to improve some existing infrastructure as it seems a lot of engineering resources are being taken up with basic management and monitoring tasks and the costs seem to be excessive. You are thinking of deploying Amazon ElasticCache to help. Which of the following statements is true in regards to ElasticCache?,You can improve load and response times to user actions and queries however the cost associated with scaling web applications will be more.,You can't improve load and response times to user actions and queries but you can reduce the cost associated with scaling web applications.,You can improve load and response times to user actions and queries however the cost associated with scaling web applications will remain the same.,You can improve load and response times to user actions and queries and also reduce the cost associated with scaling web applications.,D,"Amazon ElastiCache is a web service that makes it easy to deploy and run Memcached or Redis protocol-compliant server nodes in the cloud. Amazon ElastiCache improves the performance of web applications by allowing you to retrieve information from a fast, managed, in-memory caching system, instead of relying entirely on slower disk-based databases. The service simplifies and offloads the management, monitoring and operation of in-memory cache environments, enabling your engineering resources to focus on developing applications. Using Amazon ElastiCache, you can not only improve load and response times to user actions and queries, but also reduce the cost associated with scaling web applications. Reference: https://aws.amazon.com/elasticache/faqs/",,,,
64,Do Amazon EBS volumes persist independently from the running life of an Amazon EC2 instance?,"Yes, they do but only if they are detached from the instance.","No, you cannot attach EBS volumes to an instance.","No, they are dependent.","Yes, they do.",,D,"An Amazon EBS volume behaves like a raw, unformatted, external block device that you can attach to a single instance. The volume persists independently from the running life of an Amazon EC2 instance. Reference: http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/Storage.html",,,,
65,Your supervisor has asked you to build a simple file synchronization service for your department. He doesn't want to spend too much money and he wants to be notified of any changes to files by email. What do you think would be the best Amazon service to use for the email solution?,Amazon SES,Amazon CloudSearch,Amazon SWF,Amazon AppStream,,A,"File change notifications can be sent via email to users following the resource with Amazon Simple Email Service (Amazon SES), an easy-to-use, cost- effective email solution. Reference: http://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_filesync_08.pdf",,,,
66,A product team is creating a new application that will store a large amount of data. The data will be analyzed hourly and modified by multiple Amazon EC2 Linux instances.The application team believes the amount of space needed will continue to grow for the next 6 months. Which set of actions should a solutions architect take to support these needs'?,Store the data in an Amazon EBS volume. Mount the EBS volume on the application instances,Store the data in an Amazon EFS file system. Mount the file system on the application instances.,Store the data in Amazon S3 Glacier. Update the vault policy to allow access to the application instances.,Store the data in Amazon S3 Standard-Infrequent Access (S3 Standard-IA). Update the bucket policy to allow access to the application instances.,,B,,,,,
67,A gaming company has multiple Amazon EC2 instances in a single Availability Zone for its multiplayer game that communicates with users on Layer 4. The chief technology officer (CTO) wants to make the architecture highly available and cost-effective. What should a solutions architect do to meet these requirements? (Select TWO.),Increase the number of EC2 instances.,Decrease the number of EC2 instances,Configure a Network Load Balancer in front of the EC2 instances.,Configure an Application Load Balancer in front of the EC2 instances,Configure an Auto Scaling group to add or remove instances in multiple Availability Zones automatically.,C E,,,,,
68,A company hosts an application on multiple Amazon EC2 instances. The application processes messages from an Amazon SQS queue writes to an Amazon RDS table and deletes the message from the queue Occasional duplicate records are found in the RDS table. The SQS queue does not contain any duplicate messages. What should a solutions archived do to ensure messages are being processed once only?,Use the CreateQueue API call to create a new queue,Use the AddPermission API call to add appropriate permissions,Use the ReceiveMessage API call to set an appropriate wait time.,Use the ChangeMessageVisibility API call to increase the visibility timeout,,A,https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html#FIFO-queues-exactly-once-processing ,,,,
69,"A solutions architect is designing an application for a two-step order process. The first step is synchronous and must return to the user with little latency. The second step takes longer, so it will be implemented in a separate component Orders must be processed exactly once and in the order in which they are received. How should the solutions architect integrate these components?",Use Amazon SQS FIFO queues.,Use an AWS Lambda function along with Amazon SQS standard queues,Create an SNS topic and subscribe an Amazon SQS FIFO queue to that topic,Create an SNS topic and subscribe an Amazon SQS Standard queue to that topic.,,C,https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFOqueues.Html,,,,
70,A solutions architect is designing a high performance computing (HPC) workload on Amazon EC2. The EC2 instances need to communicate to each other frequently and require network performance with low latency and high throughput. Which EC2 configuration meets these requirements?,Launch the EC2 instances in a cluster placement group in one Availability Zone,Launch the EC2 instances in a spread placement group in one Availability Zone,Launch the EC2 instances in an Auto Scaling group in two Regions and peer the VPCs,Launch the EC2 instances in an Auto Scaling group spanning multiple Availability Zones,,A,,,,,
71,"A company is planning to use Amazon S3 lo store images uploaded by its users. The images must be encrypted at rest in Amazon S3. The company does not want to spend time managing and rotating the keys, but it does want to control who can access those keys. What should a solutions architect use to accomplish this?",Server-Side Encryption with keys stored in an S3 bucket,Server-Side Encryption with Customer-Provided Keys (SSE-C),Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3),Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS),,C,,,,,
72,An Amazon EC2 administrator created the following policy associated with an 1AM group containing several users. What is the effect of this policy?,Users can terminate an EC2 instance in any AWS Region except us-east-1.,Users can terminate an EC2 instance with the IP address 10.100. 1001 in the us-east-1 Region.,Users can terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254.,Users cannot terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254.,,C,,,,,
73,"A company is running an ecommerce application on Amazon EC2. The application consists of a stateless web tier that requires a minimum of 10 instances, and a peak of 250 instances to support the application's usage. The application requires 50 instances 80% of the time. Which solution should be used to minimize costs?",Purchase Reserved Instances to cover 250 instances ,Purchase Reserved Instances to cover 80 instances. Use Spot Instances to cover the remaining instances ,Purchase On-Demand Instances to cover 40 instances. Use Spot Instances to cover the remaining instances ,Purchase Reserved Instances to cover 50 instances. Use On-Demand and Spot Instances to cover the remaining instances ,,D,,,,,
74,Does DynamoDB support in-place atomic updates?,Yes,No,It does support in-place non-atomic updates,It is not defined,,A,DynamoDB supports in-place atomic updates.,,,,
75,Your manager has just given you access to multiple VPN connections that someone else has recently set up between all your company's offices. She needs you to make sure that the communication between the VPNs is secure. Which of the following services would be best for providing a low-cost hub-and-spoke model for primary or backup connectivity between these remote offices?,Amazon CloudFront,AWS Direct Connect,AWS CloudHSM,AWS VPN CloudHub,,D,"If you have multiple VPN connections, you can provide secure communication between sites using the AWS VPN CloudHub. The VPN CloudHub operates on a simple hub-and-spoke model that you can use with or without a VPC. This design is suitable for customers with multiple branch offices and existing Internet connections who would like to implement a convenient, potentially low-cost hub-and-spoke model for primary or backup connectivity between these remote offices. Reference: http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPN_CloudHub.html",,,,
76,Amazon EC2 provides a ____. It is an HTTP or HTTPS request that uses the HTTP verbs GET or POST.,web database,.net framework,Query API,C library,,C,Amazon EC2 provides a Query API. These requests are HTTP or HTTPS requests that use the HTTP verbs GET or POST and a Query parameter named Action. Reference: http://docs.aws.amazon.com/AWSEC2/latest/APIReference/making-api-requests.html ,,,,
77,"In Amazon AWS, which of the following statements is true of key pairs?",Key pairs are used only for Amazon SDKs.,Key pairs are used only for Amazon EC2 and Amazon CloudFront.,Key pairs are used only for Elastic Load Balancing and AWS IAM.,Key pairs are used for all Amazon services.,,B,"Key pairs consist of a public and private key, where you use the private key to create a digital signature, and then AWS uses the corresponding public key to validate the signature. Key pairs are used only for Amazon EC2 and Amazon CloudFront. Reference: http://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html",,,,
78,Does Amazon DynamoDB support both increment and decrement atomic operations?,"Only increment, since decrement are inherently impossible with DynamoDB's data model.","No, neither increment nor decrement operations.","Yes, both increment and decrement operations.","Only decrement, since increment are inherently impossible with DynamoDB's data model.",,C,Amazon DynamoDB supports increment and decrement atomic operations. Reference: http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/APISummary.html,,,,
79,"An organization has three separate AWS accounts, one each for development, testing, and production. The organization wants the testing team to have access to certain AWS resources in the production account. How can the organization achieve this?",It is not possible to access resources of one account with another account.,Create the IAM roles with cross account access.,"Create the IAM user in a test account, and allow it access to the production environment with the IAM policy.",Create the IAM users with cross account access.,,B,"An organization has multiple AWS accounts to isolate a development environment from a testing or production environment. At times the users from one account need to access resources in the other account, such as promoting an update from the development environment to the production environment. In this case the IAM role with cross account access will provide a solution. Cross account access lets one account share access to their resources with users in the other AWS accounts. Reference: http://media.amazonwebservices.com/AWS_Security_Best_Practices.pdf",,,,
80,You need to import several hundred megabytes of data from a local Oracle database to an Amazon RDS DB instance. What does AWS recommend you use to accomplish this?,Oracle export/import utilities,Oracle SQL Developer,Oracle Data Pump,DBMS_FILE_TRANSFER,,C,"How you import data into an Amazon RDS DB instance depends on the amount of data you have and the number and variety of database objects in your database. For example, you can use Oracle SQL Developer to import a simple, 20 MB database; you want to use Oracle Data Pump to import complex databases or databases that are several hundred megabytes or several terabytes in size. Reference: http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Procedural.Importing.html",,,,
81,A user has created an EBS volume with 1000 IOPS. What is the average IOPS that the user will get for most of the year as per EC2 SLA if the instance is attached to the EBS optimized instance?,950,990,1000,900,,D,"As per AWS SLA if the instance is attached to an EBS-Optimized instance, then the Provisioned IOPS volumes are designed to deliver within 10% of the provisioned IOPS performance 99.9% of the time in a given year. Thus, if the user has created a volume of 1000 IOPS, the user will get a minimum 900 IOPS 99.9% time of the year. Reference: http://aws.amazon.com/ec2/faqs/",,,,
82,You need to migrate a large amount of data into the cloud that you have stored on a hard disk and you decide that the best way to accomplish this is with AWS Import/Export and you mail the hard disk to AWS. Which of the following statements is incorrect in regards to AWS Import/Export?,It can export from Amazon S3,It can Import to Amazon Glacier,It can export from Amazon Glacier.,It can Import to Amazon EBS,,C,AWS Import/Export supports: Import to Amazon S3 Export from Amazon S3 Import to Amazon EBS Import to Amazon Glacier AWS Import/Export does not currently support export from Amazon EBS or Amazon Glacier. Reference: https://docs.aws.amazon.com/AWSImportExport/latest/DG/whatisdisk.html,,,,
83,"You are in the process of creating a Route 53 DNS failover to direct traffic to two EC2 zones. Obviously, if one fails, you would like Route 53 to direct traffic to the other region. Each region has an ELB with some instances being distributed. What is the best way for you to configure the Route 53 health check?",Route 53 doesn't support ELB with an internal health check.You need to create your own Route 53 health check of the ELB,"Route 53 natively supports ELB with an internal health check. Turn ""Evaluate target health"" off and ""Associate with Health Check"" on and R53 will use the ELB's internal health check.",Route 53 doesn't support ELB with an internal health check. You need to associate your resource record set for the ELB with your own health check,"Route 53 natively supports ELB with an internal health check. Turn ""Evaluate target health"" on and ""Associate with Health Check"" off and R53 will use the ELB's internal health check.",,D,"With DNS Failover, Amazon Route 53 can help detect an outage of your website and redirect your end users to alternate locations where your application is operating properly. When you enable this feature, Route 53 uses health checks--regularly making Internet requests to your application's endpoints from multiple locations around the world--to determine whether each endpoint of your application is up or down. To enable DNS Failover for an ELB endpoint, create an Alias record pointing to the ELB and set the ""Evaluate Target Health"" parameter to true. Route 53 creates and manages the health checks for your ELB automatically. You do not need to create your own Route 53 health check of the ELB. You also do not need to associate your resource record set for the ELB with your own health check, because Route 53 automatically associates it with the health checks that Route 53 manages on your behalf. The ELB health check will also inherit the health of your backend instances behind that ELB. Reference: http://aws.amazon.com/about-aws/whats-new/2013/05/30/amazon-route-53-adds-elb- integration-for-dns- failover/",,,,
84,"A user wants to use an EBS-backed Amazon EC2 instance for a temporary job. Based on the input data, the job is most likely to finish within a week. Which of the following steps should be followed to terminate the instance automatically once the job is finished?",Configure the EC2 instance with a stop instance to terminate it.,Configure the EC2 instance with ELB to terminate the instance when it remains idle.,Configure the CloudWatch alarm on the instance that should perform the termination action once the instance is idle.,Configure the Auto Scaling schedule activity that terminates the instance after 7 days.,,C,"Auto Scaling can start and stop the instance at a pre-defined time. Here, the total running time is unknown. Thus, the user has to use the CloudWatch alarm, which monitors the CPU utilization. The user can create an alarm that is triggered when the average CPU utilization percentage has been lower than 10 percent for 24 hours, signaling that it is idle and no longer in use. When the utilization is below the threshold limit, it will terminate the instance as a part of the instance action. Reference: http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/UsingAlarmActions.html",,,,
85,Which of the following is true of Amazon EC2 security group?,You can modify the outbound rules for EC2-Classic.,You can modify the rules for a security group only if the security group controls the traffic for just one instance.,You can modify the rules for a security group only when a new instance is created.,You can modify the rules for a security group at any time.,,D,"A security group acts as a virtual firewall that controls the traffic for one or more instances. When you launch an instance, you associate one or more security groups with the instance. You add rules to each security group that allow traffic to or from its associated instances. You can modify the rules for a security group at any time; the new rules are automatically applied to all instances that are associated with the security group. Reference: http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/using-network- security.html",,,,
86,"An Elastic IP address (EIP) is a static IP address designed for dynamic cloud computing. With an EIP, you can mask the failure of an instance or software by rapidly remapping the address to another instance in your account. Your EIP is associated with your AWS account, not a particular EC2 instance, and it remains associated with your account until you choose to explicitly release it. By default how many EIPs is each AWS account limited to on a per region basis?",1,5,Unlimited,10,,B,"By default, all AWS accounts are limited to 5 Elastic IP addresses per region for each AWS account, because public (IPv4) Internet addresses are a scarce public resource. AWS strongly encourages you to use an EIP primarily for load balancing use cases, and use DNS hostnames for all other inter- node communication. If you feel your architecture warrants additional EIPs, you would need to complete the Amazon EC2 Elastic IP Address Request Form and give reasons as to your need for additional addresses. Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses- eip.html#using-instance-ad dressing-limit",,,,
87,"An application running on AWS uses an Amazon Aurora Multi-AZ deployment for its database. When evaluating performance metrics, a solutions architect discovered that the database reads are causing high I/O and adding latency to the write requests against the database. What should the solutions architect do to separate the read requests from the write requests?",Enable read-through caching on the Amazon Aurora database,Update the application to read from the Multi-AZ standby instance,Create a read replica and modify the application to use the appropriate endpoint,Create a second Amazon Aurora database and link it to the primary database as a read replica.,,C,https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html,,,,
88,An application runs on Amazon EC2 instances across multiple Availability Zones. The instances run in an Amazon EC2 Auto Scaling group behind an Application Load Balancer. The application performs best when the CPU utilization of the EC2 instances is at or near 40%. What should a solutions architect do to maintain the desired performance across all instances m the group?,Use a simple scaling policy to dynamically scale the Auto Scaling group,Use a target tracking policy to dynamically scale the Auto Scaling group,Use an AWS Lambda function to update the desired Auto Scaling group capacity,Use scheduled scaling actions to scale up and scale down the Auto Scaling group,,D,https://docs.aws.amazon.com/autoscaling/application/userguide/application-auto-scalingscheduled-scaling.html,,,,
89,A company runs a multi-tier web application that hosts news content. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones and use an Amazon Aurora database. A solutions architect needs to make the application more resilient to periodic increases in request rates. Which architecture should the solutions architect implement? (Select TWO ),Add AWS Shield.,Add Aurora Replicas,Add AWS Direct Connect,Add AWS Global Accelerator.,Add an Amazon CloudFront distribution in front of the Application Load Balancer,D E,,,,,
90,A solutions architect is optimizing a website for an upcoming musical event Videos of the performances will be streamed in real time and then will be available on demand. The event is expected to attract a global online audience. Which service will improve the performance of both the real-time and on-demand streaming?,Amazon CloudFront,AWS Global Accelerator,Amazon Route 53,Amazon S3 Transfer Acceleration,,A,https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/on-demand-streaming-video.html,,,,
91,A company serves content to its subscribers across the world using an application running on AWS. The application has several Amazon EC2 instances in a private subnet behind an Application Load Balancer (ALB). Due to a recent change in copyright restrictions the chief information officer (CIO) wants to block access for certain countries. Which action will meet these requirements?,Modify the ALB security group to deny incoming traffic from blocked countries,Modify the security group for EC2 instances to deny incoming traffic from blocked countries,Use Amazon CloudFront to serve the application and deny access to blocked countries,Use ALB listener rules to return access denied responses to incoming traffic from blocked countries,,C,,,,,
92,A manufacturing company wants to implement predictive maintenance on its machinery equipment. The company will install thousands of loT sensors that will send data to AWS in real time. A solutions architect is tasked with implementing a solution that will receive events in an ordered manner for each machinery asset and ensure that data is saved for further processing at a later time. Which solution would be MOST efficient?,Use Amazon Kinesis Data Streams for real-time events with a partition for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon S3.,Use Amazon Kinesis Data Streams for real-time events with a shard for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon EBS.,Use an Amazon SQS FIFO queue for real-time events with one queue for each equipment asset. Trigger an AWS Lambda function for the SQS queue to save data to Amazon EFS.,Use an Amazon SQS standard queue for real-time events with one queue for each equipment asset. Trigger an AWS Lambda function from the SQS queue to save data to Amazon S3.,,A,,,,,
93,"A company has deployed an API in a VPC behind an internet-facing Application Load Balancer (ALB). An application that consumes the API as a client is deployed in a second account in private subnets behind a NAT gateway. When requests to the client application increase, the NAT gateway costs are higher than expected. A solutions architect has configured the ALB to be internal. Which combination of architectural changes will reduce the NAT gateway costs'? (Select TWO )",Configure a VPC peering connection between the two VPCs. Access the API using the private address,Configure an AWS Direct Connect connection between the two VPCs. Access the API using the private address.,Configure a ClassicLink connection for the API into the client VPC. Access the API using the ClassicLink address.,Configure a PrivateLink connection for the API into the client VPC. Access the API using the PrivateLink address.,Configure an AWS Resource Access Manager connection between the two accounts. Access the API using the private address,D E,,,,,
94,"In Amazon EC2, partial instance-hours are billed _____.",per second used in the hour,per minute used,by combining partial segments into full hours,as full hours,,D,Partial instance-hours are billed to the next hour. Reference: http://aws.amazon.com/ec2/faqs/,,,,
95,"In EC2, what happens to the data in an instance store if an instance reboots (either intentionally or unintentionally)?",Data is deleted from the instance store for security reasons.,Data persists in the instance store.,Data is partially present in the instance store.,Data in the instance store will be lost.,,B,"The data in an instance store persists only during the lifetime of its associated instance. If an instance reboots (intentionally or unintentionally), data in the instance store persists. However, data on instance store volumes is lost under the following circumstances. Failure of an underlying drive Stopping an Amazon EBS-backed instance Terminating an instance Reference: http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/InstanceStorage.html",,,,
96,You are setting up a VPC and you need to set up a public subnet within that VPC. Which following requirement must be met for this subnet to be considered a public subnet?,Subnet's traffic is not routed to an internet gateway but has its traffic routed to a virtual private gateway.,Subnet's traffic is routed to an internet gateway.,Subnet's traffic is not routed to an internet gateway.,None of these answers can be considered a public subnet.,,B,"A virtual private cloud (VPC) is a virtual network dedicated to your AWS account. It is logically isolated from other virtual networks in the AWS cloud. You can launch your AWS resources, such as Amazon EC2 instances, into your VPC. You can configure your VPC: you can select its IP address range, create subnets, and configure route tables, network gateways, and security settings. A subnet is a range of IP addresses in your VPC. You can launch AWS resources into a subnet that you select. Use a public subnet for resources that must be connected to the internet, and a private subnet for resources that won't be connected to the Internet. If a subnet's traffic is routed to an internet gateway, the subnet is known as a public subnet. If a subnet doesn't have a route to the internet gateway, the subnet is known as a private subnet. If a subnet doesn't have a route to the internet gateway, but has its traffic routed to a virtual private gateway, the subnet is known as a VPN-only subnet. Reference: http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html",,,,
97,Can you specify the security group that you created for a VPC when you launch an instance in EC2-Classic?,"No, you can specify the security group created for EC2-Classic when you launch a VPC instance.",No,Yes,"No, you can specify the security group created for EC2-Classic to a non-VPC based instance only.",,B,"If you're using EC2-Classic, you must use security groups created specifically for EC2-Classic. When you launch an instance in EC2-Classic, you must specify a security group in the same region as the instance. You can't specify a security group that you created for a VPC when you launch an instance in EC2-Classic. Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html#ec2-classic-securit y-groups",,,,
98,"While using the EC2 GET requests as URLs, the _____ is the URL that serves as the entry point for the web service.",token,endpoint,action,None of these,,B,The endpoint is the URL that serves as the entry point for the web service. Reference: http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/using-query-api.html,,,,
99,"You have been asked to build a database warehouse using Amazon Redshift. You know a little about it, including that it is a SQL data warehouse solution, and uses industry standard ODBC and JDBC connections and PostgreSQL drivers. However you are not sure about what sort of storage it uses for database tables. What sort of storage does Amazon Redshift use for database tables?",InnoDB Tables,NDB data storage,Columnar data storage,NDB CLUSTER Storage,,C,"Amazon Redshift achieves efficient storage and optimum query performance through a combination of massively parallel processing, columnar data storage, and very efficient, targeted data compression encoding schemes. Columnar storage for database tables is an important factor in optimizing analytic query performance because it drastically reduces the overall disk I/O requirements and reduces the amount of data you need to load from disk. Reference: http://docs.aws.amazon.com/redshift/latest/dg/c_columnar_storage_disk_mem_mgmnt.html",,,,
100,You are checking the workload on some of your General Purpose (SSD) and Provisioned IOPS (SSD) volumes and it seems that the I/O latency is higher than you require. You should probably check the _____________ to make sure that your application is not trying to drive more IOPS than you have provisioned.,Amount of IOPS that are available,Acknowledgement from the storage subsystem,Average queue length,Time it takes for the I/O operation to complete,,C,"In EBS workload demand plays an important role in getting the most out of your General Purpose (SSD) and Provisioned IOPS (SSD) volumes. In order for your volumes to deliver the amount of IOPS that are available, they need to have enough I/O requests sent to them. There is a relationship between the demand on the volumes, the amount of IOPS that are available to them, and the latency of the request (the amount of time it takes for the I/O operation to complete). Latency is the true end-to-end client time of an I/O operation; in other words, when the client sends a IO, how long does it take to get an acknowledgement from the storage subsystem that the IO read or write is complete. If your I/O latency is higher than you require, check your average queue length to make sure that your application is not trying to drive more IOPS than you have provisioned. You can maintain high IOPS while keeping latency down by maintaining a low average queue length (which is achieved by provisioning more IOPS for your volume). Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-workload-demand.html",,,,
