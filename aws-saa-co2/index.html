
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta name="description" content="">
  <meta name="author" content="">
  <title id="PageTitle"></title>

  <!-- Bootstrap core CSS 
      <link href="https://getbootstrap.com/docs/4.1/dist/css/bootstrap.min.css" rel="stylesheet">
  -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
  <!-- Custom styles -->
  <style type="text/css" media="all">
    .container { max-width: 960px; }
    .lh-condensed { line-height: 1.25; }
    .pager-left { margin:5px 0 5px; color:#999; text-align:left; font-size: 14px; }
    .pager-right { margin:5px 0 5px; color:#999; text-align:right; font-size: 14px; }
    .pager-right select { border: 1px solid #ccc; color:#999; }
    .pager-left-button { margin-right:10px; text-align:left; font-size: 12px; }
    .pager-right-button { margin-left:10px; text-align:right; font-size: 12px; }
    .question { margin:5px 0 5px; font-size: 12px; }
    .explaination { margin:10px 5px 0 5px; }
    .explaination h2 { margin: 5px 0px 5px 0px; text-align:right; font-size: 14px; color:#999; }
    .explaination p { padding: 5px 7px 5px 7px; font-size: 12px; border: 1px solid #ccc; }
    img.question-image { width:100%; height:auto; display:block; max-width:80%; margin:10px auto; border:1px solid #ccc; }
    input[type=number] {
      width: 50px;
      border: 1px solid #ccc;
    }
    /*
    .darkmode--activated p, 
    .darkmode--activated span, 
    .darkmode--activated label, 
    .darkmode--activated h2,
    .darkmode--activated hr,
    */
    .darkmode--activated h3 , .lead { 
      color: #222; }
    .darkmode--activated .container { 
      color: #ccc; }
    .darkmode--activated .jumbotron { background-color: #3b3b3b; }
  </style>

<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>
<script>
  function addDarkmodeWidget() {
    const options = {
      bottom: '32px', // default: '32px'
      right: '32px', // default: '32px'
      left: 'unset', // default: 'unset'
      time: '0.5s', // default: '0.3s'
      mixColor: '#fff', // default: '#fff'
      backgroundColor: '#f8f9fa', // default: '#fff'
      buttonColorDark: '#222', // default: '#100f2c'
      buttonColorLight: '#fff', // default: '#fff'
      saveInCookies: false, // default: true,
      label: 'ðŸŒ“', // default: ''
      //label: 'mode', // default: ''
      autoMatchOsTheme: true // default: true
    }

    const darkmode = new Darkmode(options);
    darkmode.showWidget();

    //new Darkmode().showWidget();
  }
  window.addEventListener('load', addDarkmodeWidget);
</script>

<!-- JS quiz variables - start -->
<script>
var Quiz = {
  "QuizCode": "SAA-C02",
  "QuizTitle": "Exam Practice ( SAA-C02 )",
  "QuizDescription": "AWS Certified Solutions Architect Associate",
  "QuizQuestions": [
    {
      "id": "1",
      "question": "A solutions architect is designing a new service behind Amazon API Gateway. The request patterns for the service will be unpredictable and can change suddenly from 0 requests to over 500 per second. The total size of the data that needs to be persisted in a backend database is currently less than 1 GBwith unpredictable future growth Data can be queried using simple key-value requests.Which combination of AWS services would meet these requirements'? (Select TWO )",
      "image": "",
      "explaination": "",
      "correct": [
        "B",
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "AWS Fargate"
        },
        {
          "id": "B",
          "text": "AWS Lambda"
        },
        {
          "id": "C",
          "text": "Amazon DynamoDB"
        },
        {
          "id": "D",
          "text": "Amazon EC2 Auto Scaling"
        },
        {
          "id": "E",
          "text": "MySQL-compatible Amazon Aurora"
        }
      ]
    },
    {
      "id": "2",
      "question": "A solutions architect needs to design a managed storage solution for a company's application that includes high-performance machine learning, Thisapplication runs on AWS Fargate and the connected storage needs to have concurrent access to files and deliver high performance.Which storage option should the solutions architect recommend?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create an Amazon S3 bucket for the application and establish an IAM role for Fargate to communicate with Amazon S3."
        },
        {
          "id": "B",
          "text": "Create an Amazon FSx for Lustre file share and establish an IAM role that allows Fargate to communicate with FSx for Lustre."
        },
        {
          "id": "C",
          "text": "Create an Amazon Elastic File System (Amazon EFS) file share and establish an IAM role that allows Fargate to communicate with Amazon EFS."
        },
        {
          "id": "D",
          "text": "Create an Amazon Elastic Block Store (Amazon EBS) volume for the application and establish an IAM role that allows Fargate to communicate with"
        }
      ]
    },
    {
      "id": "3",
      "question": "A company has a multi-tier application that runs six front-end web servers in an Amazon EC2 Auto Scaling group in a single Availability Zone behind anApplication Load Balancer (ALB). A solutions architect needs to modify the infrastructure to be highly available without modifying the application.Which architecture should the solutions architect choose that provides high availability?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create an Auto Scaling group that uses three instances across each of two Regions"
        },
        {
          "id": "B",
          "text": "Modify the Auto Scaling group to use three instances across each of two Availability Zones"
        },
        {
          "id": "C",
          "text": "Create an Auto Scaling template that can be used to quickly create more instances in another Region"
        },
        {
          "id": "D",
          "text": "Change the ALB in front of the Amazon EC2 instances in a round-robin configuration to balance traffic to the web tier"
        }
      ]
    },
    {
      "id": "4",
      "question": "A company runs an internal browser-based application The application runs on Amazon EC2 instances behind an Application Load Balancer. Theinstances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. The Auto Scaling group scales up to 20 instances during workhours, but scales down to 2 instances overnight Staff are complaining that the application is very slow when the day begins, although it runs well by mid-morning.How should the scaling be changed to address the staff complaints and keep costs to a minimum?",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/autoscaling/ec2/userguide/asg-purchase-options.html",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Implement a scheduled action that sets the desired capacity to 20 shortly before the office opens"
        },
        {
          "id": "B",
          "text": "Implement a step scaling action triggered at a lower CPU threshold, and decrease the cooldown period"
        },
        {
          "id": "C",
          "text": "Implement a target tracking action triggered at a lower CPU threshold and decrease the cooldown period"
        },
        {
          "id": "D",
          "text": "Implement a scheduled action that sets the minimum and maximum capacity to 20 shortly before the office opens"
        }
      ]
    },
    {
      "id": "5",
      "question": "A solutions architect is designing a solution to access a catalog of images and provide users with the ability to submit requests to customize images.Image customization parameters will be in any request sent to an AWS API Gateway API. The customized image will be generated on demand, andusers will receive a link they can click to view or download their customized image. The solution must be highly available for viewing and customizingimagesWhat is the MOST cost-effective solution to meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon EC2 instances to manipulate the original image into the requested customization.Store the original and manipulated images in Amazon S3.Configure an Elastic Load Balancer in front of the EC2 instances."
        },
        {
          "id": "B",
          "text": "Use AWS Lambda to manipulate the original image to the requested customization.Store the original and manipulated images in Amazon S3.Configure an Amazon CloudFront distribution with the S3 bucket as the ongin."
        },
        {
          "id": "C",
          "text": "Use AWS Lambda to manipulate the original image to the requested customization.Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB.Configure an Elastic Load Balancer in front of the Amazon EC2 instances."
        },
        {
          "id": "D",
          "text": "Use Amazon EC2 instances to manipulate the original image into the requested customization.Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB.Configure an Amazon CloudFront distribution with the S3 bucket as the origin."
        }
      ]
    },
    {
      "id": "6",
      "question": "A bicycle sharing company is developing a multi-tier architecture to track the location of its bicycles during peak operating hours. The company wants touse these data points in its existing analytics platform A solutions architect must determine the most viable multi-tier option to support this architecture.The data points must be accessible from the REST API.Which action meets these requirements for storing and retrieving location data?",
      "image": "",
      "explaination": "https://aws.amazon.com/kinesis/data-analytics/",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon Athena with Amazon S3"
        },
        {
          "id": "B",
          "text": "Use Amazon API Gateway with AWS Lambda"
        },
        {
          "id": "C",
          "text": "Use Amazon QuickSight with Amazon Redshift"
        },
        {
          "id": "D",
          "text": "Use Amazon API Gateway with Amazon Kinesis Data Analytics"
        }
      ]
    },
    {
      "id": "7",
      "question": "A solutions architect is deploying a distributed database on multiple Amazon EC2 instances. The database stores all data on multiple instances so it canwithstand the loss of an instance. The database requires block storage with latency and throughput to support several million transactions per secondper server.Which storage solution should the solutions architect use?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon EBS"
        },
        {
          "id": "B",
          "text": "Amazon EC2 instance store"
        },
        {
          "id": "C",
          "text": "Amazon EFS"
        },
        {
          "id": "D",
          "text": "Amazon S3"
        }
      ]
    },
    {
      "id": "8",
      "question": "A solutions architect needs to ensure that API calls to Amazon DynamoDB from Amazon EC2 instances in a VPC do not traverse the internet.What should the solutions architect do to accomplish this? (Select TWO)",
      "image": "",
      "explaination": "",
      "correct": [
        "A",
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create a route table entry for the endpoint"
        },
        {
          "id": "B",
          "text": "Create a gateway endpoint for DynamoDB"
        },
        {
          "id": "C",
          "text": "Create a new DynamoDB table that uses the endpoint"
        },
        {
          "id": "D",
          "text": "Create an ENI for the endpoint in each of the subnets of the VPC"
        },
        {
          "id": "E",
          "text": "Create a security group entry in the default security group to provide access"
        }
      ]
    },
    {
      "id": "9",
      "question": "A solutions architect is designing a web application that will run on Amazon EC2 instances behind an Application Load Balancer (ALB). The companystrictly requires that the application be resilient against malicious internet activity and attacks, and protect against new common vulnerabilities andexposures.What should the solutions architect recommend?",
      "image": "",
      "explaination": "https://d1.awsstatic.com/whitepapers/Security/DDoS_White_Paper.pdf",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Leverage Amazon CloudFront with the ALB endpoint as the origin"
        },
        {
          "id": "B",
          "text": "Deploy an appropriate managed rule for AWS WAF and associate it with the ALB"
        },
        {
          "id": "C",
          "text": "Subscribe to AWS Shield Advanced and ensure common vulnerabilities and exposures are blocked"
        },
        {
          "id": "D",
          "text": "Configure network ACLs and security groups to allow only ports 80 and 443 to access the EC2 instances"
        }
      ]
    },
    {
      "id": "10",
      "question": "A company has been storing analytics data in an Amazon RDS instance for the past few years. The company asked a solutions architect to find asolution that allows users to access this data using an API. The expectation is that the application will experience periods of inactivity but could receivebursts of traffic within seconds.Which solution should the solutions architect suggest?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Set up an Amazon API Gateway and use Amazon ECS."
        },
        {
          "id": "B",
          "text": "Set up an Amazon API Gateway and use AWS Elastic Beanstalk."
        },
        {
          "id": "C",
          "text": "Set up an Amazon API Gateway and use AWS Lambda functions"
        },
        {
          "id": "D",
          "text": "Set up an Amazon API Gateway and use Amazon EC2 with Auto Scaling"
        }
      ]
    },
    {
      "id": "11",
      "question": "A company's web application is using multiple Linux Amazon EC2 instances and storing data on Amazon EBS volumes. The company is looking for asolution to increase the resiliency of the application in case of a failure and to provide storage that complies with atomicity, consistency, isolation, anddurability (ACID).What should a solutions architect do to meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Launch the application on EC2 instances in each Availability Zone.Attach EBS volumes to each EC2 instance."
        },
        {
          "id": "B",
          "text": "Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones.Mount an instance store on each EC2 instance."
        },
        {
          "id": "C",
          "text": "Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones.Store data on Amazon EFS and mount a target on each instance."
        },
        {
          "id": "D",
          "text": "Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones.Store data using Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA)."
        }
      ]
    },
    {
      "id": "12",
      "question": "A company has an application that calls AWS Lambda functions. A recent code review found database credentials stored in the source code. Thedatabase credentials need to be removed from the Lambda source code. The credentials must then be securely stored and rotated on an ongoing basisto meet security policy requirements.What should a solutions architect recommend to meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Store the password in AWS CloudHSM.Associate the Lambda function with a role that can retrieve the password from CloudHSM given its key ID."
        },
        {
          "id": "B",
          "text": "Store the password in AWS Secrets Manager.Associate the Lambda function with a role that can retrieve the password from Secrets Manager given its secret ID."
        },
        {
          "id": "C",
          "text": "Move the database password to an environment variable associated with the Lambda function.Retrieve the password from the environment variable upon execution."
        },
        {
          "id": "D",
          "text": "Store the password in AWS Key Management Service (AWS KMS).Associate the Lambda function with a role that can retrieve the password from AWS KMS given its key ID."
        }
      ]
    },
    {
      "id": "13",
      "question": "A solutions architect needs the static website within an Amazon S3 bucket.Which action will accomplish this?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Enable Amazon S3 versioning"
        },
        {
          "id": "B",
          "text": "Enable Amazon S3 Intelligent-Tiering."
        },
        {
          "id": "C",
          "text": "Enable an Amazon S3 lifecycle policy"
        },
        {
          "id": "D",
          "text": "Enable Amazon S3 cross-Region replication."
        }
      ]
    },
    {
      "id": "14",
      "question": "A company is managing health records on-premises. The company must keep these records indefinitely, disable any modifications to the records oncethey are stored, and granularly audit access at all levels. The chief technology officer (CTO) is concerned because there are already millions of recordsnot being used by any application, and the current infrastructure is running out of space. The CTO has requested a solutions architect design a solutionto move existing data and support future records.Which services can the solutions architect recommend to meet these requirements'?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use AWS DataSync to move existing data to AWS.Use Amazon S3 to store existing and new data.Enable Amazon S3 object lock and enable AWS CloudTrail with data events."
        },
        {
          "id": "B",
          "text": "Use AWS Storage Gateway to move existing data to AWS.Use Amazon S3 to store existing and new data.Enable Amazon S3 object lock and enable AWS CloudTrail with management events."
        },
        {
          "id": "C",
          "text": "Use AWS DataSync to move existing data to AWS.Use Amazon S3 to store existing and new data.Enable Amazon S3 object lock and enable AWS CloudTrail with management events."
        },
        {
          "id": "D",
          "text": "Use AWS Storage Gateway to move existing data to AWS.Use Amazon Elastic Block Store (Amazon EBS) to store existing and new data.Enable Amazon S3 object lock and enable Amazon S3 server access logging."
        }
      ]
    },
    {
      "id": "15",
      "question": "A company currently operates a web application backed by an Amazon RDS MySQL database. It has automated backups that are run daily and are notencrypted. A security audit requires future backups to be encrypted and the unencrypted backups to be destroyed. The company will make at least oneencrypted backup before destroying the old backups.What should be done to enable encryption for future backups?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Enable default encryption for the Amazon S3 bucket where backups are stored"
        },
        {
          "id": "B",
          "text": "Modify the backup section of the database configuration to toggle the Enable encryption check box."
        },
        {
          "id": "C",
          "text": "Create a snapshot of the database.Copy it to an encrypted snapshot.Restore the database from the encrypted snapshot."
        },
        {
          "id": "D",
          "text": "Enable an encrypted read replica on RDS for MySQL.Promote the encrypted read replica to primary.Remove the original database instance."
        }
      ]
    },
    {
      "id": "16",
      "question": "A client reports that they want see an audit log of any changes made to AWS resources in their account.What can the client do to achieve this?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Set up Amazon CloudWatch monitors on services they own"
        },
        {
          "id": "B",
          "text": "Enable AWS CloudTrail logs to be delivered to an Amazon S3 bucket"
        },
        {
          "id": "C",
          "text": "Use Amazon CloudWatch Events to parse logs"
        },
        {
          "id": "D",
          "text": "Use AWS OpsWorks to manage their resources"
        }
      ]
    },
    {
      "id": "17",
      "question": "An application running in a private subnet accesses an Amazon DynamoDB table. There is a security requirement that the data never leave the AWSnetwork.How should this requirement be met?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure a network ACL on DynamoDB to limit traffic to the private subnet"
        },
        {
          "id": "B",
          "text": "Enable DynamoDB encryption at rest using an AWS KMS key"
        },
        {
          "id": "C",
          "text": "Add a NAT gateway and configure the route table on the private subnet"
        },
        {
          "id": "D",
          "text": "Create a VPC endpoint for DynamoDB and configure the endpoint policy"
        }
      ]
    },
    {
      "id": "18",
      "question": "A three-tier application is being created to host small news articles. The application is expected to serve millions of users. When breaking news occurs,the site must handle very large spikes in traffic without significantly impacting database performance.Which design meets these requirements while minimizing costs?",
      "image": "",
      "explaination": "DAX has in memory cache. If breaking news happens, majority of the users searching will look for the exact same thing. That being said, requests willquery the Memory Cache first and will not need to fetch the data from the DB directly.",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Auto Scaling groups to increase the number of Amazon EC2 instances delivering the web application"
        },
        {
          "id": "B",
          "text": "Use Auto Scaling groups to increase the size of the Amazon RDS instances delivering the database"
        },
        {
          "id": "C",
          "text": "Use Amazon DynamoDB strongly consistent reads to adjust for the increase in traffic"
        },
        {
          "id": "D",
          "text": "Use Amazon DynamoDB Accelerator (DAX) to cache read operations to the database"
        }
      ]
    },
    {
      "id": "19",
      "question": "During a review of business applications, a Solutions Architect identifies a critical application with a relational database that was built by a business userand is running on the user's desktop. To reduce the risk of a business interruption, the Solutions Architect wants to migrate the application to a highlyavailable, multi-tiered solution in AWS.What should the Solutions Architect do to accomplish this with the LEAST amount of disruption to the business?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create an import package of the application code for upload to AWS Lambda, and include a function to create another Lambda function to migrate data into an Amazon RDS database"
        },
        {
          "id": "B",
          "text": "Create an image of the user's desktop, migrate it to Amazon EC2 using VM Import, and place the EC2 instance in an Auto Scaling group"
        },
        {
          "id": "C",
          "text": "Pre-stage new Amazon EC2 instances running the application code on AWS behind an Application Load Balancer and an Amazon RDS Multi-AZ DB instance"
        },
        {
          "id": "D",
          "text": "Use AWS DMS to migrate the backend database to an Amazon RDS Multi-AZ DB instance.Migrate the application code to AWS Elastic Beanstalk"
        }
      ]
    },
    {
      "id": "20",
      "question": "A company has thousands of files stored in an Amazon S3 bucket that has a well-defined access pattern. The files are accessed by an applicationmultiple times a day for the first 30 days. Files are rarely accessed within the next 90 days. After that, the files are never accessed again. During the first120 days, accessing these files should never take more than a few seconds.Which lifecycle policy should be used for the S3 objects to minimize costs based on the access pattern?",
      "image": "",
      "explaination": "It is mentioned that they need to access data in few seconds during the 120 days.",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon S3 Standard-Infrequent Access (S3 Standard-IA) storage for the first 30 days. Then move the files to the GLACIER storage class for the next 90 days. Allow the data to expire after that."
        },
        {
          "id": "B",
          "text": "Use Amazon S3 Standard storage for the first 30 days. Then move the files to Amazon S3 Standard- Infrequent Access (S3 Standard-IA) for the next 90 days. Allow the data to expire after that."
        },
        {
          "id": "C",
          "text": "Use Amazon S3 Standard storage for first 30 days. Then move the files to the GLACIER storage class for the next 90 days. Allow the data to expire after that."
        },
        {
          "id": "D",
          "text": "Use Amazon S3 Standard-Infrequent Access (S3 Standard-IA) for the first 30 days. After that, move the data to the GLACIER storage class, where is will be deleted automatically."
        }
      ]
    },
    {
      "id": "21",
      "question": "A company creates business-critical 3D images every night. The images are batch-processed every Friday and require an uninterrupted 48 hours tocomplete.What is the MOST cost-effective Amazon EC2 pricing model for this scenario?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "On-Demand Instances"
        },
        {
          "id": "B",
          "text": "Scheduled Reserved Instances"
        },
        {
          "id": "C",
          "text": "Reserved Instances"
        },
        {
          "id": "D",
          "text": "Spot Instances"
        }
      ]
    },
    {
      "id": "22",
      "question": "An application generates audit logs of operational activities. Compliance requirements mandate that the application retain the logs for 5 years. How can these requirements be met?",
      "image": "",
      "explaination": "Amazon Glacier, which enables long-term storage of mission-critical data, has added Vault Lock. This new feature allows you to lock your vault with a variety of compliance controls that are designed to support such long-term records retention.",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Save the logs in an Amazon S3 bucket and enable Multi-Factor Authentication Delete (MFA Delete) on the bucket."
        },
        {
          "id": "B",
          "text": "Save the logs in an Amazon EFS volume and use Network File System version 4 (NFSv4) locking with the volume."
        },
        {
          "id": "C",
          "text": "Save the logs in an Amazon Glacier vault and use the Vault Lock feature."
        },
        {
          "id": "D",
          "text": "Save the logs in an Amazon EBS volume and take monthly snapshots."
        }
      ]
    },
    {
      "id": "23",
      "question": "A Solutions Architect is creating an application running in an Amazon VPC that needs to access AWS Systems Manager Parameter Store. Networksecurity rules prohibit any route table entry with a 0.0.0.0/0 destination.What infrastructure addition will allow access to the AWS service while meeting the requirements?",
      "image": "",
      "explaination": "You can privately access AWS Systems Manager APIs from your VPC (created using Amazon Virtual Private Cloud) by creating VPC Endpoints. With VPC Endpoints, the routing between the VPC and AWS Systems Manager is handled by the AWS network without the need for an internet gateway, NAT gateway, or VPN connection. The latest generation of VPC Endpoints used by AWS Systems Manager are powered by AWS PrivateLink, a technology that enables private connectivity between AWS services using Elastic Network Interfaces (ENIs) with private IP addresses in your VPCs. To learn more about PrivateLink, visit the PrivateLink documentation. https://docs.aws.amazon.com/vpc/latest/userguide/vpce-interface.html",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "VPC peering"
        },
        {
          "id": "B",
          "text": "NAT instance"
        },
        {
          "id": "C",
          "text": "NAT gateway"
        },
        {
          "id": "D",
          "text": "AWS PrivateLink"
        }
      ]
    },
    {
      "id": "24",
      "question": "A photo-sharing website running on AWS allows users to generate thumbnail images of photos stored in Amazon S3. An Amazon DynamoDB table maintains the locations of photos, and thumbnails are easily re- created from the originals if they are accidentally deleted. How should the thumbnail images be stored to ensure the LOWEST cost?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon S3 Standard-Infrequent Access (S3 Standard-IA) with cross-region replication"
        },
        {
          "id": "B",
          "text": "Amazon S3"
        },
        {
          "id": "C",
          "text": "Amazon Glacier"
        },
        {
          "id": "D",
          "text": "Amazon S3 with cross-region replication"
        }
      ]
    },
    {
      "id": "25",
      "question": "A company is implementing a data lake solution on Amazon S3. Its security policy mandates that the data stored in Amazon S3 should be encrypted at rest. Which options can achieve this? (Select TWO.)",
      "image": "",
      "explaination": "",
      "correct": [
        "B",
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use S3 server-side encryption with an Amazon EC2 key pair."
        },
        {
          "id": "B",
          "text": "Use S3 server-side encryption with customer-provided keys (SSE-C)."
        },
        {
          "id": "C",
          "text": "Use S3 bucket policies to restrict access to the data at rest."
        },
        {
          "id": "D",
          "text": "Use client-side encryption before ingesting the data to Amazon S3 using encryption keys."
        },
        {
          "id": "E",
          "text": "Use SSL to encrypt the data while in transit to Amazon S3."
        }
      ]
    },
    {
      "id": "26",
      "question": "A solutions architect has created a new AWS account and must secure AWS account root user access. Which combination of actions will accomplish this? (Select TWO.)",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/IAM/latest/UserGuide/id_root-user.html",
      "correct": [
        "A",
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Ensure the root user uses a strong password"
        },
        {
          "id": "B",
          "text": "Enable multi-factor authentication to the root user"
        },
        {
          "id": "C",
          "text": "Store root user access keys in an encrypted Amazon S3 bucket"
        },
        {
          "id": "D",
          "text": "Add the root user to a group containing administrative permissions."
        },
        {
          "id": "E",
          "text": "Apply the required permissions to the root user with an inline policy document"
        }
      ]
    },
    {
      "id": "27",
      "question": "A company's application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. On the first day of every month at midnight the application becomes much slower when the month-end financial calculation batch executes. This causes the CPU utilization of the EC2 instances to immediately peak to 100% which disrupts the application. What should a solutions architect recommend to ensure the application is able to handle the workload and avoid downtime?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure an Amazon CloudFront distribution in front of the ALB"
        },
        {
          "id": "B",
          "text": "Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization"
        },
        {
          "id": "C",
          "text": "Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule."
        },
        {
          "id": "D",
          "text": "Configure Amazon ElastiCache to remove some of the workload from the EC2 instances"
        }
      ]
    },
    {
      "id": "28",
      "question": "A company is migrating from an on-premises infrastructure to the AWS Cloud. One of the company's applications stores files on a Windows file server farm that uses Distributed File System Replication (DFSR) to keep data in sync. A solutions architect needs to replace the file server farm. Which service should the solutions architect use?",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/fsx/latest/WindowsGuide/migrate-files-to-fsx-datasync.html",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon EFS"
        },
        {
          "id": "B",
          "text": "Amazon FSx"
        },
        {
          "id": "C",
          "text": "Amazon S3"
        },
        {
          "id": "D",
          "text": "AWS Storage Gateway"
        }
      ]
    },
    {
      "id": "29",
      "question": "A company's website is used to sell products to the public. The site runs on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB). There is also an Amazon CloudFront distribution and AWS WAF is being used to protect against SQL injection attacks. The ALB is the origin for the CloudFront distribution. A recent review of security logs revealed an external malicious IP that needs to be blocked from accessing the website. What should a solutions architect do to protect the application?",
      "image": "",
      "explaination": "https://aws.amazon.com/blogs/aws/aws-web-application-firewall-waf-for-application-loadbalancers",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Modify the network ACL on the CloudFront distribution to add a deny rule for the malicious IP address"
        },
        {
          "id": "B",
          "text": "Modify the configuration of AWS WAF to add an IP match condition to block the malicious IP address"
        },
        {
          "id": "C",
          "text": "Modify the network ACL for the EC2 instances in the target groups behind the ALB to deny the malicious IP address"
        },
        {
          "id": "D",
          "text": "Modify the security groups for the EC2 instances in the target groups behind the ALB to deny the malicious IP address"
        }
      ]
    },
    {
      "id": "30",
      "question": "A marketing company is storing CSV files in an Amazon S3 bucket for statistical analysis. An application on an Amazon EC2 instance needs permission to efficiently process the CSV data stored in the S3 bucket. Which action will MOST securely grant the EC2 instance access to the S3 bucket?",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Target.S3.html",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Attach a resource-based policy to the S3 bucket"
        },
        {
          "id": "B",
          "text": "Create an IAM user for the application with specific permissions to the S3 bucket"
        },
        {
          "id": "C",
          "text": "Associate an IAM role with least privilege permissions to the EC2 instance profile"
        },
        {
          "id": "D",
          "text": "Store AWS credentials directly on the EC2 instance for applications on the instance to use for API calls"
        }
      ]
    },
    {
      "id": "31",
      "question": "A solutions architect is designing a solution where users will De directed to a backup static error page it the primary website is unavailable. The primary website's DNS records are hosted in Amazon Route 53 where their domain is pointing to an Application Load Balancer (ALB). Which configuration should the solutions architect use to meet the company's needs while minimizing changes and infrastructure overhead?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Point a Route 53 alias record to an Amazon CloudFront distribution with the ALB as one of its origins. Then, create custom error pages for the distribution. "
        },
        {
          "id": "B",
          "text": "Set up a Route 53 active-passive failover configuration. Direct traffic to a static error page hosted within an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy. "
        },
        {
          "id": "C",
          "text": "Update the Route 53 record to use a latency-based routing policy. Add the backup static error page hosted within an Amazon S3 bucket to the record so the traffic is sent to the most responsive endpoints. "
        },
        {
          "id": "D",
          "text": "Set up a Route 53 active-active configuration with the ALB and an Amazon EC2 instance hosting a static error page as endpoints. Route 53 will only send requests to the instance if the health checks fail for the ALB. "
        }
      ]
    },
    {
      "id": "32",
      "question": "A solutions architect is designing the cloud architecture for a new application being deployed on AWS. The process should run in parallel while adding and removing application nodes as needed based on the number of jobs to be processed. The processor application is stateless. The solutions architect must ensure that the application is loosely coupled and the job items are durably stored. Which design should the solutions architect use?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on CPU usage"
        },
        {
          "id": "B",
          "text": "Create an Amazon SQS queue to hold the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch configuration that uses the AMI. Create an Auto Scaling group using the launch configuration. Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage"
        },
        {
          "id": "C",
          "text": "Create an Amazon SQS queue to hold the jobs that needs to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue"
        },
        {
          "id": "D",
          "text": "Create an Amazon SNS topic to send the jobs that need to be processed. Create an Amazon Machine Image (AMI) that consists of the processor application. Create a launch template that uses the AMI. Create an Auto Scaling group using the launch template. Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic."
        }
      ]
    },
    {
      "id": "33",
      "question": "A company has a legacy application that processes data in two parts. The second part of the process takes longer than the first, so the company has decided to rewrite the application as two microservices running on Amazon ECS that can scale independently. How should a solutions architect integrate the microservices?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Implement code in microservice 1 to send data to an Amazon S3 bucket. Use S3 event notifications to invoke microservice 2."
        },
        {
          "id": "B",
          "text": "Implement code in microservice 1 to publish data to an Amazon SNS topic. Implement code in microservice 2 to subscribe to this topic."
        },
        {
          "id": "C",
          "text": "Implement code in microservice 1 to send data to Amazon Kinesis Data Firehose. Implement code in microservice 2 to read from Kinesis Data Firehose."
        },
        {
          "id": "D",
          "text": "Implement code in microservice 1 to send data to an Amazon SQS queue. Implement code in microservice 2 to process messages from the queue."
        }
      ]
    },
    {
      "id": "34",
      "question": "A solutions architect at an ecommerce company wants to back up application log data to Amazon S3. The solutions architect is unsure how frequently the logs will be accessed or which logs will be accessed the most. The company wants to keep costs as low as possible by using the appropriate S3 storage class. Which S3 storage class should be implemented to meet these requirements?",
      "image": "",
      "explaination": "S3 One Zone-IA is for data that is accessed less frequently, but requires rapid access when needed. Unlike other S3 Storage Classes which store data in a minimum of three Availability Zones (AZs), S3 One Zone-IA stores data in a single AZ and costs 20% less than S3 Standard-IA. S3 One Zone-IA is ideal for customers who want a lower-cost option for infrequently accessed data but do not require the availability and resilience of S3 Standard or S3 Standard-IA. It's a good choice for storing secondary backup copies of on-premises data or easily re-creatable data. You can also use it as cost-effective storage for data that is replicated from another AWS Region using S3 Cross-Region Replication.",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "S3 Glacier"
        },
        {
          "id": "B",
          "text": "S3 Intelligent-Tiering"
        },
        {
          "id": "C",
          "text": "S3 Standard-Infrequent Access (S3 Standard-IA)"
        },
        {
          "id": "D",
          "text": "S3 One Zone-Infrequent Access (S3 One Zone-IA)"
        }
      ]
    },
    {
      "id": "35",
      "question": "A security team wants to limit access to specific services or actions in all of the team's AWS accounts. All accounts belong to a large organization in AWS Organizations. The solution must be scalable and there must be a single point where permissions can be maintained. What should a solutions architect do to accomplish this?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create an ACL to provide access to the services or actions."
        },
        {
          "id": "B",
          "text": "Create a security group to allow accounts and attach it to user groups"
        },
        {
          "id": "C",
          "text": "Create cross-account roles in each account to deny access to the services or actions."
        },
        {
          "id": "D",
          "text": "Create a service control policy in the root organizational unit to deny access to the services or actions"
        }
      ]
    },
    {
      "id": "36",
      "question": "You are trying to launch an EC2 instance, however the instance seems to go into a terminated status immediately. What would probably not be a reason that this is happening?",
      "image": "",
      "explaination": "Amazon EC2 provides a virtual computing environments, known as an instance. After you launch an instance, AWS recommends that you check its status to confirm that it goes from the pending status to the running status, the not terminated status. The following are a few reasons why an Amazon EBS-backed instance might immediately terminate: You've reached your volume limit. The AMI is missing a required part. The snapshot is corrupt. Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_InstanceStraightToTerminated.html",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "The AMI is missing a required part."
        },
        {
          "id": "B",
          "text": "The snapshot is corrupt."
        },
        {
          "id": "C",
          "text": "You need to create storage in EBS first."
        },
        {
          "id": "D",
          "text": "You've reached your volume limit."
        }
      ]
    },
    {
      "id": "37",
      "question": "You have set up an Auto Scaling group. The cool down period for the Auto Scaling group is 7 minutes. The first instance is launched after 3 minutes, while the second instance is launched after 4 minutes. How many minutes after the first instance is launched will Auto Scaling accept another scaling activity request?",
      "image": "",
      "explaination": "If an Auto Scaling group is launching more than one instance, the cool down period for each instance starts after that instance is launched. The group remains locked until the last instance that was launched has completed its cool down period. In this case the cool down period for the first instance starts after 3 minutes and finishes at the 10th minute (3+7 cool down), while for the second instance it starts at the 4th minute and finishes at the 11th minute (4+7 cool down). Thus, the Auto Scaling group will receive another request only after 11 minutes. Reference: http://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/AS_Concepts.html",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "11 minutes"
        },
        {
          "id": "B",
          "text": "7 minutes"
        },
        {
          "id": "C",
          "text": "10 minutes"
        },
        {
          "id": "D",
          "text": "14 minutes"
        }
      ]
    },
    {
      "id": "38",
      "question": "In Amazon EC2 Container Service components, what is the name of a logical grouping of container instances on which you can place tasks?",
      "image": "",
      "explaination": "Amazon ECS contains the following components: A Cluster is a logical grouping of container instances that you can place tasks on. A Container instance is an Amazon EC2 instance that is running the Amazon ECS agent and has been registered into a cluster. A Task definition is a description of an application that contains one or more container definitions. A Scheduler is the method used for placing tasks on container instances. A Service is an Amazon ECS service that allows you to run and maintain a specified number of instances of a task definition simultaneously. A Task is an instantiation of a task definition that is running on a container instance. A Container is a Linux container that was created as part of a task. Reference: http://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "A cluster"
        },
        {
          "id": "B",
          "text": "A container instance"
        },
        {
          "id": "C",
          "text": "A container"
        },
        {
          "id": "D",
          "text": "A task definition"
        }
      ]
    },
    {
      "id": "39",
      "question": "In the context of AWS support, why must an EC2 instance be unreachable for 20 minutes rather than allowing customers to open tickets immediately?",
      "image": "",
      "explaination": "An EC2 instance must be unreachable for 20 minutes before opening a ticket, because most reachability issues are resolved by automated processes in less than 20 minutes and will not require any action on the part of the customer. If the instance is still unreachable after this time frame has passed, then you should open a case with support. Reference: https://aws.amazon.com/premiumsupport/faqs/",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Because most reachability issues are resolved by automated processes in less than 20 minutes"
        },
        {
          "id": "B",
          "text": "Because all EC2 instances are unreachable for 20 minutes every day when AWS does routine maintenance"
        },
        {
          "id": "C",
          "text": "Because all EC2 instances are unreachable for 20 minutes when first launched"
        },
        {
          "id": "D",
          "text": "Because of all the reasons listed here"
        }
      ]
    },
    {
      "id": "40",
      "question": "Can a user get a notification of each instance start / terminate configured with Auto Scaling?",
      "image": "",
      "explaination": "The user can get notifications using SNS if he has configured the notifications while creating the Auto Scaling group. Reference: http://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/GettingStartedTutorial.html",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Yes, if configured with the Launch Config"
        },
        {
          "id": "B",
          "text": "Yes, always"
        },
        {
          "id": "C",
          "text": "Yes, if configured with the Auto Scaling group"
        },
        {
          "id": "D",
          "text": "No"
        }
      ]
    },
    {
      "id": "41",
      "question": "Amazon EBS provides the ability to create backups of any Amazon EC2 volume into what is known as _____.",
      "image": "",
      "explaination": "Amazon allows you to make backups of the data stored in your EBS volumes through snapshots that can later be used to create a new EBS volume. Reference: http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/Storage.html",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "snapshots"
        },
        {
          "id": "B",
          "text": "images"
        },
        {
          "id": "C",
          "text": "instance backups"
        },
        {
          "id": "D",
          "text": "mirrors"
        }
      ]
    },
    {
      "id": "42",
      "question": "To specify a resource in a policy statement, in Amazon EC2, can you use its Amazon Resource Name (ARN)?",
      "image": "",
      "explaination": "Some Amazon EC2 API actions allow you to include specific resources in your policy that can be created or modified by the action. To specify a resource in the statement, you need to use its Amazon Resource Name (ARN). Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-ug.pdf",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Yes, you can."
        },
        {
          "id": "B",
          "text": "No, you can't because EC2 is not related to ARN."
        },
        {
          "id": "C",
          "text": "No, you can't because you can't specify a particular Amazon EC2 resource in an IAM policy."
        },
        {
          "id": "D",
          "text": "Yes, you can but only for the resources that are not affected by the action."
        }
      ]
    },
    {
      "id": "43",
      "question": "After you recommend Amazon Redshift to a client as an alternative solution to paying data warehouses to analyze his data, your client asks you to explain why you are recommending Redshift. Which of the following would be a reasonable response to his request?",
      "image": "",
      "explaination": "Amazon Redshift delivers fast query performance by using columnar storage technology to improve I/O efficiency and parallelizing queries across multiple nodes. Redshift uses standard PostgreSQL JDBC and ODBC drivers, allowing you to use a wide range of familiar SQL clients. Data load speed scales linearly with cluster size, with integrations to Amazon S3, Amazon DynamoDB, Amazon Elastic MapReduce, Amazon Kinesis or any SSH- enabled host. AWS recommends Amazon Redshift for customers who have a combination of needs, such as: High performance at scale as data and query complexity grows Desire to prevent reporting and analytic processing from interfering with the performance of OLTP workloads Large volumes of structured data to persist and query using standard SQL and existing BI tools Desire to the administrative burden of running one's own data warehouse and dealing with setup, durability, monitoring, scaling and patching Reference: https://aws.amazon.com/running_databases/#redshift_anchor",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "It has high performance at scale as data and query complexity grows."
        },
        {
          "id": "B",
          "text": "It prevents reporting and analytic processing from interfering with the performance of OLTP workloads."
        },
        {
          "id": "C",
          "text": "You don't have the administrative burden of running your own data warehouse and dealing with setup, durability, monitoring, scaling, and patching."
        },
        {
          "id": "D",
          "text": "All answers listed are a reasonable response to his question"
        }
      ]
    },
    {
      "id": "44",
      "question": "One of the criteria for a new deployment is that the customer wants to use AWS Storage Gateway. However you are not sure whether you should use gateway-cached volumes or gateway-stored volumes or even what the differences are. Which statement below best describes those differences?",
      "image": "",
      "explaination": "Volume gateways provide cloud-backed storage volumes that you can mount as Internet Small Computer System Interface (iSCSI) devices from your on-premises application servers. The gateway supports the following volume configurations: Gateway-cached volumes ?You store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway-cached volumes offer a substantial cost savings on primary storage and minimize the need to scale your storage on- premises. You also retain low-latency access to your frequently accessed data. Gateway-stored volumes ?If you need low-latency access to your entire data set, you can configure your on- premises gateway to store all your data locally and then asynchronously back up point-in-time snapshots of this data to Amazon S3. This configuration provides durable and inexpensive off-site backups that you can recover to your local data center or Amazon EC2. For example, if you need replacement capacity for disaster recovery, you can recover the backups to Amazon EC2. Reference: http://docs.aws.amazon.com/storagegateway/latest/userguide/volume-gateway.html",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Gateway-cached lets you store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway-stored enables you to configure your on-premises gateway to store all your data locally and then asynchronously back up point-in-time snapshots of this data to Amazon S3."
        },
        {
          "id": "B",
          "text": "Gateway-cached is free whilst gateway-stored is not."
        },
        {
          "id": "C",
          "text": "Gateway-cached is up to 10 times faster than gateway-stored."
        },
        {
          "id": "D",
          "text": "Gateway-stored lets you store your data in Amazon Simple Storage Service (Amazon S3) and retain a copy of frequently accessed data subsets locally. Gateway-cached enables you to configure your on-premises gateway to store all your data locally and then asynchronously back up point-in-time"
        }
      ]
    },
    {
      "id": "45",
      "question": "A user is launching an EC2 instance in the US East region. Which of the below mentioned options is recommended by AWS with respect to the selection of the availability zone?",
      "image": "",
      "explaination": "When launching an instance with EC2, AWS recommends not to select the availability zone (AZ). AWS specifies that the default Availability Zone should be accepted. This is because it enables AWS to select the best Availability Zone based on the system health and available capacity. If the user launches additional instances, only then an Availability Zone should be specified. This is to specify the same or different AZ from the running instances. Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Always select the AZ while launching an instance"
        },
        {
          "id": "B",
          "text": "Always select the US-East-1-a zone for HA"
        },
        {
          "id": "C",
          "text": "Do not select the AZ; instead let AWS select the AZ"
        },
        {
          "id": "D",
          "text": "The user can never select the availability zone while launching an instance"
        }
      ]
    },
    {
      "id": "46",
      "question": "A company's website runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The website has a mix of dynamic and static content Users around the globe are reporting that the website is slow. Which set of actions will improve website performance for users worldwide?",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-cloudfrontdistribution.Html ",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create an Amazon CloudFront distribution and configure the ALB as an origin. Then update the Amazon Route 53 record to point to the CloudFront distribution."
        },
        {
          "id": "B",
          "text": "Create a latency-based Amazon Route 53 record for the ALB. Then launch new EC2 instances with larger instance sizes and register the instances with the ALB."
        },
        {
          "id": "C",
          "text": "Launch nev. EC2 instances hosting the same web application in different Regions closer to the users. Then register the instances with the same ALB using cross-Region VPC peering."
        },
        {
          "id": "D",
          "text": "Host the website in an Amazon S3 bucket in the Regions closest to the users and delete the ALB and EC2 instances. Then update an Amazon Route 53 record to point to the S3 buckets."
        }
      ]
    },
    {
      "id": "47",
      "question": "A company wants to migrate a high performance computing (HPC) application and data from on- premises to the AWS Cloud. The company uses tiered storage on premises with hot high-performance parallel storage to support the application during periodic runs of the application and more economical cold storage to hold the data when the application is not actively running. Which combination of solutions should a solutions architect recommend to support the storage needs of the application? (Select TWO )",
      "image": "",
      "explaination": "",
      "correct": [
        "A",
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon S3 for cold data storage"
        },
        {
          "id": "B",
          "text": "Amazon EFS for cold data storage"
        },
        {
          "id": "C",
          "text": "Amazon S3 for high-performance parallel storage"
        },
        {
          "id": "D",
          "text": "Amazon FSx for Lustre for high-performance parallel storage"
        },
        {
          "id": "E",
          "text": "Amazon FSx for Windows for high-performance parallel storage"
        }
      ]
    },
    {
      "id": "48",
      "question": "A company has on-premises servers running a relational database. The current database serves high read traffic for users in different locations. The company wants to migrate to AWS with the least amount of effort. The database solution should support disaster recovery and not affect the company's current traffic flow. Which solution meets these requirements?",
      "image": "",
      "explaination": "https://aws.amazon.com/blogs/database/implementing-a-disaster-recovery-strategy-with-amazon-rds/",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use a database in Amazon RDS with Multi-AZ and at least one read replica"
        },
        {
          "id": "B",
          "text": "Use a database in Amazon RDS with Multi-AZ and at least one standby replica"
        },
        {
          "id": "C",
          "text": "Use databases hosted on multiple Amazon EC2 instances in different AWS Regions"
        },
        {
          "id": "D",
          "text": "Use databases hosted on Amazon EC2 instances behind an Application Load Balancer in different Availability Zones"
        }
      ]
    },
    {
      "id": "49",
      "question": "A media streaming company collects real-time data and stores it in a disk-optimized database system. The company is not getting the expected throughput and wants an in-memory database storage solution that performs faster and provides high availability using data replication. Which database should a solutions architect recommend'?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon RDS for MySQL"
        },
        {
          "id": "B",
          "text": "Amazon RDS for PostgreSQL"
        },
        {
          "id": "C",
          "text": "Amazon ElastiCache for Redis"
        },
        {
          "id": "D",
          "text": "Amazon ElastiCache for Memcached"
        }
      ]
    },
    {
      "id": "50",
      "question": "A company's application is running on Amazon EC2 instances within an Auto Scaling group behind an Elastic Load Balancer. Based on the application's history, the company anticipates a spike in traffic during a holiday each year. A solutions architect must design a strategy to ensure that the Auto Scaling group proactively increases capacity to minimize any performance impact on application users. Which solution will meet these requirements?",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-dg.pdf ",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create an Amazon CloudWatch alarm to scale up the EC2 instances when CPU utilization exceeds 90%"
        },
        {
          "id": "B",
          "text": "Create a recurring scheduled action to scale up the Auto Scaling group before the expected period of peak demand"
        },
        {
          "id": "C",
          "text": "Increase the minimum and maximum number of EC2 instances in the Auto Scaling group during the peak demand period"
        },
        {
          "id": "D",
          "text": "Configure an Amazon Simple Notification Service (Amazon SNS) notification to send alerts when there are auto scaling EC2_INSTANCE_LAUNCH events"
        }
      ]
    },
    {
      "id": "51",
      "question": "A company has a two-tier application architecture that runs in public and private subnets Amazon EC2 instances running the web application are in the public subnet and a database runs on the private subnet. The web application instances and the database are running in a single Availability Zone (AZ). Which combination of steps should a solutions architect take to provide high availability for this architecture? (Select TWO.)",
      "image": "",
      "explaination": "You would the EC2 instances to have high availability by placing them in multiple AZs.",
      "correct": [
        "B",
        "E"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create new public and private subnets in the same AZ for high availability"
        },
        {
          "id": "B",
          "text": "Create an Amazon EC2 Auto Scaling group and Application Load Balancer spanning multiple AZs"
        },
        {
          "id": "C",
          "text": "Add the existing web application instances to an Auto Scaling group behind an Application Load Balancer"
        },
        {
          "id": "D",
          "text": "Create new public and private subnets in a new AZ Create a database using Amazon EC2 in one AZ"
        },
        {
          "id": "E",
          "text": "Create new public and private subnets in the same VPC each in a new AZ Migrate the database to an Amazon RDS multi-AZ deployment"
        }
      ]
    },
    {
      "id": "52",
      "question": "A financial services company has a web application that serves users in the United States and Europe. The application consists of a database tier and a web server tier. The database tier consists of a MySQL database hosted in us-east-1 Amazon Route 53 geoproximity routing is used to direct traffic to instances in the closest Region. A performance review of the system reveals that European users are not receiving the same level of query performance as those in the United States. Which changes should be made to the database tier to improve performance?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Migrate the database to Amazon RDS for MySQL. Configure Multi-AZ in one of the European Regions. "
        },
        {
          "id": "B",
          "text": "Migrate the database to Amazon DynamoDB. Use DynamoDB global tables to enable replication to additional Regions. "
        },
        {
          "id": "C",
          "text": "Deploy MySQL instances in each Region. Deploy an Application Load Balancer in front of MySQL to reduce the load on the primary instance. "
        },
        {
          "id": "D",
          "text": "Migrate the database to an Amazon Aurora global database in MySQL compatibility mode. Configure read replicas in one of the European Regions. "
        }
      ]
    },
    {
      "id": "53",
      "question": "A solutions architect is tasked with transferring 750 TB of data from a network-attached file system located at a branch office to Amazon S3 Glacier. The solution must avoid saturating the branch office's low-bandwidth internet connection. What is the MOST cost-effective solution1?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create a site-to-site VPN tunnel to an Amazon S3 bucket and transfer the files directly. Create a bucket policy to enforce a VPC endpoint."
        },
        {
          "id": "B",
          "text": "Order 10 AWS Snowball appliances and select an S3 Glacier vault as the destination. Create a bucket policy to enforce a VPC endpoint."
        },
        {
          "id": "C",
          "text": "Mount the network-attached file system to Amazon S3 and copy the files directly. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier."
        },
        {
          "id": "D",
          "text": "Order 10 AWS Snowball appliances and select an Amazon S3 bucket as the destination. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier."
        }
      ]
    },
    {
      "id": "54",
      "question": "A company's production application runs online transaction processing (OLTP) transactions on an Amazon RDS MySQL DB instance. The company is launching a new reporting tool that will access the same data. The reporting tool must be highly available and not impact the performance of the production application. How can this be achieved'?",
      "image": "",
      "explaination": "https://aws.amazon.com/blogs/database/best-storage-practices-for-running-production-workloadson- hosted-databases-with-amazon-rds-or-amazon- ec2/ ",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create hourly snapshots of the production RDS DB instance. "
        },
        {
          "id": "B",
          "text": "Create a Multi-AZ RDS Read Replica of the production RDS DB instance. "
        },
        {
          "id": "C",
          "text": "Create multiple RDS Read Replicas of the production RDS DB instance. Place the Read Replicas in an Auto Scaling group. "
        },
        {
          "id": "D",
          "text": "Create a Single-AZ RDS Read Replica of the production RDS DB instance. Create a second Single-AZ RDS Read Replica from the replica. "
        }
      ]
    },
    {
      "id": "55",
      "question": "A company allows its developers to attach existing IAM policies to existing IAM roles to enable faster experimentation and agility. However the security operations team is concerned that the developers could attach the existing administrator policy, which would allow the developers to circumvent any other security policies. How should a solutions architect address this issue?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create an Amazon SNS topic to send an alert every time a developer creates a new policy"
        },
        {
          "id": "B",
          "text": "Use service control policies to disable IAM activity across all accounts in the organizational unit"
        },
        {
          "id": "C",
          "text": "Prevent the developers from attaching any policies and assign all IAM duties to the security operations team"
        },
        {
          "id": "D",
          "text": "Set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy"
        }
      ]
    },
    {
      "id": "56",
      "question": "A user is storing a large number of objects on AWS S3. The user wants to implement the search functionality among the objects. How can the user achieve this?",
      "image": "",
      "explaination": "In Amazon Web Services, AWS S3 does not provide any query facility. To retrieve a specific object the user needs to know the exact bucket / object key. In this case it is recommended to have an own DB system which manages the S3 metadata and key mapping. Reference: http://media.amazonwebservices.com/AWS_Storage_Options.pdf",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use the indexing feature of S3."
        },
        {
          "id": "B",
          "text": "Tag the objects with the metadata to search on that."
        },
        {
          "id": "C",
          "text": "Use the query functionality of S3."
        },
        {
          "id": "D",
          "text": "Make your own DB system which stores the S3 metadata for the search functionality."
        }
      ]
    },
    {
      "id": "57",
      "question": "After setting up a Virtual Private Cloud (VPC) network, a more experienced cloud engineer suggests that to achieve low network latency and high network throughput you should look into setting up a placement group. You know nothing about this, but begin to do some research about it and are especially curious about its limitations. Which of the below statements is wrong in describing the limitations of a placement group?",
      "image": "",
      "explaination": "A placement group is a logical grouping of instances within a single Availability Zone. Using placement groups enables applications to participate in a low-latency, 10 Gbps network. Placement groups are recommended for applications that benefit from low network latency, high network throughput, or both. To provide the lowest latency, and the highest packet-per-second network performance for your placement group, choose an instance type that supports enhanced networking. Placement groups have the following limitations: The name you specify for a placement group a name must be unique within your AWS account. A placement group can't span multiple Availability Zones. Although launching multiple instance types into a placement group is possible, this reduces the likelihood that the required capacity will be available for your launch to succeed. We recommend using the same instance type for all instances in a placement group. You can't merge placement groups. Instead, you must terminate the instances in one placement group, and then relaunch those instances into the other placement group. A placement group can span peered VPCs; however, you will not get full- bisection bandwidth between instances in peered VPCs. For more information about VPC peering connections, see VPC Peering in the Amazon VPC User Guide. You can't move an existing instance into a placement group. You can create an AMI from your existing instance, and then launch a new instance from the AMI into a placement group. Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Although launching multiple instance types into a placement group is possible, this reduces the likelihood that the required capacity will be available for your launch to succeed."
        },
        {
          "id": "B",
          "text": "A placement group can span multiple Availability Zones."
        },
        {
          "id": "C",
          "text": "You can't move an existing instance into a placement group."
        },
        {
          "id": "D",
          "text": "A placement group can span peered VPCs"
        }
      ]
    },
    {
      "id": "58",
      "question": "What is a placement group in Amazon EC2?",
      "image": "",
      "explaination": "A placement group is a logical grouping of instances within a single Availability Zone. Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "It is a group of EC2 instances within a single Availability Zone."
        },
        {
          "id": "B",
          "text": "It the edge location of your web content."
        },
        {
          "id": "C",
          "text": "It is the AWS region where you run the EC2 instance of your web content."
        },
        {
          "id": "D",
          "text": "It is a group used to span multiple Availability Zones."
        }
      ]
    },
    {
      "id": "59",
      "question": "You are migrating an internal server on your DC to an EC2 instance with EBS volume. Your server disk usage is around 500GB so you just copied all your data to a 2TB disk to be used with AWS Import/Export. Where will the data be imported once it arrives at Amazon?",
      "image": "",
      "explaination": "An import to Amazon EBS will have different results depending on whether the capacity of your storage device is less than or equal to 1 TB or greater than 1 TB. The maximum size of an Amazon EBS snapshot is 1 TB, so if the device image is larger than 1 TB, the image is chunked and stored on Amazon S3. The target location is determined based on the total capacity of the device, not the amount of data on the device. Reference: http://docs.aws.amazon.com/AWSImportExport/latest/DG/Concepts.html",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "to a 2TB EBS volume"
        },
        {
          "id": "B",
          "text": "to an S3 bucket with 2 objects of 1TB"
        },
        {
          "id": "C",
          "text": "to an 500GB EBS volume"
        },
        {
          "id": "D",
          "text": "to an S3 bucket as a 2TB snapshot"
        }
      ]
    },
    {
      "id": "60",
      "question": "A client needs you to import some existing infrastructure from a dedicated hosting provider to AWS to try and save on the cost of running his current website. He also needs an automated process that manages backups, software patching, automatic failure detection, and recovery. You are aware that his existing set up currently uses an Oracle database. Which of the following AWS databases would be best for accomplishing this task?",
      "image": "",
      "explaination": "Amazon RDS gives you access to the capabilities of a familiar MySQL, Oracle, SQL Server, or PostgreSQL database engine. This means that the code, applications, and tools you already use today with your existing databases can be used with Amazon RDS. Amazon RDS automatically patches the database software and backs up your database, storing the backups for a user- defined retention period and enabling point-in-time recovery. Reference: http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon RDS"
        },
        {
          "id": "B",
          "text": "Amazon Redshift"
        },
        {
          "id": "C",
          "text": "Amazon SimpleDB"
        },
        {
          "id": "D",
          "text": "Amazon ElastiCache"
        }
      ]
    },
    {
      "id": "61",
      "question": "True or false: A VPC contains multiple subnets, where each subnet can span multiple Availability Zones.",
      "image": "",
      "explaination": "A VPC can span several Availability Zones. In contrast, a subnet must reside within a single Availability Zone. Reference: https://aws.amazon.com/vpc/faqs/",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "This is true only if requested during the set-up of VPC."
        },
        {
          "id": "B",
          "text": "This is true."
        },
        {
          "id": "C",
          "text": "This is false."
        },
        {
          "id": "D",
          "text": "This is true only for US regions."
        }
      ]
    },
    {
      "id": "62",
      "question": "An edge location refers to which Amazon Web Service?",
      "image": "",
      "explaination": "Amazon CloudFront is a content distribution network. A content delivery network or content distribution network (CDN) is a large distributed system of servers deployed in multiple data centers across the world. The location of the data center used for CDN is called edge location. Amazon CloudFront can cache static content at each edge location. This means that your popular static content (e.g., your site's logo, navigational images, cascading style sheets, JavaScript code, etc.) will be available at a nearby edge location for the browsers to download with low latency and improved performance for viewers. Caching popular static content with Amazon CloudFront also helps you offload requests for such files from your origin sever - CloudFront serves the cached copy when available and only makes a request to your origin server if the edge location receiving the browser's request does not have a copy of the file. Reference: http://aws.amazon.com/cloudfront/",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "An edge location is refered to the network configured within a Zone or Region"
        },
        {
          "id": "B",
          "text": "An edge location is an AWS Region"
        },
        {
          "id": "C",
          "text": "An edge location is the location of the data center used for Amazon CloudFront."
        },
        {
          "id": "D",
          "text": "An edge location is a Zone within an AWS Region"
        }
      ]
    },
    {
      "id": "63",
      "question": "You are looking at ways to improve some existing infrastructure as it seems a lot of engineering resources are being taken up with basic management and monitoring tasks and the costs seem to be excessive. You are thinking of deploying Amazon ElasticCache to help. Which of the following statements is true in regards to ElasticCache?",
      "image": "",
      "explaination": "Amazon ElastiCache is a web service that makes it easy to deploy and run Memcached or Redis protocol-compliant server nodes in the cloud. Amazon ElastiCache improves the performance of web applications by allowing you to retrieve information from a fast, managed, in-memory caching system, instead of relying entirely on slower disk-based databases. The service simplifies and offloads the management, monitoring and operation of in-memory cache environments, enabling your engineering resources to focus on developing applications. Using Amazon ElastiCache, you can not only improve load and response times to user actions and queries, but also reduce the cost associated with scaling web applications. Reference: https://aws.amazon.com/elasticache/faqs/",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "You can improve load and response times to user actions and queries however the cost associated with scaling web applications will be more."
        },
        {
          "id": "B",
          "text": "You can't improve load and response times to user actions and queries but you can reduce the cost associated with scaling web applications."
        },
        {
          "id": "C",
          "text": "You can improve load and response times to user actions and queries however the cost associated with scaling web applications will remain the same."
        },
        {
          "id": "D",
          "text": "You can improve load and response times to user actions and queries and also reduce the cost associated with scaling web applications."
        }
      ]
    },
    {
      "id": "64",
      "question": "Do Amazon EBS volumes persist independently from the running life of an Amazon EC2 instance?",
      "image": "",
      "explaination": "An Amazon EBS volume behaves like a raw, unformatted, external block device that you can attach to a single instance. The volume persists independently from the running life of an Amazon EC2 instance. Reference: http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/Storage.html",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Yes, they do but only if they are detached from the instance."
        },
        {
          "id": "B",
          "text": "No, you cannot attach EBS volumes to an instance."
        },
        {
          "id": "C",
          "text": "No, they are dependent."
        },
        {
          "id": "D",
          "text": "Yes, they do."
        }
      ]
    },
    {
      "id": "65",
      "question": "Your supervisor has asked you to build a simple file synchronization service for your department. He doesn't want to spend too much money and he wants to be notified of any changes to files by email. What do you think would be the best Amazon service to use for the email solution?",
      "image": "",
      "explaination": "File change notifications can be sent via email to users following the resource with Amazon Simple Email Service (Amazon SES), an easy-to-use, cost- effective email solution. Reference: http://media.amazonwebservices.com/architecturecenter/AWS_ac_ra_filesync_08.pdf",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon SES"
        },
        {
          "id": "B",
          "text": "Amazon CloudSearch"
        },
        {
          "id": "C",
          "text": "Amazon SWF"
        },
        {
          "id": "D",
          "text": "Amazon AppStream"
        }
      ]
    },
    {
      "id": "66",
      "question": "A product team is creating a new application that will store a large amount of data. The data will be analyzed hourly and modified by multiple Amazon EC2 Linux instances.The application team believes the amount of space needed will continue to grow for the next 6 months. Which set of actions should a solutions architect take to support these needs'?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Store the data in an Amazon EBS volume. Mount the EBS volume on the application instances"
        },
        {
          "id": "B",
          "text": "Store the data in an Amazon EFS file system. Mount the file system on the application instances."
        },
        {
          "id": "C",
          "text": "Store the data in Amazon S3 Glacier. Update the vault policy to allow access to the application instances."
        },
        {
          "id": "D",
          "text": "Store the data in Amazon S3 Standard-Infrequent Access (S3 Standard-IA). Update the bucket policy to allow access to the application instances."
        }
      ]
    },
    {
      "id": "67",
      "question": "A gaming company has multiple Amazon EC2 instances in a single Availability Zone for its multiplayer game that communicates with users on Layer 4. The chief technology officer (CTO) wants to make the architecture highly available and cost-effective. What should a solutions architect do to meet these requirements? (Select TWO.)",
      "image": "",
      "explaination": "",
      "correct": [
        "C",
        "E"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Increase the number of EC2 instances."
        },
        {
          "id": "B",
          "text": "Decrease the number of EC2 instances"
        },
        {
          "id": "C",
          "text": "Configure a Network Load Balancer in front of the EC2 instances."
        },
        {
          "id": "D",
          "text": "Configure an Application Load Balancer in front of the EC2 instances"
        },
        {
          "id": "E",
          "text": "Configure an Auto Scaling group to add or remove instances in multiple Availability Zones automatically."
        }
      ]
    },
    {
      "id": "68",
      "question": "A company hosts an application on multiple Amazon EC2 instances. The application processes messages from an Amazon SQS queue writes to an Amazon RDS table and deletes the message from the queue Occasional duplicate records are found in the RDS table. The SQS queue does not contain any duplicate messages. What should a solutions archived do to ensure messages are being processed once only?",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html#FIFO-queues-exactly-once-processing ",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use the CreateQueue API call to create a new queue"
        },
        {
          "id": "B",
          "text": "Use the AddPermission API call to add appropriate permissions"
        },
        {
          "id": "C",
          "text": "Use the ReceiveMessage API call to set an appropriate wait time."
        },
        {
          "id": "D",
          "text": "Use the ChangeMessageVisibility API call to increase the visibility timeout"
        }
      ]
    },
    {
      "id": "69",
      "question": "A solutions architect is designing an application for a two-step order process. The first step is synchronous and must return to the user with little latency. The second step takes longer, so it will be implemented in a separate component Orders must be processed exactly once and in the order in which they are received. How should the solutions architect integrate these components?",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFOqueues.Html",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon SQS FIFO queues."
        },
        {
          "id": "B",
          "text": "Use an AWS Lambda function along with Amazon SQS standard queues"
        },
        {
          "id": "C",
          "text": "Create an SNS topic and subscribe an Amazon SQS FIFO queue to that topic"
        },
        {
          "id": "D",
          "text": "Create an SNS topic and subscribe an Amazon SQS Standard queue to that topic."
        }
      ]
    },
    {
      "id": "70",
      "question": "A solutions architect is designing a high performance computing (HPC) workload on Amazon EC2. The EC2 instances need to communicate to each other frequently and require network performance with low latency and high throughput. Which EC2 configuration meets these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Launch the EC2 instances in a cluster placement group in one Availability Zone"
        },
        {
          "id": "B",
          "text": "Launch the EC2 instances in a spread placement group in one Availability Zone"
        },
        {
          "id": "C",
          "text": "Launch the EC2 instances in an Auto Scaling group in two Regions and peer the VPCs"
        },
        {
          "id": "D",
          "text": "Launch the EC2 instances in an Auto Scaling group spanning multiple Availability Zones"
        }
      ]
    },
    {
      "id": "71",
      "question": "A company is planning to use Amazon S3 lo store images uploaded by its users. The images must be encrypted at rest in Amazon S3. The company does not want to spend time managing and rotating the keys, but it does want to control who can access those keys. What should a solutions architect use to accomplish this?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Server-Side Encryption with keys stored in an S3 bucket"
        },
        {
          "id": "B",
          "text": "Server-Side Encryption with Customer-Provided Keys (SSE-C)"
        },
        {
          "id": "C",
          "text": "Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)"
        },
        {
          "id": "D",
          "text": "Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS)"
        }
      ]
    },
    {
      "id": "72",
      "question": "An Amazon EC2 administrator created the following policy associated with an IAM group containing several users. What is the effect of this policy?",
      "image": "img/question-72.png",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Users can terminate an EC2 instance in any AWS Region except us-east-1."
        },
        {
          "id": "B",
          "text": "Users can terminate an EC2 instance with the IP address 10.100. 1001 in the us-east-1 Region."
        },
        {
          "id": "C",
          "text": "Users can terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254."
        },
        {
          "id": "D",
          "text": "Users cannot terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254."
        }
      ]
    },
    {
      "id": "73",
      "question": "A company is running an ecommerce application on Amazon EC2. The application consists of a stateless web tier that requires a minimum of 10 instances, and a peak of 250 instances to support the application's usage. The application requires 50 instances 80% of the time. Which solution should be used to minimize costs?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Purchase Reserved Instances to cover 250 instances "
        },
        {
          "id": "B",
          "text": "Purchase Reserved Instances to cover 80 instances. Use Spot Instances to cover the remaining instances "
        },
        {
          "id": "C",
          "text": "Purchase On-Demand Instances to cover 40 instances. Use Spot Instances to cover the remaining instances "
        },
        {
          "id": "D",
          "text": "Purchase Reserved Instances to cover 50 instances. Use On-Demand and Spot Instances to cover the remaining instances "
        }
      ]
    },
    {
      "id": "74",
      "question": "Does DynamoDB support in-place atomic updates?",
      "image": "",
      "explaination": "DynamoDB supports in-place atomic updates.",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Yes"
        },
        {
          "id": "B",
          "text": "No"
        },
        {
          "id": "C",
          "text": "It does support in-place non-atomic updates"
        },
        {
          "id": "D",
          "text": "It is not defined"
        }
      ]
    },
    {
      "id": "75",
      "question": "Your manager has just given you access to multiple VPN connections that someone else has recently set up between all your company's offices. She needs you to make sure that the communication between the VPNs is secure. Which of the following services would be best for providing a low-cost hub-and-spoke model for primary or backup connectivity between these remote offices?",
      "image": "",
      "explaination": "If you have multiple VPN connections, you can provide secure communication between sites using the AWS VPN CloudHub. The VPN CloudHub operates on a simple hub-and-spoke model that you can use with or without a VPC. This design is suitable for customers with multiple branch offices and existing Internet connections who would like to implement a convenient, potentially low-cost hub-and-spoke model for primary or backup connectivity between these remote offices. Reference: http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPN_CloudHub.html",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon CloudFront"
        },
        {
          "id": "B",
          "text": "AWS Direct Connect"
        },
        {
          "id": "C",
          "text": "AWS CloudHSM"
        },
        {
          "id": "D",
          "text": "AWS VPN CloudHub"
        }
      ]
    },
    {
      "id": "76",
      "question": "Amazon EC2 provides a ____. It is an HTTP or HTTPS request that uses the HTTP verbs GET or POST.",
      "image": "",
      "explaination": "Amazon EC2 provides a Query API. These requests are HTTP or HTTPS requests that use the HTTP verbs GET or POST and a Query parameter named Action. Reference: http://docs.aws.amazon.com/AWSEC2/latest/APIReference/making-api-requests.html ",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "web database"
        },
        {
          "id": "B",
          "text": ".net framework"
        },
        {
          "id": "C",
          "text": "Query API"
        },
        {
          "id": "D",
          "text": "C library"
        }
      ]
    },
    {
      "id": "77",
      "question": "In Amazon AWS, which of the following statements is true of key pairs?",
      "image": "",
      "explaination": "Key pairs consist of a public and private key, where you use the private key to create a digital signature, and then AWS uses the corresponding public key to validate the signature. Key pairs are used only for Amazon EC2 and Amazon CloudFront. Reference: http://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Key pairs are used only for Amazon SDKs."
        },
        {
          "id": "B",
          "text": "Key pairs are used only for Amazon EC2 and Amazon CloudFront."
        },
        {
          "id": "C",
          "text": "Key pairs are used only for Elastic Load Balancing and AWS IAM."
        },
        {
          "id": "D",
          "text": "Key pairs are used for all Amazon services."
        }
      ]
    },
    {
      "id": "78",
      "question": "Does Amazon DynamoDB support both increment and decrement atomic operations?",
      "image": "",
      "explaination": "Amazon DynamoDB supports increment and decrement atomic operations. Reference: http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/APISummary.html",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Only increment, since decrement are inherently impossible with DynamoDB's data model."
        },
        {
          "id": "B",
          "text": "No, neither increment nor decrement operations."
        },
        {
          "id": "C",
          "text": "Yes, both increment and decrement operations."
        },
        {
          "id": "D",
          "text": "Only decrement, since increment are inherently impossible with DynamoDB's data model."
        }
      ]
    },
    {
      "id": "79",
      "question": "An organization has three separate AWS accounts, one each for development, testing, and production. The organization wants the testing team to have access to certain AWS resources in the production account. How can the organization achieve this?",
      "image": "",
      "explaination": "An organization has multiple AWS accounts to isolate a development environment from a testing or production environment. At times the users from one account need to access resources in the other account, such as promoting an update from the development environment to the production environment. In this case the IAM role with cross account access will provide a solution. Cross account access lets one account share access to their resources with users in the other AWS accounts. Reference: http://media.amazonwebservices.com/AWS_Security_Best_Practices.pdf",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "It is not possible to access resources of one account with another account."
        },
        {
          "id": "B",
          "text": "Create the IAM roles with cross account access."
        },
        {
          "id": "C",
          "text": "Create the IAM user in a test account, and allow it access to the production environment with the IAM policy."
        },
        {
          "id": "D",
          "text": "Create the IAM users with cross account access."
        }
      ]
    },
    {
      "id": "80",
      "question": "You need to import several hundred megabytes of data from a local Oracle database to an Amazon RDS DB instance. What does AWS recommend you use to accomplish this?",
      "image": "",
      "explaination": "How you import data into an Amazon RDS DB instance depends on the amount of data you have and the number and variety of database objects in your database. For example, you can use Oracle SQL Developer to import a simple, 20 MB database; you want to use Oracle Data Pump to import complex databases or databases that are several hundred megabytes or several terabytes in size. Reference: http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Oracle.Procedural.Importing.html",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Oracle export/import utilities"
        },
        {
          "id": "B",
          "text": "Oracle SQL Developer"
        },
        {
          "id": "C",
          "text": "Oracle Data Pump"
        },
        {
          "id": "D",
          "text": "DBMS_FILE_TRANSFER"
        }
      ]
    },
    {
      "id": "81",
      "question": "A user has created an EBS volume with 1000 IOPS. What is the average IOPS that the user will get for most of the year as per EC2 SLA if the instance is attached to the EBS optimized instance?",
      "image": "",
      "explaination": "As per AWS SLA if the instance is attached to an EBS-Optimized instance, then the Provisioned IOPS volumes are designed to deliver within 10% of the provisioned IOPS performance 99.9% of the time in a given year. Thus, if the user has created a volume of 1000 IOPS, the user will get a minimum 900 IOPS 99.9% time of the year. Reference: http://aws.amazon.com/ec2/faqs/",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "950"
        },
        {
          "id": "B",
          "text": "990"
        },
        {
          "id": "C",
          "text": "1000"
        },
        {
          "id": "D",
          "text": "900"
        }
      ]
    },
    {
      "id": "82",
      "question": "You need to migrate a large amount of data into the cloud that you have stored on a hard disk and you decide that the best way to accomplish this is with AWS Import/Export and you mail the hard disk to AWS. Which of the following statements is incorrect in regards to AWS Import/Export?",
      "image": "",
      "explaination": "AWS Import/Export supports: Import to Amazon S3 Export from Amazon S3 Import to Amazon EBS Import to Amazon Glacier AWS Import/Export does not currently support export from Amazon EBS or Amazon Glacier. Reference: https://docs.aws.amazon.com/AWSImportExport/latest/DG/whatisdisk.html",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "It can export from Amazon S3"
        },
        {
          "id": "B",
          "text": "It can Import to Amazon Glacier"
        },
        {
          "id": "C",
          "text": "It can export from Amazon Glacier."
        },
        {
          "id": "D",
          "text": "It can Import to Amazon EBS"
        }
      ]
    },
    {
      "id": "83",
      "question": "You are in the process of creating a Route 53 DNS failover to direct traffic to two EC2 zones. Obviously, if one fails, you would like Route 53 to direct traffic to the other region. Each region has an ELB with some instances being distributed. What is the best way for you to configure the Route 53 health check?",
      "image": "",
      "explaination": "With DNS Failover, Amazon Route 53 can help detect an outage of your website and redirect your end users to alternate locations where your application is operating properly. When you enable this feature, Route 53 uses health checks--regularly making Internet requests to your application's endpoints from multiple locations around the world--to determine whether each endpoint of your application is up or down. To enable DNS Failover for an ELB endpoint, create an Alias record pointing to the ELB and set the \"Evaluate Target Health\" parameter to true. Route 53 creates and manages the health checks for your ELB automatically. You do not need to create your own Route 53 health check of the ELB. You also do not need to associate your resource record set for the ELB with your own health check, because Route 53 automatically associates it with the health checks that Route 53 manages on your behalf. The ELB health check will also inherit the health of your backend instances behind that ELB. Reference: http://aws.amazon.com/about-aws/whats-new/2013/05/30/amazon-route-53-adds-elb- integration-for-dns- failover/",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Route 53 doesn't support ELB with an internal health check.You need to create your own Route 53 health check of the ELB"
        },
        {
          "id": "B",
          "text": "Route 53 natively supports ELB with an internal health check. Turn \"Evaluate target health\" off and \"Associate with Health Check\" on and R53 will use the ELB's internal health check."
        },
        {
          "id": "C",
          "text": "Route 53 doesn't support ELB with an internal health check. You need to associate your resource record set for the ELB with your own health check"
        },
        {
          "id": "D",
          "text": "Route 53 natively supports ELB with an internal health check. Turn \"Evaluate target health\" on and \"Associate with Health Check\" off and R53 will use the ELB's internal health check."
        }
      ]
    },
    {
      "id": "84",
      "question": "A user wants to use an EBS-backed Amazon EC2 instance for a temporary job. Based on the input data, the job is most likely to finish within a week. Which of the following steps should be followed to terminate the instance automatically once the job is finished?",
      "image": "",
      "explaination": "Auto Scaling can start and stop the instance at a pre-defined time. Here, the total running time is unknown. Thus, the user has to use the CloudWatch alarm, which monitors the CPU utilization. The user can create an alarm that is triggered when the average CPU utilization percentage has been lower than 10 percent for 24 hours, signaling that it is idle and no longer in use. When the utilization is below the threshold limit, it will terminate the instance as a part of the instance action. Reference: http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/UsingAlarmActions.html",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure the EC2 instance with a stop instance to terminate it."
        },
        {
          "id": "B",
          "text": "Configure the EC2 instance with ELB to terminate the instance when it remains idle."
        },
        {
          "id": "C",
          "text": "Configure the CloudWatch alarm on the instance that should perform the termination action once the instance is idle."
        },
        {
          "id": "D",
          "text": "Configure the Auto Scaling schedule activity that terminates the instance after 7 days."
        }
      ]
    },
    {
      "id": "85",
      "question": "Which of the following is true of Amazon EC2 security group?",
      "image": "",
      "explaination": "A security group acts as a virtual firewall that controls the traffic for one or more instances. When you launch an instance, you associate one or more security groups with the instance. You add rules to each security group that allow traffic to or from its associated instances. You can modify the rules for a security group at any time; the new rules are automatically applied to all instances that are associated with the security group. Reference: http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/using-network- security.html",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "You can modify the outbound rules for EC2-Classic."
        },
        {
          "id": "B",
          "text": "You can modify the rules for a security group only if the security group controls the traffic for just one instance."
        },
        {
          "id": "C",
          "text": "You can modify the rules for a security group only when a new instance is created."
        },
        {
          "id": "D",
          "text": "You can modify the rules for a security group at any time."
        }
      ]
    },
    {
      "id": "86",
      "question": "An Elastic IP address (EIP) is a static IP address designed for dynamic cloud computing. With an EIP, you can mask the failure of an instance or software by rapidly remapping the address to another instance in your account. Your EIP is associated with your AWS account, not a particular EC2 instance, and it remains associated with your account until you choose to explicitly release it. By default how many EIPs is each AWS account limited to on a per region basis?",
      "image": "",
      "explaination": "By default, all AWS accounts are limited to 5 Elastic IP addresses per region for each AWS account, because public (IPv4) Internet addresses are a scarce public resource. AWS strongly encourages you to use an EIP primarily for load balancing use cases, and use DNS hostnames for all other inter- node communication. If you feel your architecture warrants additional EIPs, you would need to complete the Amazon EC2 Elastic IP Address Request Form and give reasons as to your need for additional addresses. Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses- eip.html#using-instance-ad dressing-limit",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "1"
        },
        {
          "id": "B",
          "text": "5"
        },
        {
          "id": "C",
          "text": "Unlimited"
        },
        {
          "id": "D",
          "text": "10"
        }
      ]
    },
    {
      "id": "87",
      "question": "An application running on AWS uses an Amazon Aurora Multi-AZ deployment for its database. When evaluating performance metrics, a solutions architect discovered that the database reads are causing high I/O and adding latency to the write requests against the database. What should the solutions architect do to separate the read requests from the write requests?",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Enable read-through caching on the Amazon Aurora database"
        },
        {
          "id": "B",
          "text": "Update the application to read from the Multi-AZ standby instance"
        },
        {
          "id": "C",
          "text": "Create a read replica and modify the application to use the appropriate endpoint"
        },
        {
          "id": "D",
          "text": "Create a second Amazon Aurora database and link it to the primary database as a read replica."
        }
      ]
    },
    {
      "id": "88",
      "question": "An application runs on Amazon EC2 instances across multiple Availability Zones. The instances run in an Amazon EC2 Auto Scaling group behind an Application Load Balancer. The application performs best when the CPU utilization of the EC2 instances is at or near 40%. What should a solutions architect do to maintain the desired performance across all instances m the group?",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/autoscaling/application/userguide/application-auto-scalingscheduled-scaling.html",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use a simple scaling policy to dynamically scale the Auto Scaling group"
        },
        {
          "id": "B",
          "text": "Use a target tracking policy to dynamically scale the Auto Scaling group"
        },
        {
          "id": "C",
          "text": "Use an AWS Lambda function to update the desired Auto Scaling group capacity"
        },
        {
          "id": "D",
          "text": "Use scheduled scaling actions to scale up and scale down the Auto Scaling group"
        }
      ]
    },
    {
      "id": "89",
      "question": "A company runs a multi-tier web application that hosts news content. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones and use an Amazon Aurora database. A solutions architect needs to make the application more resilient to periodic increases in request rates. Which architecture should the solutions architect implement? (Select TWO )",
      "image": "",
      "explaination": "",
      "correct": [
        "D",
        "E"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Add AWS Shield."
        },
        {
          "id": "B",
          "text": "Add Aurora Replicas"
        },
        {
          "id": "C",
          "text": "Add AWS Direct Connect"
        },
        {
          "id": "D",
          "text": "Add AWS Global Accelerator."
        },
        {
          "id": "E",
          "text": "Add an Amazon CloudFront distribution in front of the Application Load Balancer"
        }
      ]
    },
    {
      "id": "90",
      "question": "A solutions architect is optimizing a website for an upcoming musical event Videos of the performances will be streamed in real time and then will be available on demand. The event is expected to attract a global online audience. Which service will improve the performance of both the real-time and on-demand streaming?",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/on-demand-streaming-video.html",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon CloudFront"
        },
        {
          "id": "B",
          "text": "AWS Global Accelerator"
        },
        {
          "id": "C",
          "text": "Amazon Route 53"
        },
        {
          "id": "D",
          "text": "Amazon S3 Transfer Acceleration"
        }
      ]
    },
    {
      "id": "91",
      "question": "A company serves content to its subscribers across the world using an application running on AWS. The application has several Amazon EC2 instances in a private subnet behind an Application Load Balancer (ALB). Due to a recent change in copyright restrictions the chief information officer (CIO) wants to block access for certain countries. Which action will meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Modify the ALB security group to deny incoming traffic from blocked countries"
        },
        {
          "id": "B",
          "text": "Modify the security group for EC2 instances to deny incoming traffic from blocked countries"
        },
        {
          "id": "C",
          "text": "Use Amazon CloudFront to serve the application and deny access to blocked countries"
        },
        {
          "id": "D",
          "text": "Use ALB listener rules to return access denied responses to incoming traffic from blocked countries"
        }
      ]
    },
    {
      "id": "92",
      "question": "A manufacturing company wants to implement predictive maintenance on its machinery equipment. The company will install thousands of loT sensors that will send data to AWS in real time. A solutions architect is tasked with implementing a solution that will receive events in an ordered manner for each machinery asset and ensure that data is saved for further processing at a later time. Which solution would be MOST efficient?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon Kinesis Data Streams for real-time events with a partition for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon S3."
        },
        {
          "id": "B",
          "text": "Use Amazon Kinesis Data Streams for real-time events with a shard for each equipment asset. Use Amazon Kinesis Data Firehose to save data to Amazon EBS."
        },
        {
          "id": "C",
          "text": "Use an Amazon SQS FIFO queue for real-time events with one queue for each equipment asset. Trigger an AWS Lambda function for the SQS queue to save data to Amazon EFS."
        },
        {
          "id": "D",
          "text": "Use an Amazon SQS standard queue for real-time events with one queue for each equipment asset. Trigger an AWS Lambda function from the SQS queue to save data to Amazon S3."
        }
      ]
    },
    {
      "id": "93",
      "question": "A company has deployed an API in a VPC behind an internet-facing Application Load Balancer (ALB). An application that consumes the API as a client is deployed in a second account in private subnets behind a NAT gateway. When requests to the client application increase, the NAT gateway costs are higher than expected. A solutions architect has configured the ALB to be internal. Which combination of architectural changes will reduce the NAT gateway costs'? (Select TWO )",
      "image": "",
      "explaination": "",
      "correct": [
        "D",
        "E"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure a VPC peering connection between the two VPCs. Access the API using the private address"
        },
        {
          "id": "B",
          "text": "Configure an AWS Direct Connect connection between the two VPCs. Access the API using the private address."
        },
        {
          "id": "C",
          "text": "Configure a ClassicLink connection for the API into the client VPC. Access the API using the ClassicLink address."
        },
        {
          "id": "D",
          "text": "Configure a PrivateLink connection for the API into the client VPC. Access the API using the PrivateLink address."
        },
        {
          "id": "E",
          "text": "Configure an AWS Resource Access Manager connection between the two accounts. Access the API using the private address"
        }
      ]
    },
    {
      "id": "94",
      "question": "In Amazon EC2, partial instance-hours are billed _____.",
      "image": "",
      "explaination": "Partial instance-hours are billed to the next hour. Reference: http://aws.amazon.com/ec2/faqs/",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "per second used in the hour"
        },
        {
          "id": "B",
          "text": "per minute used"
        },
        {
          "id": "C",
          "text": "by combining partial segments into full hours"
        },
        {
          "id": "D",
          "text": "as full hours"
        }
      ]
    },
    {
      "id": "95",
      "question": "In EC2, what happens to the data in an instance store if an instance reboots (either intentionally or unintentionally)?",
      "image": "",
      "explaination": "The data in an instance store persists only during the lifetime of its associated instance. If an instance reboots (intentionally or unintentionally), data in the instance store persists. However, data on instance store volumes is lost under the following circumstances. Failure of an underlying drive Stopping an Amazon EBS-backed instance Terminating an instance Reference: http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/InstanceStorage.html",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Data is deleted from the instance store for security reasons."
        },
        {
          "id": "B",
          "text": "Data persists in the instance store."
        },
        {
          "id": "C",
          "text": "Data is partially present in the instance store."
        },
        {
          "id": "D",
          "text": "Data in the instance store will be lost."
        }
      ]
    },
    {
      "id": "96",
      "question": "You are setting up a VPC and you need to set up a public subnet within that VPC. Which following requirement must be met for this subnet to be considered a public subnet?",
      "image": "",
      "explaination": "A virtual private cloud (VPC) is a virtual network dedicated to your AWS account. It is logically isolated from other virtual networks in the AWS cloud. You can launch your AWS resources, such as Amazon EC2 instances, into your VPC. You can configure your VPC: you can select its IP address range, create subnets, and configure route tables, network gateways, and security settings. A subnet is a range of IP addresses in your VPC. You can launch AWS resources into a subnet that you select. Use a public subnet for resources that must be connected to the internet, and a private subnet for resources that won't be connected to the Internet. If a subnet's traffic is routed to an internet gateway, the subnet is known as a public subnet. If a subnet doesn't have a route to the internet gateway, the subnet is known as a private subnet. If a subnet doesn't have a route to the internet gateway, but has its traffic routed to a virtual private gateway, the subnet is known as a VPN-only subnet. Reference: http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Subnet's traffic is not routed to an internet gateway but has its traffic routed to a virtual private gateway."
        },
        {
          "id": "B",
          "text": "Subnet's traffic is routed to an internet gateway."
        },
        {
          "id": "C",
          "text": "Subnet's traffic is not routed to an internet gateway."
        },
        {
          "id": "D",
          "text": "None of these answers can be considered a public subnet."
        }
      ]
    },
    {
      "id": "97",
      "question": "Can you specify the security group that you created for a VPC when you launch an instance in EC2-Classic?",
      "image": "",
      "explaination": "If you're using EC2-Classic, you must use security groups created specifically for EC2-Classic. When you launch an instance in EC2-Classic, you must specify a security group in the same region as the instance. You can't specify a security group that you created for a VPC when you launch an instance in EC2-Classic. Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-network-security.html#ec2-classic-securit y-groups",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "No, you can specify the security group created for EC2-Classic when you launch a VPC instance."
        },
        {
          "id": "B",
          "text": "No"
        },
        {
          "id": "C",
          "text": "Yes"
        },
        {
          "id": "D",
          "text": "No, you can specify the security group created for EC2-Classic to a non-VPC based instance only."
        }
      ]
    },
    {
      "id": "98",
      "question": "While using the EC2 GET requests as URLs, the _____ is the URL that serves as the entry point for the web service.",
      "image": "",
      "explaination": "The endpoint is the URL that serves as the entry point for the web service. Reference: http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/using-query-api.html",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "token"
        },
        {
          "id": "B",
          "text": "endpoint"
        },
        {
          "id": "C",
          "text": "action"
        },
        {
          "id": "D",
          "text": "None of these"
        }
      ]
    },
    {
      "id": "99",
      "question": "You have been asked to build a database warehouse using Amazon Redshift. You know a little about it, including that it is a SQL data warehouse solution, and uses industry standard ODBC and JDBC connections and PostgreSQL drivers. However you are not sure about what sort of storage it uses for database tables. What sort of storage does Amazon Redshift use for database tables?",
      "image": "",
      "explaination": "Amazon Redshift achieves efficient storage and optimum query performance through a combination of massively parallel processing, columnar data storage, and very efficient, targeted data compression encoding schemes. Columnar storage for database tables is an important factor in optimizing analytic query performance because it drastically reduces the overall disk I/O requirements and reduces the amount of data you need to load from disk. Reference: http://docs.aws.amazon.com/redshift/latest/dg/c_columnar_storage_disk_mem_mgmnt.html",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "InnoDB Tables"
        },
        {
          "id": "B",
          "text": "NDB data storage"
        },
        {
          "id": "C",
          "text": "Columnar data storage"
        },
        {
          "id": "D",
          "text": "NDB CLUSTER Storage"
        }
      ]
    },
    {
      "id": "100",
      "question": "You are checking the workload on some of your General Purpose (SSD) and Provisioned IOPS (SSD) volumes and it seems that the I/O latency is higher than you require. You should probably check the _____________ to make sure that your application is not trying to drive more IOPS than you have provisioned.",
      "image": "",
      "explaination": "In EBS workload demand plays an important role in getting the most out of your General Purpose (SSD) and Provisioned IOPS (SSD) volumes. In order for your volumes to deliver the amount of IOPS that are available, they need to have enough I/O requests sent to them. There is a relationship between the demand on the volumes, the amount of IOPS that are available to them, and the latency of the request (the amount of time it takes for the I/O operation to complete). Latency is the true end-to-end client time of an I/O operation; in other words, when the client sends a IO, how long does it take to get an acknowledgement from the storage subsystem that the IO read or write is complete. If your I/O latency is higher than you require, check your average queue length to make sure that your application is not trying to drive more IOPS than you have provisioned. You can maintain high IOPS while keeping latency down by maintaining a low average queue length (which is achieved by provisioning more IOPS for your volume). Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-workload-demand.html",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amount of IOPS that are available"
        },
        {
          "id": "B",
          "text": "Acknowledgement from the storage subsystem"
        },
        {
          "id": "C",
          "text": "Average queue length"
        },
        {
          "id": "D",
          "text": "Time it takes for the I/O operation to complete"
        }
      ]
    },
    {
      "id": "101",
      "question": "Which of the below mentioned options is not available when an instance is launched by Auto Scaling with EC2 Classic?",
      "image": "",
      "explaination": "Auto Scaling supports both EC2 classic and EC2-VPC. When an instance is launched as a part of EC2 classic, it will have the public IP and DNS as well as the private IP and DNS. Reference: http://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/GettingStartedTutorial.html",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Public IP"
        },
        {
          "id": "B",
          "text": "Elastic IP"
        },
        {
          "id": "C",
          "text": "Private DNS"
        },
        {
          "id": "D",
          "text": "Private IP"
        }
      ]
    },
    {
      "id": "102",
      "question": "You have been given a scope to deploy some AWS infrastructure for a large organisation. The requirements are that you will have a lot of EC2 instances but may need to add more when the average utilization of your Amazon EC2 fleet is high and conversely remove them when CPU utilization is low. Which AWS services would be best to use to accomplish this?",
      "image": "",
      "explaination": "Auto Scaling enables you to follow the demand curve for your applications closely, reducing the need to manually provision Amazon EC2 capacity in advance. For example, you can set a condition to add new Amazon EC2 instances in increments to the Auto Scaling group when the average utilization of your Amazon EC2 fleet is high; and similarly, you can set a condition to remove instances in the same increments when CPU utilization is low. If you have predictable load changes, you can set a schedule through Auto Scaling to plan your scaling activities. You can use Amazon CloudWatch to send alarms to trigger scaling activities and Elastic Load Balancing to help distribute traffic to your instances within Auto Scaling groups. Auto Scaling enables you to run your Amazon EC2 fleet at optimal utilization. Reference: http://aws.amazon.com/autoscaling/",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Auto Scaling, Amazon CloudWatch and AWS Elastic Beanstalk"
        },
        {
          "id": "B",
          "text": "Auto Scaling, Amazon CloudWatch and Elastic Load Balancing."
        },
        {
          "id": "C",
          "text": "Amazon CloudFront, Amazon CloudWatch and Elastic Load Balancing."
        },
        {
          "id": "D",
          "text": "AWS Elastic Beanstalk , Amazon CloudWatch and Elastic Load Balancing."
        }
      ]
    },
    {
      "id": "103",
      "question": "A company's legacy application is currently relying on a single-instance Amazon RDS MySQL database without encryption. Due to new compliance requirements, all existing and new data in this database must be encrypted. How should this be accomplished?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create an Amazon S3 bucket with server-side encryption enabled. Move all the data to Amazon S3 Delete the RDS instance."
        },
        {
          "id": "B",
          "text": "Enable RDS Multi-AZ mode with encryption at rest enabled. Perform a failover to the standby instance to delete the original instance."
        },
        {
          "id": "C",
          "text": "Take a snapshot of the RDS instance Create an encrypted copy of the snapshot. Restore the RDS instance from the encrypted snapshot."
        },
        {
          "id": "D",
          "text": "Create an RDS read replica with encryption at rest enabled. Promote the read replica to master and switch the application over to the new master Delete the old RDS instance."
        }
      ]
    },
    {
      "id": "104",
      "question": "A company has a three-tier image-sharing application it uses an Amazon EC2 instance for the front-end layer, another for the backend tier, and a third for the MySQL database. A solutions architect has been tasked with designing a solution that is highly available, and requires the least amount of changes to the application. Which solution meets these requirements'?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon S3 to host the front-end layer and AWS Lambda functions for the backend layer. Move the database to an Amazon DynamoDB table and use Amazon S3 to store and serve users' images."
        },
        {
          "id": "B",
          "text": "Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end and backend layers. Move the database to an Amazon RDS instance with multiple read replicas to store and serve users' images."
        },
        {
          "id": "C",
          "text": "Use Amazon S3 to host the front-end layer and a fleet of Amazon EC2 instances in an Auto Scaling group for the backend layer. Move the database to a memory optimized instance type to store and serve users' images."
        },
        {
          "id": "D",
          "text": "Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end and backend layers. Move the database to an Amazon RDS instance with a Multi-AZ deployment Use Amazon S3 to store and serve users' images."
        }
      ]
    },
    {
      "id": "105",
      "question": "A web application is deployed in the AWS Cloud It consists of a two-tier architecture that includes a web layer and a database layer. The web server is vulnerable to cross-site scripting (XSS) attacks. What should a solutions architect do to remediate the vulnerability?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create a Classic Load Balancer. Put the web layer behind the load balancer and enable AWS WAF."
        },
        {
          "id": "B",
          "text": "Create a Network Load Balancer. Put the web layer behind the load balancer and enable AWS WAF."
        },
        {
          "id": "C",
          "text": "Create an Application Load Balancer. Put the web layer behind the load balancer and enable AWS WAF."
        },
        {
          "id": "D",
          "text": "Create an Application Load Balancer. Put the web layer behind the load balancer and use AWS Shield Standard."
        }
      ]
    },
    {
      "id": "106",
      "question": "A recently acquired company is required to buikl its own infrastructure on AWS and migrate multiple applications to the cloud within a month. Each application has approximately 50 TB of data to be transferred. After the migration is complete this company and its parent company will both require secure network connectivity with consistent throughput from their data centers to the applications. A solutions architect must ensure one-time data migration and ongoing network connectivity. Which solution will meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "AWS Direct Connect for both the initial transfer and ongoing connectivity"
        },
        {
          "id": "B",
          "text": "AWS Site-to-Site VPN for both the initial transfer and ongoing connectivity"
        },
        {
          "id": "C",
          "text": "AWS Snowball for the initial transfer and AWS Direct Connect for ongoing connectivity"
        },
        {
          "id": "D",
          "text": "AWS Snowball for the initial transfer and AWS Site-to-Site VPN for ongoing connectivity"
        }
      ]
    },
    {
      "id": "107",
      "question": "Organizers for a global event want to put daily reports online as static HTML pages. The pages are expected to generate millions of views from users around the world The files are stored in an Amazon S3 bucket. A solutions architect has been asked to design an efficient and effective solution. Which action should the solutions architect take to accomplish this?",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3AndCustomOrigins.html",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Generate presigned URLs for the files"
        },
        {
          "id": "B",
          "text": "Use cross-Region replication to all Regions"
        },
        {
          "id": "C",
          "text": "Use the geoproximity feature of Amazon Route 53"
        },
        {
          "id": "D",
          "text": "Use Amazon CloudFront with the S3 bucket as its origin"
        }
      ]
    },
    {
      "id": "108",
      "question": "A company runs an application on a group of Amazon Linux EC2 instances, The application writes log files using standard API calls For compliance reasons, all log files must be retained indefinitely and will be analyzed by a reporting tool that must access all files concurrently. Which storage service should a solutions architect use to provide the MOST cost-effective solution?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon EBS"
        },
        {
          "id": "B",
          "text": "Amazon EFS"
        },
        {
          "id": "C",
          "text": "Amazon EC2 instance store"
        },
        {
          "id": "D",
          "text": "Amazon S3"
        }
      ]
    },
    {
      "id": "109",
      "question": "A company's application is running on Amazon EC2 instances m a single Region in the event of a disaster a solutions architect needs to ensure that the resources can also be deployed to a second Region. Which combination of actions should the solutions architect take to accomplish this-? (Select TWO)",
      "image": "",
      "explaination": "",
      "correct": [
        "B",
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Detach a volume on an EC2 instance and copy it to Amazon S3"
        },
        {
          "id": "B",
          "text": "Launch a new EC2 instance from an Amazon Machine image (AMI) in a new Region"
        },
        {
          "id": "C",
          "text": "Launch a new EC2 instance in a new Region and copy a volume from Amazon S3 to the new instance"
        },
        {
          "id": "D",
          "text": "Copy an Amazon Machine Image (AMI) of an EC2 instance and specify a different Region for the destination"
        },
        {
          "id": "E",
          "text": "Copy an Amazon Elastic Block Store (Amazon EBS) volume from Amazon S3 and launch an EC2 instance in the destination Region using that EBS VOLUME"
        }
      ]
    },
    {
      "id": "110",
      "question": "A solutions architect is designing a two-tier web application. The application consists of a public-facing web tier hosted on Amazon EC2 in public subnets. The database tier consists of Microsoft SQL Server running on Amazon EC2 in a private subnet Security is a high priority for the company. How should security groups be configured in this situation? (Select TWO )",
      "image": "",
      "explaination": "The answer should be A to allow the internet to access the web tier and C to allow only the web tier to access the database using the correct port. No ports are required outbound as traffic will automatically be permitted outbound when a session is established inbound.",
      "correct": [
        "A",
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/70"
        },
        {
          "id": "B",
          "text": "Configure the security group for the web tier to allow outbound traffic on port 443 from 0.0.0.0/0"
        },
        {
          "id": "C",
          "text": "Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier"
        },
        {
          "id": "D",
          "text": "Configure the security group for the database tier to allow outbound traffic on ports 443 and 1433 to the security group for the web tier"
        },
        {
          "id": "E",
          "text": "Configure the security group for the database tier to allow inbound traffic on ports 443 and 1433 from the security group for the web tier"
        }
      ]
    },
    {
      "id": "111",
      "question": "A data science team requires storage for nightly log processing. The size and number of logs is unknown and will persist for 24 hours only. What is the MOST cost-effective solution?",
      "image": "",
      "explaination": "The logs will persist for only 24 hours and therefore you won't be able to store in Glacier.",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon S3 Glacier"
        },
        {
          "id": "B",
          "text": "Amazon S3 Standard"
        },
        {
          "id": "C",
          "text": "Amazon S3 intelligent-Tiering"
        },
        {
          "id": "D",
          "text": "Amazon S3 One Zone-Infrequent Access {S3 One Zone-IA)"
        }
      ]
    },
    {
      "id": "112",
      "question": "A company is hosting a web application on AWS using a single Amazon EC2 instance that stores user- uploaded documents in an Amazon EBS volume. For better scalability and availability the company duplicated the architecture and created a second EC2 instance and EBS volume in another Availability Zone: placing both behind an Application Load Balancer. After completing this change users reported that each time they refreshed the website they could see one subset of their documents or the other but never all of the documents at the same time. What should a solutions architect propose to ensure users see all of their documents at once?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Copy the data so both EBS volumes contain all the documents."
        },
        {
          "id": "B",
          "text": "Configure the Application Load Balancer to direct a user to the server with the documents."
        },
        {
          "id": "C",
          "text": "Copy the data from both EBS volumes to Amazon EFS. Modify the application to save new documents to Amazon EPS."
        },
        {
          "id": "D",
          "text": "Configure the Application Load Balancer to send the request to both servers. Return each document from the correct server."
        }
      ]
    },
    {
      "id": "113",
      "question": "You are building infrastructure for a data warehousing solution and an extra request has come through that there will be a lot of business reporting queries running all the time and you are not sure if your current DB instance will be able to handle it. What would be the best solution for this?",
      "image": "",
      "explaination": "Read Replicas make it easy to take advantage of MySQL's built-in replication functionality to elastically scale out beyond the capacity constraints of a single DB Instance for read-heavy database workloads. There are a variety of scenarios where deploying one or more Read Replicas for a given source DB Instance may make sense. Common reasons for deploying a Read Replica include: Scaling beyond the compute or I/O capacity of a single DB Instance for read-heavy database workloads. This excess read traffic can be directed to one or more Read Replicas. Serving read traffic while the source DB Instance is unavailable. If your source DB Instance cannot take I/O requests (e.g. due to I/O suspension for backups or scheduled maintenance), you can direct read traffic to your Read Replica(s). For this use case, keep in mind that the data on the Read Replica may be \"stale\" since the source DB Instance is unavailable. Business reporting or data warehousing scenarios; you may want business reporting queries to run against a Read Replica, rather than your primary, production DB Instance. Reference: https://aws.amazon.com/rds/faqs/",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "DB Parameter Groups"
        },
        {
          "id": "B",
          "text": "Read Replicas"
        },
        {
          "id": "C",
          "text": "Multi-AZ DB Instance deployment"
        },
        {
          "id": "D",
          "text": "Database Snapshots"
        }
      ]
    },
    {
      "id": "114",
      "question": "In DynamoDB, could you use IAM to grant access to Amazon DynamoDB resources and API actions?",
      "image": "",
      "explaination": "Amazon DynamoDB integrates with AWS Identity and Access Management (IAM). You can use AWS IAM to grant access to Amazon DynamoDB resources and API actions. To do this, you first write an AWS IAM policy, which is a document that explicitly lists the permissions you want to grant. You then attach that policy to an AWS IAM user or role. Reference: http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/UsingIAMWithDDB.html",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "In DynamoDB there is no need to grant access"
        },
        {
          "id": "B",
          "text": "Depended to the type of access"
        },
        {
          "id": "C",
          "text": "No"
        },
        {
          "id": "D",
          "text": "Yes"
        }
      ]
    },
    {
      "id": "115",
      "question": "Much of your company's data does not need to be accessed often, and can take several hours for retrieval time, so it's stored on Amazon Glacier. However someone within your organization has expressed concerns that his data is more sensitive than the other data, and is wondering whether the high level of encryption that he knows is on S3 is also used on the much cheaper Glacier service. Which of the following statements would be most applicable in regards to this concern?",
      "image": "",
      "explaination": "Like Amazon S3, the Amazon Glacier service provides low-cost, secure, and durable storage. But where S3 is designed for rapid retrieval, Glacier is meant to be used as an archival service for data that is not accessed often, and for which retrieval times of several hours are suitable. Amazon Glacier automatically encrypts the data using AES-256 and stores it durably in an immutable form. Amazon Glacier is designed to provide average annual durability of 99.999999999% for an archive. It stores each archive in multiple facilities and multiple devices. Unlike traditional systems which can require laborious data verification and manual repair, Glacier performs regular, systematic data integrity checks, and is built to be automatically self-healing. Reference: http://d0.awsstatic.com/whitepapers/Security/AWS%20Security%20Whitepaper.pdf",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "There is no encryption on Amazon Glacier, that's why it is cheaper."
        },
        {
          "id": "B",
          "text": "Amazon Glacier automatically encrypts the data using AES-128 a lesser encryption method than Amazon S3 but you can change it to AES-256 if you are willing to pay more."
        },
        {
          "id": "C",
          "text": "Amazon Glacier automatically encrypts the data using AES-256, the same as Amazon S3."
        },
        {
          "id": "D",
          "text": "Amazon Glacier automatically encrypts the data using AES-128 a lesser encryption method than Amazon S3."
        }
      ]
    },
    {
      "id": "116",
      "question": "Your EBS volumes do not seem to be performing as expected and your team leader has requested you look into improving their performance. Which of the following is not a true statement relating to the performance of your EBS volumes?",
      "image": "",
      "explaination": "Several factors can affect the performance of Amazon EBS volumes, such as instance configuration, I/O characteristics, workload demand, and storage configuration. Frequent snapshots provide a higher level of data durability, but they may slightly degrade the performance of your application while the snapshot is in progress. This trade off becomes critical when you have data that changes rapidly. Whenever possible, plan for snapshots to occur during off-peak times in order to minimize workload impact. Reference: http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSPerformance.html",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Frequent snapshots provide a higher level of data durability and they will not degrade the performance of your application while the snapshot is in progress."
        },
        {
          "id": "B",
          "text": "General Purpose (SSD) and Provisioned IOPS (SSD) volumes have a throughput limit of 128 MB/s per volume."
        },
        {
          "id": "C",
          "text": "There is a relationship between the maximum performance of your EBS volumes, the amount of I/O you are driving to them, and the amount of time it takes for each transaction to complete."
        },
        {
          "id": "D",
          "text": "There is a 5 to 50 percent reduction in IOPS when you first access each block of data on a newly created or restored EBS volume"
        }
      ]
    },
    {
      "id": "117",
      "question": "You've created your first load balancer and have registered your EC2 instances with the load balancer. Elastic Load Balancing routinely performs health checks on all the registered EC2 instances and automatically distributes all incoming requests to the DNS name of your load balancer across your registered, healthy EC2 instances. By default, the load balancer uses the ___ protocol for checking the health of your instances.",
      "image": "",
      "explaination": "In Elastic Load Balancing a health configuration uses information such as protocol, ping port, ping path (URL), response timeout period, and health check interval to determine the health state of the instances registered with the load balancer. Currently, HTTP on port 80 is the default health check. Reference: http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/TerminologyandKeyConcepts.html",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "HTTPS"
        },
        {
          "id": "B",
          "text": "HTTP"
        },
        {
          "id": "C",
          "text": "ICMP"
        },
        {
          "id": "D",
          "text": "IPv6"
        }
      ]
    },
    {
      "id": "118",
      "question": "A major finance organisation has engaged your company to set up a large data mining application. Using AWS you decide the best service for this is Amazon Elastic MapReduce(EMR) which you know uses Hadoop. Which of the following statements best describes Hadoop?",
      "image": "",
      "explaination": "Amazon EMR uses Apache Hadoop as its distributed data processing engine. Hadoop is an open source, Java software framework that supports data- intensive distributed applications running on large clusters of commodity hardware. Hadoop implements a programming model named \"MapReduce,\" where the data is divided into many small fragments of work, each of which may be executed on any node in the cluster. This framework has been widely used by developers, enterprises and startups and has proven to be a reliable software platform for processing up to petabytes of data on clusters of thousands of commodity machines. Reference: http://aws.amazon.com/elasticmapreduce/faqs/",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Hadoop is 3rd Party software which can be installed using AMI"
        },
        {
          "id": "B",
          "text": "Hadoop is an open source python web framework"
        },
        {
          "id": "C",
          "text": "Hadoop is an open source Java software framework"
        },
        {
          "id": "D",
          "text": "Hadoop is an open source javascript framework"
        }
      ]
    },
    {
      "id": "119",
      "question": "In Amazon EC2 Container Service, are other container types supported?",
      "image": "",
      "explaination": "In Amazon EC2 Container Service, Docker is the only container platform supported by EC2 Container Service presently. Reference: http://aws.amazon.com/ecs/faqs/",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Yes, EC2 Container Service supports any container service you need."
        },
        {
          "id": "B",
          "text": "Yes, EC2 Container Service also supports Microsoft container service."
        },
        {
          "id": "C",
          "text": "No, Docker is the only container platform supported by EC2 Container Service presently."
        },
        {
          "id": "D",
          "text": "Yes, EC2 Container Service supports Microsoft container service and Openstack."
        }
      ]
    },
    {
      "id": "120",
      "question": "A Solutions Architect is designing the architecture for a web application that will be hosted on AWS. Internet users will access the application using HTTP and HTTPS. How should the Architect design the traffic control requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use a network ACL to allow outbound ports for HTTP and HTTPS. Deny other traffic for inbound and outbound."
        },
        {
          "id": "B",
          "text": "Use a network ACL to allow inbound ports for HTTP and HTTPS. Deny other traffic for inbound and outbound."
        },
        {
          "id": "C",
          "text": "Allow inbound ports for HTTP and HTTPS in the security group used by the web servers."
        },
        {
          "id": "D",
          "text": "Allow outbound ports for HTTP and HTTPS in the security group used by the web servers."
        }
      ]
    },
    {
      "id": "121",
      "question": "A solutions architect is designing a system to analyze the performance of financial markets while the markets are closed. The system will run a series of compute-intensive jobs for 4 hours every night. The time to complete the compute jobs is expected to remain constant, and jobs cannot be interrupted once started. Once completed, the system is expected to run for a minimum of 1 year. Which type of Amazon EC2 instances should be used to reduce the cost of the system?",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-scheduled-instances.html",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Spot Instances"
        },
        {
          "id": "B",
          "text": "On-Demand Instances"
        },
        {
          "id": "C",
          "text": "Standard Reserved Instances"
        },
        {
          "id": "D",
          "text": "Scheduled Reserved Instances"
        }
      ]
    },
    {
      "id": "122",
      "question": "A company hosts a static website on-premises and wants to migrate the website to AWS. The website should load as quickly as possible for users around the world. The company also wants the most cost- effective solution. What should a solutions architect do to accomplish this?",
      "image": "",
      "explaination": "Having the same content replicated to multiple buckets is not cost effective as your paying multiple times for the same service.",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Replicate the S3 bucket to multiple AWS Regions"
        },
        {
          "id": "B",
          "text": "Copy the website content to an Amazon S3 bucket. Configure the bucket to serve static webpage content. Configure Amazon CloudFront with the S3 bucket as the origin"
        },
        {
          "id": "C",
          "text": "Copy the website content to an Amazon EBS-backed. Amazon EC2 instance running Apache HTTP Server. Configure Amazon Route 53 geolocation routing policies to select the closest origin"
        },
        {
          "id": "D",
          "text": "Copy the website content to multiple Amazon EBS-backed. Amazon EC2 instances running Apache HTTP Server in multiple AWS Regions. Configure Amazon CloudFront geolocation routing policies to select the closest origin"
        }
      ]
    },
    {
      "id": "123",
      "question": "A solutions architect is implementing a document review application using an Amazon S3 bucket for storage. The solution must prevent accidental deletion of the documents and ensure that all versions of the documents are available. Users must be able to download, modify, and upload documents. Which combination of actions should be taken to meet these requirements'? (Select TWO)",
      "image": "",
      "explaination": "",
      "correct": [
        "B",
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Enable a read-only bucket ACL"
        },
        {
          "id": "B",
          "text": "Enable versioning on the bucket"
        },
        {
          "id": "C",
          "text": "Attach an IAM policy to the bucket"
        },
        {
          "id": "D",
          "text": "Enable MFA Delete on the bucket"
        },
        {
          "id": "E",
          "text": "Encrypt the bucket using AWS KMS"
        }
      ]
    },
    {
      "id": "124",
      "question": "A company built a food ordering application that captures user data and stores it for future analysis. The application's static front end is deployed on an Amazon EC2 instance. The front-end application sends the requests to the backend application running on separate EC2 instance. The backend application then stores the data in Amazon RDS. What should a solutions architect do to decouple the architecture and make it scalable?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon S3 to serve the front-end application which sends requests to Amazon EC2 to execute the backend application. The backend application will process and store the data in Amazon RDS"
        },
        {
          "id": "B",
          "text": "Use Amazon S3 to serve the front-end application and write requests to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe Amazon EC2 instances to the HTTP/HTTPS endpoint of the topic and process and store the data in Amazon RDS"
        },
        {
          "id": "C",
          "text": "Use an EC2 instance to serve the front end and write requests to an Amazon SQS queue. Place the backend instance in an Auto Scaling group and scale based on the queue depth to process and store the data in Amazon RDS"
        },
        {
          "id": "D",
          "text": "Use Amazon S3 to serve the static front-end application and send requests to Amazon API Gateway which writes the requests to an Amazon SQS queue. Place the backend instances in an Auto Scaling group and scale based on the queue depth to process and store the data in Amazon RDS"
        }
      ]
    },
    {
      "id": "125",
      "question": "A Solutions Architect must design a web application that will be hosted on AWS, allowing users to purchase access to premium, shared content that is stored in an S3 bucket. Upon payment, content will be available for download for 14 days before the user is denied access. Which of the following would be the LEAST complicated implementation?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use an Amazon CloudFront distribution with an origin access identity (OAI) Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs Design a Lambda function to remove data that is older than 14 days"
        },
        {
          "id": "B",
          "text": "Use an S3 bucket and provide direct access to the tile Design the application to track purchases in a DynamoDH table Configure a Lambda function to remove data that is older than 14 days based on a query to Amazon DynamoDB"
        },
        {
          "id": "C",
          "text": "Use an Amazon CloudFront distribution with an OAI Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs Design the application to sot an expiration of 14 days for the URL"
        },
        {
          "id": "D",
          "text": "Use an Amazon CloudFront distribution with an OAI Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs Design the application to set an expiration of 60 minutes for the URL and recreate the URL as necessary"
        }
      ]
    },
    {
      "id": "126",
      "question": "A company wants to host a scalable web application on AWS. The application will be accessed by users from different geographic regions of the world. Application users will be able to download and upload unique data up to gigabytes in size. The development team wants a cost-effective solution to minimize upload and download latency and maximize performance. What should a solutions architect do to accomplish this?",
      "image": "",
      "explaination": "https://aws.amazon.com/ec2/autoscaling/",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon S3 with Transfer Acceleration to host the application."
        },
        {
          "id": "B",
          "text": "Use Amazon S3 with CacheControl headers to host the application."
        },
        {
          "id": "C",
          "text": "Use Amazon EC2 with Auto Scaling and Amazon CloudFront to host the application."
        },
        {
          "id": "D",
          "text": "Use Amazon EC2 with Auto Scaling and Amazon ElastiCache to host the application."
        }
      ]
    },
    {
      "id": "127",
      "question": "A company captures clickstream data from multiple websites and analyzes it using batch processing. The data is loaded nightly into Amazon Redshift and is consumed by business analysts. The company wants to move towards near-real-time data processing for timely insights. The solution should process the streaming data with minimal effort and operational overhead. Which combination of AWS services are MOST cost-effective for this solution? (Choose two.)",
      "image": "",
      "explaination": "https://d0.awsstatic.com/whitepapers/whitepaper-streaming-data-solutions-on-aws-with-amazonkinesis.pdf (9)",
      "correct": [
        "A",
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon EC2"
        },
        {
          "id": "B",
          "text": "AWS Lambda"
        },
        {
          "id": "C",
          "text": "Amazon Kinesis Data Streams"
        },
        {
          "id": "D",
          "text": "Amazon Kinesis Data Firehose"
        },
        {
          "id": "E",
          "text": "Amazon Kinesis Data Analytics"
        }
      ]
    },
    {
      "id": "128",
      "question": "A company is migrating a three-tier application to AWS. The application requires a MySQL database. In the past, the application users reported poor application performance when creating new entries. These performance issues were caused by users generating different real-time reports from the application duringworking hours. Which solution will improve the performance of the application when it is moved to AWS?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Import the data into an Amazon DynamoDB table with provisioned capacity. Refactor the application to use DynamoDB for reports. "
        },
        {
          "id": "B",
          "text": "Create the database on a compute optimized Amazon EC2 instance. Ensure compute resources exceed the on-premises database. "
        },
        {
          "id": "C",
          "text": "Create an Amazon Aurora MySQL Multi-AZ DB cluster with multiple read replicas. Configure the application reader endpoint for reports. "
        },
        {
          "id": "D",
          "text": "Create an Amazon Aurora MySQL Multi-AZ DB cluster. Configure the application to use the backup instance of the cluster as an endpoint for the reports. "
        }
      ]
    },
    {
      "id": "129",
      "question": "A start-up company has a web application based in the us-east-1 Region with multiple Amazon EC2 instances running behind an Application Load Balancer across multiple Availability Zones. As the company's user base grows in the us-west-1 Region, it needs a solution with low latency and high availability. What should a solutions architect do to accomplish this?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Provision EC2 instances in us-west-1. Switch the Application Load Balancer to a Network Load Balancer to achieve cross-Region load balancing."
        },
        {
          "id": "B",
          "text": "Provision EC2 instances and an Application Load Balancer in us-west-1. Make the load balancer distribute the traffic based on the location of the request."
        },
        {
          "id": "C",
          "text": "Provision EC2 instances and configure an Application Load Balancer in us-west-1. Create an accelerator in AWS Global Accelerator that uses an endpoint group that includes the load balancer endpoints in both Regions."
        },
        {
          "id": "D",
          "text": "Provision EC2 instances and configure an Application Load Balancer in us-west-1. Configure Amazon Route 53 with a weighted routing policy. Create alias records in Route 53 that point to the Application Load Balancer."
        }
      ]
    },
    {
      "id": "130",
      "question": "A company is planning to migrate a business-critical dataset to Amazon S3. The current solution design uses a single S3 bucket in the us-east-1 Region with versioning enabled to store the dataset. The company's disaster recovery policy states that all data multiple AWS Regions. How should a solutions architect design the S3 solution?",
      "image": "",
      "explaination": "https://medium.com/@KerrySheldon/s3-exercise-2-4-adding-objects-to-an-s3-bucket-with-crossregion-replication-a78b332b7697",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create an additional S3 bucket in another Region and configure cross-Region replication."
        },
        {
          "id": "B",
          "text": "Create an additional S3 bucket in another Region and configure cross-origin resource sharing (CORS)."
        },
        {
          "id": "C",
          "text": "Create an additional S3 bucket with versioning in another Region and configure cross-Region replication."
        },
        {
          "id": "D",
          "text": "Create an additional S3 bucket with versioning in another Region and configure cross-origin resource (CORS)."
        }
      ]
    },
    {
      "id": "131",
      "question": "A company has application running on Amazon EC2 instances in a VPC. One of the applications needs to call an Amazon S3 API to store and read objects. The company's security policies restrict any internet-bound traffic from the applications. Which action will fulfill these requirements and maintain security?",
      "image": "",
      "explaination": "https://aws.amazon.com/blogs/aws/new-vpc-endpoint-for-amazon-s3/",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure an S3 interface endpoint."
        },
        {
          "id": "B",
          "text": "Configure an S3 gateway endpoint."
        },
        {
          "id": "C",
          "text": "Create an S3 bucket in a private subnet."
        },
        {
          "id": "D",
          "text": "Create an S3 bucket in the same Region as the EC2 instance."
        }
      ]
    },
    {
      "id": "132",
      "question": "A company's web application uses an Amazon RDS PostgreSQL DB instance to store its application data. During the financial closing period at the start of every month. Accountants run large queries that impact the database's performance due to high usage. The company wants to minimize the impact that the reporting activity has on the web application. What should a solutions architect do to reduce the impact on the database with the LEAST amount of effort?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create a read replica and direct reporting traffic to the replica."
        },
        {
          "id": "B",
          "text": "Create a Multi-AZ database and direct reporting traffic to the standby."
        },
        {
          "id": "C",
          "text": "Create a cross-Region read replica and direct reporting traffic to the replica."
        },
        {
          "id": "D",
          "text": "Create an Amazon Redshift database and direct reporting traffic to the Amazon Redshift database."
        }
      ]
    },
    {
      "id": "133",
      "question": "A company must generate sales reports at the beginning of every month. The reporting process launches 20 Amazon EC2 instances on the first of the month. The process runs for 7 days and cannot be interrupted. The company wants to minimize costs. Which pricing model should the company choose?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Reserved Instances"
        },
        {
          "id": "B",
          "text": "Spot Block Instances"
        },
        {
          "id": "C",
          "text": "On-Demand Instances"
        },
        {
          "id": "D",
          "text": "Scheduled Reserved Instances"
        }
      ]
    },
    {
      "id": "134",
      "question": "A company is hosting a website behind multiple Application Load Balancers. The company has different distribution rights for its content around the world. A solutions architect needs to ensure that users are served the correct content without violating distribution rights. Which configuration should the solutions architect choose to meet these requirements?",
      "image": "",
      "explaination": "https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html (geolocation routing)",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure Amazon CloudFront with AWS WAF."
        },
        {
          "id": "B",
          "text": "Configure Application Load Balancers with AWS WAF."
        },
        {
          "id": "C",
          "text": "Configure Amazon Route 53 with a geolocation policy."
        },
        {
          "id": "D",
          "text": "Configure Amazon Route 53 with a geoproximity routing policy."
        }
      ]
    },
    {
      "id": "135",
      "question": "A company's website is using an Amazon RDS MySQL Multi-AZ DB instance for its transactional data storage. There are other internal systems that query this DB instance to fetch data for internal batch processing. The RDS DB instance slows down significantly the internal systems fetch data. This impacts the website's read and write performance, and the users experience slow response times. Which solution will improve the website's performance?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use an RDS PostgreSQL DB instance instead of a MySQL database."
        },
        {
          "id": "B",
          "text": "Use Amazon ElastiCache to cache the query responses for the website."
        },
        {
          "id": "C",
          "text": "Add an additional Availability Zone to the current RDS MySQL Multi.AZ DB instance."
        },
        {
          "id": "D",
          "text": "Add a read replica to the RDS DB instance and configure the internal systems to query the read replica."
        }
      ]
    },
    {
      "id": "136",
      "question": "A solutions architect is designing storage for a high performance computing (HPC) environment based on Amazon Linux. The workload stores and processes a large amount of engineering drawings that require shared storage and heavy computing. Which storage option would be the optimal solution?",
      "image": "",
      "explaination": "https://d1.awsstatic.com/whitepapers/AWS%20Partner%20Network_HPC%20Storage%20Options_2019_FINAL.pdf (p.8)",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon Elastic File System (Amazon EFS)"
        },
        {
          "id": "B",
          "text": "Amazon FSx for Lustre"
        },
        {
          "id": "C",
          "text": "Amazon EC2 instance store"
        },
        {
          "id": "D",
          "text": "Amazon EBS Provisioned IOPS SSD (io1)"
        }
      ]
    },
    {
      "id": "137",
      "question": "A company is performing an AWS Well-Architected Framework review of an existing workload deployed on AWS. The review identified a public-facing website running on the same Amazon EC2 instance as a Microsoft Active Directory domain controller that was install recently to support other AWS services. A solutions architect needs to recommend a new design that would improve the security of the architecture and minimize the administrative demand on IT staff. What should the solutions architect recommend?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use AWS Directory Service to create a managed Active Directory. Uninstall Active Directory on the current EC2 instance."
        },
        {
          "id": "B",
          "text": "Create another EC2 instance in the same subnet and reinstall Active Directory on it. Uninstall Active Directory."
        },
        {
          "id": "C",
          "text": "Use AWS Directory Service to create an Active Directory connector. Proxy Active Directory requests to the Active domain controller running on the current EC2 instance."
        },
        {
          "id": "D",
          "text": "Enable AWS Single Sign-On (AWS SSO) with Security Assertion Markup Language (SAML) 2.0 federation with the current Active Directory controller. Modify the EC2 instance's security group to deny public access to Active Directory."
        }
      ]
    },
    {
      "id": "138",
      "question": "A company runs an application in a branch office within a small data closet with no virtualized compute resources. The application data is stored on an NFS volume. Compliance standards require a daily offsite backup of the NFS volume. Which solution meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Install an AWS Storage Gateway file gateway on premises to replicate the data to Amazon S3."
        },
        {
          "id": "B",
          "text": "Install an AWS Storage Gateway file gateway hardware appliance on premises to replicate the data to Amazon S3."
        },
        {
          "id": "C",
          "text": "Install an AWS Storage Gateway volume gateway with stored volumes on premises to replicate the data to Amazon S3."
        },
        {
          "id": "D",
          "text": "Install an AWS Storage Gateway volume gateway with cached volumes on premises to replicate the data to Amazon S3."
        }
      ]
    },
    {
      "id": "139",
      "question": "An application hosted on AWS is experiencing performance problems, and the application vendor wants to perform an analysis of the log file to troubleshoot further. The log file is stored on Amazon S3 and is 10 GB in size. The application owner will make the log file available to the vendor for a limited time. What is the MOST secure way to do this?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Enable public read on the S3 object and provide the link to the vendor."
        },
        {
          "id": "B",
          "text": "Upload the file to Amazon WorkDocs and share the public link with the vendor."
        },
        {
          "id": "C",
          "text": "Generate a presigned URL and have the vendor download the log file before it expires."
        },
        {
          "id": "D",
          "text": "Create an IAM user for the vendor to provide access to the S3 bucket and the application. Enforce multifactor authentication."
        }
      ]
    },
    {
      "id": "140",
      "question": "A company hosts its product information webpages on AWS. The existing solution uses multiple Amazon C2 instances behind an Application Load Balancer in an Auto Scaling group. The website also uses a custom DNS name and communicates with HTTPS only using a dedicated SSL certificate. The company is planning a new product launch and wants to be sure that users from around the world have the best possible experience on the new website. What should a solutions architect do to meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Redesign the application to use Amazon CloudFront."
        },
        {
          "id": "B",
          "text": "Redesign the application to use AWS Elastic Beanstalk."
        },
        {
          "id": "C",
          "text": "Redesign the application to use a Network Load Balancer."
        },
        {
          "id": "D",
          "text": "Redesign the application to use Amazon S3 static website hosting."
        }
      ]
    },
    {
      "id": "141",
      "question": "A solutions architect observes that a nightly batch processing job is automatically scaled up for 1 hour before the desired Amazon EC2 capacity is reached. The peak capacity is the same every night and the batch jobs always start at 1 AM. The solutions architect needs to find a cost-effective solution that will allow for the desired EC2 capacity to be reached quickly and allow the Auto Scaling group to scale down after the batch jobs are complete. What should the solutions architect do to meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Increase the minimum capacity for the Auto Scaling group."
        },
        {
          "id": "B",
          "text": "Increase the maximum capacity for the Auto Scaling group."
        },
        {
          "id": "C",
          "text": "Configure scheduled scaling to scale up to the desired compute level."
        },
        {
          "id": "D",
          "text": "Change the scaling policy to add more EC2 instances during each scaling operation."
        }
      ]
    },
    {
      "id": "142",
      "question": "An ecommerce company is running a multi-tier application on AWS. The front-end and backend tiers both run on Amazon EC2. and the database runs on Amazon RDS for MySQL. The backend tier communicates with the RDS instance. There are frequent calls to return identical datasets from the database that are causing performance slowdowns. Which action should be taken to improve the performance of the backend?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Implement Amazon SNS to store the database calls."
        },
        {
          "id": "B",
          "text": "Implement Amazon ElastiCache to cache the large datasets."
        },
        {
          "id": "C",
          "text": "Implement an RDS for MySQL read replica to cache database calls."
        },
        {
          "id": "D",
          "text": "Implement Amazon Kinesis Data Firehose to stream the calls to the database."
        }
      ]
    },
    {
      "id": "143",
      "question": "A company's application hosted on Amazon EC2 instances needs to access an Amazon S3 bucket. Due to data sensitivity, traffic cannot traverse the internet How should a solutions architect configure access?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create a private hosted zone using Amazon Route 53."
        },
        {
          "id": "B",
          "text": "Configure a VPC gateway endpoint for Amazon S3 in the VPC."
        },
        {
          "id": "C",
          "text": "Configure AWS PrivateLink between the EC2 instance and the S3 bucket."
        },
        {
          "id": "D",
          "text": "Set up a site-to-site VPN connection between the VPC and the S3 bucket."
        }
      ]
    },
    {
      "id": "144",
      "question": "An application runs on Amazon EC2 instances in private subnets. The application needs to access an Amazon DynamoDB table. What is the MOST secure way to access the table while ensuring that the traffic does not leave the AWS network?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use a VPC endpoint for DynamoDB."
        },
        {
          "id": "B",
          "text": "Use a NAT gateway in a public subnet."
        },
        {
          "id": "C",
          "text": "Use a NAT instance in a private subnet."
        },
        {
          "id": "D",
          "text": "Use the internet gateway attached to the VPC."
        }
      ]
    },
    {
      "id": "145",
      "question": "A solutions architect needs to design a low-latency solution for a static single-page application accessed by users utilizing a custom domain name. The solution must be serverless, encrypted in transit, and cost- effective. Which combination of AWS services and features should the solutions architect use? (Select TWO.)",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon S3"
        },
        {
          "id": "B",
          "text": "Amazon EC2"
        },
        {
          "id": "C",
          "text": "AWS Fargate"
        },
        {
          "id": "D",
          "text": "Amazon CloudFront"
        },
        {
          "id": "E",
          "text": "Elastic Load Balancer"
        }
      ]
    },
    {
      "id": "146",
      "question": "A company has global users accessing an application deployed in different AWS Regions, exposing public static IP addresses. The users are experiencing poor performance when accessing the application over the internet. What should a solutions architect recommend to reduce internet latency?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Set up AWS Global Accelerator and add endpoints."
        },
        {
          "id": "B",
          "text": "Set up AWS Direct Connect locations in multiple Regions."
        },
        {
          "id": "C",
          "text": "Set up an Amazon CloudFront distribution to access an application."
        },
        {
          "id": "D",
          "text": "Set up an Amazon Route 53 geoproximity routing policy to route traffic."
        }
      ]
    },
    {
      "id": "147",
      "question": "An application requires a development environment (DEV) and production environment (PROD) for several years. The DEV instances will run for 10 hours each day during normal business hours, while the PROD instances will run 24 hours each day. A solutions architect needs to determine a compute instance purchase strategy to minimize costs. Which solution is the MOST cost-effective?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "DEV with Spot Instances and PROD with On-Demand Instances"
        },
        {
          "id": "B",
          "text": "DEV with On-Demand Instances and PROD with Spot Instances"
        },
        {
          "id": "C",
          "text": "DEV with Scheduled Reserved Instances and PROD with Reserved Instances"
        },
        {
          "id": "D",
          "text": "DEV with On-Demand Instances and PROD with Scheduled Reserved Instances"
        }
      ]
    },
    {
      "id": "148",
      "question": "A solutions architect is designing a customer-facing application. The application is expected to have a variable amount of reads and writes depending on the time of year and clearly defined access patterns throughout the year. Management requires that database auditing and scaling be managed in the AWS Cloud. The Recovery Point Objective (RPO) must be less than 5 hours. Which solutions can accomplish this? (Select TWO.)",
      "image": "",
      "explaination": "",
      "correct": [
        "A",
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon DynamoDB with auto scaling. Use on-demand backups and AWS CloudTrail."
        },
        {
          "id": "B",
          "text": "Use Amazon DynamoDB with auto scaling. Use on-demand backups and Amazon DynamoDB Streams."
        },
        {
          "id": "C",
          "text": "Use Amazon Redshift Configure concurrency scaling. Enable audit logging. Perform database snapshots every 4 hours."
        },
        {
          "id": "D",
          "text": "Use Amazon RDS with Provisioned IOPS. Enable the database auditing parameter. Perform database snapshots every 5 hours."
        },
        {
          "id": "E",
          "text": "Use Amazon RDS with auto scaling. Enable the database auditing parameter. Configure the backup retention period to at least 1 day."
        }
      ]
    },
    {
      "id": "149",
      "question": "A website on Amazon S3. The website serves petabytes of outbound traffic monthly, which accounts for most of the company's AWS costs. What should a solutions architect do to reduce costs?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure Amazon CloudFront with the existing website as the origin."
        },
        {
          "id": "B",
          "text": "Move the website to Amazon EC2 with Amazon EBS volumes for storage."
        },
        {
          "id": "C",
          "text": "Use AWS Global Accelerator and specify the existing website as the endpoint."
        },
        {
          "id": "D",
          "text": "Rearchitect the website to run on a combination of Amazon API Gateway and AWS Lambda."
        }
      ]
    },
    {
      "id": "150",
      "question": "A solution architect has created two IAM policies: Policy1 and Policy2. Both policies are attached to an IAM group. A cloud engineer is added as an IAM user to the IAM group. Which action will the cloud engineer be able to perform?",
      "image": "img/question-150.png",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Deleting IAM users"
        },
        {
          "id": "B",
          "text": "Deleting directories"
        },
        {
          "id": "C",
          "text": "Deleting Amazon EC2 instances"
        }
      ]
    },
    {
      "id": "151",
      "question": "A solutions architect is helping a developer design a new ecommerce shopping cart application using AWS services. The developer is unsure of the current database schema and expects to make changes as the ecommerce site grows. The solution needs to be highly resilient and capable of automatically scaling read and write capacity. Which database solution meets these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon Aurora PostgreSQL"
        },
        {
          "id": "B",
          "text": "Amazon DynamoDB with on-demand enabled"
        },
        {
          "id": "C",
          "text": "Amazon DynamoDB with DynamoDB Streams enabled"
        },
        {
          "id": "D",
          "text": "Amazon SQS and Amazon Aurora PostgreSQL"
        }
      ]
    },
    {
      "id": "152",
      "question": "A solutions architect is designing an architecture for a new application that requires low network latency and high network throughput between Amazon EC2 instances. Which component should be included in the architectural design?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "An Auto Scaling group with Spot Instance types."
        },
        {
          "id": "B",
          "text": "A placement group using a cluster placement strategy."
        },
        {
          "id": "C",
          "text": "A placement group using a partition placement strategy."
        },
        {
          "id": "D",
          "text": "An Auto Scaling group with On-Demand instance types."
        }
      ]
    },
    {
      "id": "153",
      "question": "A company has a web application with sporadic usage patterns. There is heavy usage at the beginning of each month, moderate usage at the start of each week, and unpredictable usage during the week. The application consists of a web server and a MySQL database server running inside the data center. The company would like to move the application to the AWS Cloud, and needs to select a cost-effective database platform that will not require database modifications. Which solution will meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon DynamoDB"
        },
        {
          "id": "B",
          "text": "Amazon RDS for MySQL"
        },
        {
          "id": "C",
          "text": "MySQL-compatible Amazon Aurora Serverless"
        },
        {
          "id": "D",
          "text": "MySQL deployed on Amazon EC2 in an Auto Scaling group"
        }
      ]
    },
    {
      "id": "154",
      "question": "A solutions architect is designing a mission-critical web application. It will consist of Amazon EC2 instances behind an Application Load Balancer and a relational database. The database should be highly available and fault tolerant. Which database implementations will meet these requirements? (Select TWO.)",
      "image": "",
      "explaination": "",
      "correct": [
        "A",
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon Redshift"
        },
        {
          "id": "B",
          "text": "Amazon DynamoDB"
        },
        {
          "id": "C",
          "text": "Amazon RDS for MySQL"
        },
        {
          "id": "D",
          "text": "MySQL-compatible Amazon Aurora Multi-AZ"
        },
        {
          "id": "E",
          "text": "Amazon RDS for SQL Server Standard Edition Mufti-AZ"
        }
      ]
    },
    {
      "id": "155",
      "question": "A media company is evaluating the possibility of moving its systems to the AWS Cloud. The company needs at least 10 TB of storage with the maximum possible I/O performance for video processing. 300 TB of very durable storage for storing media content, and 900 TB of storage to meet requirements for archival media that is not in use anymore. Which set of services should a solutions architect recommend to meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage"
        },
        {
          "id": "B",
          "text": "Amazon EBS for maximum performance. Amazon EFS for durable data storage, and Amazon S3 Glacier for archival storage"
        },
        {
          "id": "C",
          "text": "Amazon EC2 instance store for maximum performance, Amazon EFS for durable data storage, and Amazon S3 for archival storage"
        },
        {
          "id": "D",
          "text": "Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage"
        }
      ]
    },
    {
      "id": "156",
      "question": "A company hosts an application on an Amazon EC2 instance that requires a maximum of 200 GB storage space. The application is used infrequently, with peaks during mornings and evenings. Disk I/O varies, but peaks at 3,000 IOPS. The chief financial officer of the company is concerned about costs and has asked a solutions architect to recommend the most cost-effective storage option that does not sacrifice performance. Which solution should the solutions architect recommend?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon EBS Cold HDD (sc1)"
        },
        {
          "id": "B",
          "text": "Amazon EBS General Purpose SSD (gp2)"
        },
        {
          "id": "C",
          "text": "Amazon EBS Provisioned IOPS SSD (io1)"
        },
        {
          "id": "D",
          "text": "Amazon EBS Throughput Optimized HDD (st1)"
        }
      ]
    },
    {
      "id": "157",
      "question": "A company delivers files in Amazon S3 to certain users who do not have AWS credentials. These users must be given access for a limited lime. What should a solutions architect do to securely meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Enable public access on an Amazon S3 bucket."
        },
        {
          "id": "B",
          "text": "Generate a presigned URL to share with the users."
        },
        {
          "id": "C",
          "text": "Encrypt files using AWS KMS and provide keys to the users."
        },
        {
          "id": "D",
          "text": "Create and assign IAM roles that will grant GetObject permissions to the users."
        }
      ]
    },
    {
      "id": "158",
      "question": "A leasing company generates and emails PDF statements every month for all its customers. Each statement is about 400 KB in size. Customers can download their statements from the website for up to 30 days from when the statements were generated. At the end of their 3-year lease, the customers are emailed a ZIP file that contains all the statements. What is the MOST cost-effective storage solution for this situation?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Store the statements using the Amazon S3 Standard storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier storage after 1 day."
        },
        {
          "id": "B",
          "text": "Store the statements using the Amazon S3 Glacier storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier Deep Archive storage after 30 days."
        },
        {
          "id": "C",
          "text": "Store the statements using the Amazon S3 Standard storage class. Create a lifecycle policy to move the statements to Amazon S3 One Zone- Infrequent Access (S3 One Zone-IA) storage after 30 days."
        },
        {
          "id": "D",
          "text": "Store the statements using the Amazon S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier storage after 30 days."
        }
      ]
    },
    {
      "id": "159",
      "question": "A solutions architect is moving the static content from a public website hosted on Amazon EC2 instances to an Amazon S3 bucket. An Amazon CloudFront distribution will be used to deliver the static assets. The security group used by the EC2 instances restricts access to a limited set of IP ranges. Access to the static content should be similarly restricted. Which combination of steps will meet these requirements? (Select TWO.)",
      "image": "",
      "explaination": "",
      "correct": [
        "C",
        "E"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create an origin access identity (OAI) and associate it with the distribution. Change the permissions in the bucket policy so that only the OAI can read the objects."
        },
        {
          "id": "B",
          "text": "Create an AWS WAF web ACL that includes the same IP restrictions that exist in the EC2 security group. Associate this new web ACL with the CloudFront distribution."
        },
        {
          "id": "C",
          "text": "Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the CloudFront distribution."
        },
        {
          "id": "D",
          "text": "Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the S3 bucket hosting the static content."
        },
        {
          "id": "E",
          "text": "Create a new IAM role and associate the role with the distribution. Change the permissions either on the S3 bucket or on the files within the S3 bucket so that only the newly created IAM role has read and download permissions."
        }
      ]
    },
    {
      "id": "160",
      "question": "A company has a large Microsoft SharePoint deployment running on-premises that requires Microsoft Windows shared file storage. The company wants to migrate this workload to the AWS Cloud and is considering various storage options. The storage solution must be highly available and integrated with Active Directory for access control. Which solution will satisfy these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure Amazon EFS storage and set the Active Directory domain for authentication."
        },
        {
          "id": "B",
          "text": "Create an SMB file share on an AWS Storage Gateway file gateway in two Availability Zones."
        },
        {
          "id": "C",
          "text": "Create an Amazon S3 bucket and configure Microsoft Windows Server to mount it as a volume."
        },
        {
          "id": "D",
          "text": "Create an Amazon FSx for Windows File Server file system on AWS and set the Active Directory domain for authentication."
        }
      ]
    },
    {
      "id": "161",
      "question": "A company runs multiple Amazon EC2 Linux instances in a VPC with applications that use a hierarchical directory structure. The applications need to rapidly and concurrently read and write to shared storage How can this be achieved?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create an Amazon EFS file system and mount it from each EC2 instance."
        },
        {
          "id": "B",
          "text": "Create an Amazon S3 bucket and permit access from all the EC2 instances in the VPC."
        },
        {
          "id": "C",
          "text": "Create a file system on an Amazon EBS Provisioned IOPS SSD (io1) volume. Attach the volume to all the EC2 instances."
        },
        {
          "id": "D",
          "text": "Create file systems on Amazon EBS volumes attached to each EC2 instance. Synchronize the Amazon EBS volumes across the different EC2 instances."
        }
      ]
    },
    {
      "id": "162",
      "question": "A company runs an application using Amazon ECS. The application creates resized versions of an original image and then makes Amazon S3 API calls to store the resized images in Amazon S3. How can a solutions architect ensure that the application has permission to access Amazon S3?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Update the S3 role in AWS IAM to allow read/write access from Amazon ECS, and then relaunch the container."
        },
        {
          "id": "B",
          "text": "Create an IAM role with S3 permissions, and then specify that role as the taskRoleArn in the task definition."
        },
        {
          "id": "C",
          "text": "Create a security group that allows access from Amazon ECS to Amazon S3, and update the launch configuration used by the ECS cluster."
        },
        {
          "id": "D",
          "text": "Create an IAM user with S3 permissions, and then relaunch the Amazon EC2 instances for the ECS cluster while logged in as this account."
        }
      ]
    },
    {
      "id": "163",
      "question": "A solutions architect has configured the following IAM policy. Which action will be allowed by the policy?",
      "image": "img/question-163.png",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "An AWS Lambda function can be deleted from any network."
        },
        {
          "id": "B",
          "text": "An AWS Lambda function can be created from any network."
        },
        {
          "id": "C",
          "text": "An AWS Lambda function can be deleted from the 100.220.0.0/20 network."
        }
      ]
    },
    {
      "id": "164",
      "question": "A website runs a web application that receives a burst of traffic each day at noon. The users upload new pictures and content daily, but have been complaining of timeouts. The architecture uses Amazon EC2 Auto Scaling groups, and the custom application consistently takes 1 minute to initiate upon boot up before responding to user requests. How should a solutions architect redesign the architecture to better respond to changing traffic?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure a Network Load Balancer with a slow start configuration."
        },
        {
          "id": "B",
          "text": "Configure AWS ElastiCache for Redis to offload direct requests to the servers."
        },
        {
          "id": "C",
          "text": "Configure an Auto Scaling step scaling policy with an instance warmup condition."
        },
        {
          "id": "D",
          "text": "Configure Amazon CloudFront to use an Application Load Balancer as the origin."
        }
      ]
    },
    {
      "id": "165",
      "question": "A company has a website running on Amazon EC2 instances across two Availability Zones. The company is expecting spikes in traffic on specific holidays, and wants to provide a consistent user experience. How can a solutions architect meet this requirement?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use step scaling."
        },
        {
          "id": "B",
          "text": "Use simple scaling."
        },
        {
          "id": "C",
          "text": "Use lifecycle hooks."
        },
        {
          "id": "D",
          "text": "Use scheduled scaling."
        }
      ]
    },
    {
      "id": "166",
      "question": "A company's web application is running on Amazon EC2 instances behind an Application Load Balancer. The company recently changed its policy, which now requires the application to be accessed from one specific country only. Which configuration will meet this requirement?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure the security group for the EC2 instances."
        },
        {
          "id": "B",
          "text": "Configure the security group on the Application Load Balancer."
        },
        {
          "id": "C",
          "text": "Configure AWS WAF on the Application Load Balancer in a VPC."
        },
        {
          "id": "D",
          "text": "Configure the network ACL for the subnet that contains the EC2 instances."
        }
      ]
    },
    {
      "id": "167",
      "question": "A company has 150 TB of archived image data stored on-premises that needs to be mowed to the AWS Cloud within the next month. The company's current network connection allows up to 100 Mbps uploads for this purpose during the night only. What is the MOST cost-effective mechanism to move this data and meet the migration deadline?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use AWS Snowmobile to ship the data to AWS."
        },
        {
          "id": "B",
          "text": "Order multiple AWS Snowball devices to ship the data to AWS."
        },
        {
          "id": "C",
          "text": "Enable Amazon S3 Transfer Acceleration and securely upload the data."
        },
        {
          "id": "D",
          "text": "Create an Amazon S3 VPC endpoint and establish a VPN to upload the data."
        }
      ]
    },
    {
      "id": "168",
      "question": "A three-tier web application processes orders from customers. The web tier consists of Amazon EC2 instances behind an Application Load Balancer, a middle tier of three EC2 instances decoupled from the web tier using Amazon SQS. and an Amazon DynamoDB backend. At peak times, customers who submit orders using the site have to wait much longer than normal to receive confirmations due to lengthy processing times. A solutions architect needs to reduce these processing times. Which action will be MOST effective in accomplishing this?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Replace the SQS queue with Amazon Kinesis Data Firehose."
        },
        {
          "id": "B",
          "text": "Use Amazon ElastiCache for Redis in front of the DynamoDB backend tier."
        },
        {
          "id": "C",
          "text": "Add an Amazon CloudFront distribution to cache the responses for the web tier."
        },
        {
          "id": "D",
          "text": "Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SOS queue depth."
        }
      ]
    },
    {
      "id": "169",
      "question": "A company wants to host a web application on AWS that will communicate to a database within a VPC. The application should be highly available. What should a solutions architect recommend?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create two Amazon EC2 instances to host the web servers behind a load balancer, and then deploy the database on a large instance."
        },
        {
          "id": "B",
          "text": "Deploy a load balancer in multiple Availability Zones with an Auto Scaling group for the web servers, and then deploy Amazon RDS in multiple Availability Zones."
        },
        {
          "id": "C",
          "text": "Deploy a load balancer in the public subnet with an Auto Scaling group for the web servers, and then deploy the database on an Amazon EC2 instance in the private subnet."
        },
        {
          "id": "D",
          "text": "Deploy two web servers with an Auto Scaling group, configure a domain that points to the two web servers, and then deploy a database architecture in multiple Availability Zones."
        }
      ]
    },
    {
      "id": "170",
      "question": "A company is migrating to the AWS Cloud. A file server is the first workload to migrate. Users must be able to access the file share using the Server Message Block (SMB) protocol. Which AWS managed service meets these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon EBS"
        },
        {
          "id": "B",
          "text": "Amazon EC2"
        },
        {
          "id": "C",
          "text": "Amazon FSx"
        },
        {
          "id": "D",
          "text": "Amazon S3"
        }
      ]
    },
    {
      "id": "171",
      "question": "A company has a mobile chat application with a data store based in Amazon DynamoDB. Users would like new messages to be read with as little latency as possible. A solutions architect needs to design an optimal solution that requires minimal application changes. Which method should the solutions architect select?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure Amazon DynamoDB Accelerator (DAX) for the new messages table. Update the code to use the DAX endpoint."
        },
        {
          "id": "B",
          "text": "Add DynamoDB read replicas to handle the increased read load. Update the application to point to the read endpoint for the read replicas."
        },
        {
          "id": "C",
          "text": "Double the number of read capacity units for the new messages table in DynamoDB. Continue to use the existing DynamoDB endpoint."
        },
        {
          "id": "D",
          "text": "Add an Amazon ElastiCache for Redis cache to the application stack. Update the application to point to the Redis cache endpoint instead of DynamoDB."
        }
      ]
    },
    {
      "id": "172",
      "question": "A company wants to use an AWS Region as a disaster recovery location for its on-premises infrastructure. The company has 10 TB of existing data, and the on-premise data center has a 1 Gbps internet connection. A solutions architect must find a solution so the company can have its existing data on AWS in 72 hours without transmitting it using an unencrypted channel. Which solution should the solutions architect select?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Send the initial 10 TB of data to AWS using FTP."
        },
        {
          "id": "B",
          "text": "Send the initial 10 TB of data to AWS using AWS Snowball."
        },
        {
          "id": "C",
          "text": "Establish a VPN connection between Amazon VPC and the company's data center."
        },
        {
          "id": "D",
          "text": "Establish an AWS Direct Connect connection between Amazon VPC and the company's data center."
        }
      ]
    },
    {
      "id": "173",
      "question": "A web application runs on Amazon EC2 instances behind an Application Load Balancer. The application allows users to create custom reports of historical weather data. Generating a report can take up to 5 minutes. These long-running requests use many of the available incoming connections, making the system unresponsive to other users. How can a solutions architect make the system more responsive?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon SQS with AWS Lambda lo generate reports."
        },
        {
          "id": "B",
          "text": "Increase the idle timeout on the Application Load Balancer to 5 minutes."
        },
        {
          "id": "C",
          "text": "Update the client-side application code to increase its request timeout to 5 minutes."
        },
        {
          "id": "D",
          "text": "Publish the reports to Amazon S3 and use Amazon CloudFront for downloading to the user."
        }
      ]
    },
    {
      "id": "174",
      "question": "A company decides to migrate its three-tier web application from on premises to the AWS Cloud. The new database must be capable of dynamically scaling storage capacity and performing table joins. Which AWS service meets these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon Aurora"
        },
        {
          "id": "B",
          "text": "Amazon RDS for SqlServer"
        },
        {
          "id": "C",
          "text": "Amazon DynamoDB Streams"
        },
        {
          "id": "D",
          "text": "Amazon DynamoDB on-demand"
        }
      ]
    },
    {
      "id": "175",
      "question": "A company runs a website on Amazon EC2 instances behind an ELB Application Load Balancer. Amazon Route 53 is used for the DNS. The company wants to set up a backup website with a message including a phone number and email address that users can reach if the primary website is down. How should the company deploy this solution?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon S3 website hosting for the backup website and Route 53 failover routing policy."
        },
        {
          "id": "B",
          "text": "Use Amazon S3 website hosting for the backup website and Route 53 latency routing policy."
        },
        {
          "id": "C",
          "text": "Deploy the application in another AWS Region and use ELB health checks for failover routing."
        },
        {
          "id": "D",
          "text": "Deploy the application in another AWS Region and use server-side redirection on the primary website."
        }
      ]
    },
    {
      "id": "176",
      "question": "A company needs to implement a relational database with a multi-Region disaster recovery Recovery Point Objective (RPO) of 1 second and an Recovery Time Objective (RTO) of 1 minute. Which AWS solution can achieve this?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon Aurora Global Database"
        },
        {
          "id": "B",
          "text": "Amazon DynamoDB global tables."
        },
        {
          "id": "C",
          "text": "Amazon RDS for MySQL with Multi-AZ enabled."
        },
        {
          "id": "D",
          "text": "Amazon RDS for MySQL with a cross-Region snapshot copy."
        }
      ]
    },
    {
      "id": "177",
      "question": "A company running an on-premises application is migrating the application to AWS to increase its elasticity and availability. The current architecture uses a Microsoft SQL Server database with heavy read activity. The company wants to explore alternate database options and migrate database engines, if needed. Every 4 hours, the development team does a full copy of the production database to populate a test database. During this period, users experience latency. What should a solution architect recommend as replacement database?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon Aurora with Multi-AZ Aurora Replicas and restore from mysqldump for the test database."
        },
        {
          "id": "B",
          "text": "Use Amazon Aurora with Multi-AZ Aurora Replicas and restore snapshots from Amazon RDS for the test database."
        },
        {
          "id": "C",
          "text": "Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas, and use the standby instance for the test database."
        },
        {
          "id": "D",
          "text": "Use Amazon RDS for SQL Server with a Multi-AZ deployment and read replicas, and restore snapshots from RDS for the test database."
        }
      ]
    },
    {
      "id": "178",
      "question": "A company currently stores symmetric encryption keys in a hardware security module (HSM). A solution architect must design a solution to migrate key management to AWS. The solution should allow for key rotation and support the use of customer provided keys. Where should the key material be stored to meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon S3"
        },
        {
          "id": "B",
          "text": "AWS Secrets Manager"
        },
        {
          "id": "C",
          "text": "AWS Systems Manager Parameter store"
        },
        {
          "id": "D",
          "text": "AWS Key Management Service (AWS KMS)"
        }
      ]
    },
    {
      "id": "179",
      "question": "A company wants to run a hybrid workload for data processing. The data needs to be accessed by on- premises applications for local data processing using an NFS protocol, and must also be accessible from the AWS Cloud for further analytics and batch processing. Which solution will meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use an AWS Storage Gateway file gateway to provide file storage to AWS, then perform analytics on this data in the AWS Cloud."
        },
        {
          "id": "B",
          "text": "Use an AWS storage Gateway tape gateway to copy the backup of the local data to AWS, then perform analytics on this data in the AWS cloud."
        },
        {
          "id": "C",
          "text": "Use an AWS Storage Gateway volume gateway in a stored volume configuration to regularly take snapshots of the local data, then copy the data to AWS."
        },
        {
          "id": "D",
          "text": "Use an AWS Storage Gateway volume gateway in a cached volume configuration to back up all the local storage in the AWS cloud, then perform analytics on this data in the cloud."
        }
      ]
    },
    {
      "id": "180",
      "question": "A company must re-evaluate its need for the Amazon EC2 instances it currently has provisioned in an Auto Scaling group. At present, the Auto Scaling group is configured for minimum of two instances and a maximum of four instances across two Availability zones. A Solutions architect reviewed Amazon CloudWatch metrics and found that CPU utilization is consistently low for the EC2 instances. What should the solutions architect recommend to maximize utilization while ensuring the application remains fault tolerant?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Remove some EC2 instances to increase the utilization of remaining instances."
        },
        {
          "id": "B",
          "text": "Increase the Amazon Elastic Block Store (Amazon EBS) capacity of instances with less CPU utilization."
        },
        {
          "id": "C",
          "text": "Modify the Auto Scaling group scaling policy to scale in and out based on a higher CPU utilization metric."
        },
        {
          "id": "D",
          "text": "Create a new launch configuration that uses smaller instance types. Update the existing Auto Scaling group."
        }
      ]
    },
    {
      "id": "181",
      "question": "A company's website provides users with downloadable historical performance reports. The website needs a solution that will scale to meet the company's website demands globally. The solution should be cost effective, limit the? provisioning of Into and provide the fastest possible response time. Which combination should a solutions architect recommend to meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon CloudFront and Amazon S3"
        },
        {
          "id": "B",
          "text": "AWS Lambda and Amazon Dynamo"
        },
        {
          "id": "C",
          "text": "Application Load Balancer with Amazon EC2 Auto Scaling"
        },
        {
          "id": "D",
          "text": "Amazon Route 53 with internal Application Load Balances"
        }
      ]
    },
    {
      "id": "182",
      "question": "A company is developing a real-time multiplier game that uses UDP for communications between client and servers in an Auto Scaling group Spikes in demand are anticipated during the day, so the game server platform must adapt accordingly. Developers want to store gamer scores and other non- relational data in a database solution that will scale without intervention. Which solution should a solution architect recommend?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon Route 53 for traffic distribution and Amazon Aurora Serverless for data storage."
        },
        {
          "id": "B",
          "text": "Use a Network Load Balancer for traffic distribution and Amazon DynamoDB on-demand for data storage."
        },
        {
          "id": "C",
          "text": "Use a Network Load Balancer for traffic distribution and amazon Aura Global for data storage."
        },
        {
          "id": "D",
          "text": "Use an Application Load Balancer for traffic distribution and Amazon DynamoDB global tables for data storage"
        }
      ]
    },
    {
      "id": "183",
      "question": "A company currently has 250 TB of backup files stored in Amazon S3 in a vendor's proprietary format. Using a Linux-based software application provided by the vendor, the company wants to retrieve files from Amazon S3, transform the files to an industry-standard format, and re-upload them to Amazon S3. The company wants to minimize the data transfer charges associated with this conversation. What should a solution architect do to accomplish this?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Install the conversion software as an Amazon S3 batch operation so the data is transformed without leaving Amazon S3."
        },
        {
          "id": "B",
          "text": "Install the conversion software onto an on-premises virtual machines. Perform the transformation and re-upload the files to Amazon S3 from the virtual machine."
        },
        {
          "id": "C",
          "text": "Use AWS Snowball Edge device to expert the data and install the conversion software onto the devices. Perform the data transformation and re- upload the files to Amazon S3 from the Snowball devices."
        },
        {
          "id": "D",
          "text": "Launch an Amazon EC2 instance in the same Region as Amazon S3 and install the conversion software onto the instance. Perform the transformation and re-upload the files to Amazon S3 from the EC2 instance."
        }
      ]
    },
    {
      "id": "184",
      "question": "A company has an Amazon EC2 instance running on a private subnet that needs to access a public websites to download patches and updates. The company does not want external websites to see the EC2 instance IP address or initiate connection to it. How can a solution architect achieve this objective?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create a site-to-site VPN connection between the private subnet and the network in which the public site is deployed"
        },
        {
          "id": "B",
          "text": "Create a NAT gateway in a public subnet Route outbound traffic from the private subnet through the NAI gateway"
        },
        {
          "id": "C",
          "text": "Create a network ACL for the private subnet where the EC2 instance deployed only allows access from the IP address range of the public website"
        },
        {
          "id": "D",
          "text": "Create a security group that only allows connections from the IP address range of the public website. Attach the security group to the EC2 instance."
        }
      ]
    },
    {
      "id": "185",
      "question": "A company has created an isolated backup of its environment in another Region. The application is running in warm standby mode and is fronted by an Application Load Balancer (ALB). The current failover process is manual and requires updating a DNS alias record to point to the secondary ALB in another Region. What should a solution architect do to automate the failover process?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Enable an ALB health check"
        },
        {
          "id": "B",
          "text": "Enable an Amazon Route 53 health check."
        },
        {
          "id": "C",
          "text": "Crate an CNAME record on Amazon Route 53 pointing to the ALB endpoint."
        },
        {
          "id": "D",
          "text": "Create conditional forwarding rules on Amazon Route 53 pointing to an internal BIND DNS server."
        }
      ]
    },
    {
      "id": "186",
      "question": "A company needs to share an Amazon S3 bucket with an external vendor. The bucket owner must be able to access all objects. Which action should be taken to share the S3 bucket?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Update the bucket to be a Requester Pays bucket"
        },
        {
          "id": "B",
          "text": "Update the bucket to enable cross-origin resource sharing (CPORS)"
        },
        {
          "id": "C",
          "text": "Create a bucket policy to require users to grant bucket-owner-full when uploading objects"
        },
        {
          "id": "D",
          "text": "Create an IAM policy to require users to grant bucket-owner-full control when uploading objects."
        }
      ]
    },
    {
      "id": "187",
      "question": "A company uses Amazon S3 as its object storage solution. The company has thousands of S3 it uses to store data. Some of the S3 bucket have data that is accessed less frequently than others. A solutions architect found that lifecycle policies are not consistently implemented or are implemented partially. resulting in data being stored in high-cost storage. Which solution will lower costs without compromising the availability of objects?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use S3 ACLs"
        },
        {
          "id": "B",
          "text": "Use Amazon Elastic Block Store EBS) automated snapshots"
        },
        {
          "id": "C",
          "text": "Use S3 inteligent-Tiering storage"
        },
        {
          "id": "D",
          "text": "Use S3 One Zone-infrequent Access (S3 One Zone-IA)."
        }
      ]
    },
    {
      "id": "188",
      "question": "A solution architect is performing a security review of a recently migrated workload. The workload is a web application that consists of amazon EC2 instances in an Auto Scaling group behind an Application Load balancer. The solution architect must improve the security posture and minimize the impact of a DDoS attack on resources. Which solution is MOST effective?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure an AWS WAF ACL with rate-based rules Create an Amazon CloudFront distribution that points to the Application Load Balancer. Enable the EAF ACL on the CloudFront distribution "
        },
        {
          "id": "B",
          "text": "Create a custom AWS Lambda function that adds identified attacks into a common vulnerability pool to capture a potential DDoS attack. use the identified information to modify a network ACL to block access. "
        },
        {
          "id": "C",
          "text": "Enable VPC Flow Logs and store then in Amazon S3. Create a custom AWS Lambda functions that parses the logs looking for a DDoS attack. Modify a network ACL to block identified source IP addresses. "
        },
        {
          "id": "D",
          "text": "Enable Amazon GuardDuty and , configure findings written 10 Amazon GloudWatch Create an event with Cloud Watch Events for DDoS alerts that triggers Amazon Simple Notification Service (Amazon SNS) Have Amzon SNS invoke a custom AWS lambda function that parses the logs looking for a DDoS attack Modify a network ACL to block identified source IP addresses "
        }
      ]
    },
    {
      "id": "189",
      "question": "A company has a custom application running on an Amazon EC2 instance that: - Reads a large amount of data from Amazon S3 - Performs a multi stage analysis - Writes the results to Amazon DynamoDB The application writes a significant number of large temporary files during the multi stage analysis The process performance depends on the temporary storage performance. What would be the fastest storage option for holding the temporary files?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Multiple Amazon S3 buckets with Transfer Acceleration for storage"
        },
        {
          "id": "B",
          "text": "Multiple Amazon EBS drives with Provisioned IOPS and EBS optimization"
        },
        {
          "id": "C",
          "text": "Multiple Amazon EFS volumes using the Network I lie System version 4.1 (NFSv4.1) protocol."
        },
        {
          "id": "D",
          "text": "Multiple instance store volumes with software RAID 0."
        }
      ]
    },
    {
      "id": "190",
      "question": "A solution architect must migrate a Windows internet information Services (IIS) web application to AWS. The application currently relies on a file share hosted in the user's on-premises network-attached storage (NAS). The solution architected has proposed migrating the IIS web servers. Which replacement to the on-promises filo share is MOST resilient and durable?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Migrate the file Share to Amazon RDS."
        },
        {
          "id": "B",
          "text": "Migrate the tile Share to AWS Storage Gateway"
        },
        {
          "id": "C",
          "text": "Migrate the file Share to Amazon FSx dor Windows File Server."
        },
        {
          "id": "D",
          "text": "Migrate the tile share to Amazon Elastic File System (Amazon EFS)"
        }
      ]
    },
    {
      "id": "191",
      "question": "An application running on an Amazon EC2 instance in VPC-A needs to access files in another EC2 instance in VPC-B. Both are in separate. AWS accounts. The network administrator needs to design a solution to enable secure access to EC2 instance in VOC-B from VPC- The connectivity should not have a single point of failure or bandwidth concerns. Which solution will meet these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Set up a VPC peering connection between VPC-A and VPC-B."
        },
        {
          "id": "B",
          "text": "Set up VPC gateway endpoints for the EC2 instance running in VPC-B."
        },
        {
          "id": "C",
          "text": "Attach a virtual private gateway to VPC-B and enable routing from VPC-A."
        },
        {
          "id": "D",
          "text": "Create a private virtual interface (VIF) for the EC2 instance running in VPC-B and add appropriate routes from VPC-B."
        }
      ]
    },
    {
      "id": "192",
      "question": "A company is seeing access requests by some suspicious IP addresses. The security team discovers the requests are from different IP addresses under the same CIDR range. What should a solutions architect recommend to the team?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Add a rule in the inbound table of the security to deny the traffic from that CIDR range."
        },
        {
          "id": "B",
          "text": "Add a rule in the outbound table of the security group to deny the traffic from that CIDR range."
        },
        {
          "id": "C",
          "text": "Add a deny rule in the inbound table of the network ACL with a lower number than other rules."
        },
        {
          "id": "D",
          "text": "Add a deny rule in the outbound table of the network ACL with a lower rule number than other rules."
        }
      ]
    },
    {
      "id": "193",
      "question": "A company is using a VPC peering strategy to connect its VPCs in a single Region to allow for cross- communication. A recent increase in account creations and VPCs has made it difficult to maintain the VPC peering strategy, and the company expects to grow to hundreds of VPCs. There are also new requests to create site-to-site VPNs with some of the VPCs. A solutions architect has been tasked with creating a centrally networking setup for multiple accounts, VPNS, and VPNs. Which networking solution meets these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure shared VPCs and VPNs and share to each other"
        },
        {
          "id": "B",
          "text": "Configure a hub-and-spoke and route all traffic through VPC peering."
        },
        {
          "id": "C",
          "text": "Configure an AWS Direct Connect between all VPCs and VPNs."
        },
        {
          "id": "D",
          "text": "Configure a transit gateway with AWS Transit Gateway and connected all VPCs and VPNs."
        }
      ]
    },
    {
      "id": "194",
      "question": "A monolithic application was recently migrated to AWS and is now running on a single Amazon EC2 instance. Due to application limitations, it is not possible to use automatic scaling to scale out the application. The chief technology officer (CTO) wants an automated solution to restore the EC2 instance in the unlikely event the underlying hardware fails. What would allow for automatic recovery of the EC2 instance as quickly as possible?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure an Amazon CloudWatch alarm that triggers the recovery of the EC2 instance if it becomes impaired."
        },
        {
          "id": "B",
          "text": "Configure an Amazon CloudWatch alarm to trigger an SNS message that alerts the CTO when the EC2 instance is impaired."
        },
        {
          "id": "C",
          "text": "Configure AWS CloudTrail to monitor the health of the EC2 instance, and if it becomes impaired, triggered instance recovery."
        },
        {
          "id": "D",
          "text": "Configure an Amazon EventBridge event to trigger an AWS Lambda function once an hour that checks the health of the EC2 instance and triggers instance recovery if the EC2 instance is unhealthy."
        }
      ]
    },
    {
      "id": "195",
      "question": "A company has created a VPC with multiple private subnets in multiple Availability Zones (AZs) and one public subnet in one of the AZs. The public subnet is used to launch a NAT gateway. There are instance in the private subnet that use a NAT gateway to connect to the internet. In case is used of an AZ failure, the company wants to ensure that the instance are not all experiencing internet connectivity issues and that there is a backup plan ready. Which solution should a solutions architect recommend that is MOST highly available?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create a new public subnet with a NAT gateway in the same AZ Distribute the traffic between the two NAT gateways"
        },
        {
          "id": "B",
          "text": "Create an Amazon EC2 NAT instance in a now public subnet Distribute the traffic between the NAT gateway and the NAT instance"
        },
        {
          "id": "C",
          "text": "Create public subnets In each f\\Z and launch a NAT gateway in each subnet Configure the traffic from the private subnets In each A2 to the respective NAT gateway"
        },
        {
          "id": "D",
          "text": "Create an Amazon EC2 NAT instance in the same public subnet Replace the NAT gateway with the NAT instance and associate the instance with an Auto Scaling group with an appropriate scaling policy."
        }
      ]
    },
    {
      "id": "196",
      "question": "A company has multiple AWS accounts, for various departments. One of the departments wants to share an Amazon S3 bucket with all other department. Which solution will require the LEAST amount of effort-?",
      "image": "",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Enable cross-account S3 replication for the bucket"
        },
        {
          "id": "B",
          "text": "Create a pre signed URL tor the bucket and share it with other departments"
        },
        {
          "id": "C",
          "text": "Set the S3 bucket policy to allow cross-account access to other departments"
        },
        {
          "id": "D",
          "text": "Create IAM users for each of the departments and configure a read-only IAM policy"
        }
      ]
    },
    {
      "id": "197",
      "question": "A company collects temperature, humidity, and atmospheric pressure data in cities across multiple continents. The average volume of data collected per site each day is 500 GB. Each site has a high-speed internet connection. The company's weather forecasting applications are based in a single Region and analyze the data daily. What is the FASTEST way to aggregate data for all of these global sites?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Enable Amazon S3 Transfer Acceleration on the destination bucket. Use multipart uploads to directly upload site data to the destination bucket."
        },
        {
          "id": "B",
          "text": "Upload site data to an Amazon S3 bucket in the closest AWS Region. Use S3 cross-Region replication to copy objects to the destination bucket."
        },
        {
          "id": "C",
          "text": "Upload site data to an Amazon S3 bucket in the closest AWS Region. Use S3 cross-Region replication to copy objects to the destination bucket."
        },
        {
          "id": "D",
          "text": "Upload the data to an Amazon EC2 instance in the closes Region. Store the data in an Amazon EBS volume. One a day take an EBS snapshot and copy it to the centralize Region. Restore the EBS volume in the centralized Region and run an analysis on the data daily."
        }
      ]
    },
    {
      "id": "198",
      "question": "A company has implemented one of its microservices on AWS Lambda that accesses an Amazon DynamoDB table named Books. A solutions architect is design an IAM policy to be attached to the Lambda function's IAM role, giving it access to put, update, and delete items in the Books table. the IAM policy must prevent function from performing any other actions on the Books table or any other. Which IAM policy would fulfill these needs and provide the LEAST privileged access?",
      "image": "img/question-198.png",
      "explaination": "",
      "correct": [
        "C"
      ],
      "choices": [
        {
          "id": "A",
          "text": "A"
        },
        {
          "id": "B",
          "text": "B"
        },
        {
          "id": "C",
          "text": "C"
        },
        {
          "id": "D",
          "text": "D"
        }
      ]
    },
    {
      "id": "199",
      "question": "Application developers have noticed that a production application is very slow when business reporting users run large production reports against the Amazon RDS instance backing the application. the CPU and memory utilization metrics for the RDS instance-d not exceed 60% while the reporting queries are running. The business reporting users must be able to generate reports without affecting the applications performance. Which action will accomplish this?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Increase the size of the RDS instance"
        },
        {
          "id": "B",
          "text": "Create a read replica and connect the application to it."
        },
        {
          "id": "C",
          "text": "Enable multiple Availability Zones on the RDS instance"
        },
        {
          "id": "D",
          "text": "Create a read replication and connect the business reports to it."
        }
      ]
    },
    {
      "id": "200",
      "question": "A company's packaged application dynamically creates and returns single-use text files in response to user requests. The company is using Amazon CloudFront for distribution, but wants to future reduce data transfer costs. The company modify the application's source code. What should a solution architect do to reduce costs?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Lambda adage to compress the files as they are sent to users."
        },
        {
          "id": "B",
          "text": "Enable Amazon S3 Transfer Acceleration to reduce the response times."
        },
        {
          "id": "C",
          "text": "Enable caching on the CloudFront distribution to store generated files at the edge."
        },
        {
          "id": "D",
          "text": "Use Amazon S3 multipart uploads to move the files to Amazon S3 before returning them to users."
        }
      ]
    },
    {
      "id": "201",
      "question": "A public-facing web application queries a database hosted on a Amazon EC2 instance in a private subnet. A large number of queries involve multiple table joins, and the application performance has been degrading due to an increase in complex queries. The application team will be performing updates to improve performance. What should a solutions architect recommend to the application team? (Select TWO.)",
      "image": "",
      "explaination": "",
      "correct": [
        "C",
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Cache query data in Amazon SQS"
        },
        {
          "id": "B",
          "text": "Create a read replica to offload queries"
        },
        {
          "id": "C",
          "text": "Migrate the database to Amazon Athena"
        },
        {
          "id": "D",
          "text": "Implement Amazon DynamoDB Accelerator to cache data."
        },
        {
          "id": "E",
          "text": "Migrate the database to Amazon RDS"
        }
      ]
    },
    {
      "id": "202",
      "question": "A company has a Microsoft Windows-based application that must be migrated to AWS. This application requires the use of a shared Windows file system attached to multiple Amazon EC2 Windows instances. What should a solution architect do to accomplish this?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure a volume using Amazon EFS Mount the EPS volume to each Windows Instance"
        },
        {
          "id": "B",
          "text": "Configure AWS Storage Gateway in Volume Gateway mode Mount the volume to each Windows instance"
        },
        {
          "id": "C",
          "text": "Configure Amazon FSx for Windows File Server Mount the Amazon FSx volume to each Windows Instance"
        },
        {
          "id": "D",
          "text": "Configure an Amazon EBS volume with the required size Attach each EC2 instance to the volume Mount the file system within the volume to each Windows instance"
        }
      ]
    },
    {
      "id": "203",
      "question": "A company recently expanded globally and wants to make its application accessible to users in those geographic locations. The application is deploying on Amazon EC2 instances behind an Application Load balancer in an Auto Scaling group. The company needs the ability shift traffic from resources in one region to another. What should a solutions architect recommend?",
      "image": "",
      "explaination": "",
      "correct": [
        "B"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Configure an Amazon Route 53 latency routing policy"
        },
        {
          "id": "B",
          "text": "Configure an Amazon Route 53 geolocation routing policy"
        },
        {
          "id": "C",
          "text": "Configure an Amazon Route 53 geoproximity fouling policy."
        },
        {
          "id": "D",
          "text": "Configure an Amazon Route 53 multivalue answer routing policy"
        }
      ]
    },
    {
      "id": "204",
      "question": "A company has several business systems that require access to data stored in a file share. the business systems will access the file share using the Server Message Block (SMB) protocol. The file share solution should be accessible from both of the company's legacy on-premises environment and with AWS. Which services mod the business requirements? (Select TWO.)",
      "image": "",
      "explaination": "",
      "correct": [
        "B",
        "E"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Amazon EBS"
        },
        {
          "id": "B",
          "text": "Amazon EFS"
        },
        {
          "id": "C",
          "text": "Amazon FSx for Windows"
        },
        {
          "id": "D",
          "text": "Amazon S3"
        },
        {
          "id": "E",
          "text": "AWS Storage Gateway file gateway"
        }
      ]
    },
    {
      "id": "205",
      "question": "A company's operations teams has an existing Amazon S3 bucket configured to notify an Amazon SQS queue when new object are created within the bucket. The development team also wants to receive events when new objects are created. The existing operations team workflow must remain intact. Which solution would satisfy these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Create another SQS queue Update the S3 events in bucket to also update the new queue when a new object is created."
        },
        {
          "id": "B",
          "text": "Create a new SQS queue that only allows Amazon S3 to access the queue, Update Amazon S3 update this queue when a new object is created"
        },
        {
          "id": "C",
          "text": "Create an Amazon SNS topic and SQS queue for the Update. Update the bucket to send events to the new topic. Updates both queues to poll Amazon SNS."
        },
        {
          "id": "D",
          "text": "Create an Amazon SNS topic and SQS queue for the bucket updates. Update the bucket to send events to the new topic Add subscription for both queue in the topic."
        }
      ]
    },
    {
      "id": "206",
      "question": "A company wants to deploy a shared file system for its .NET application servers and Microsoft SQL Server database running on Amazon EC2 instance with Windows Server 2016. The solution must be able to be integrated in to the corporate Active Directory domain, be highly durable, be managed by AWS, and provided levels of throuput and IOPS. Which solution meets these requirements?",
      "image": "",
      "explaination": "",
      "correct": [
        "D"
      ],
      "choices": [
        {
          "id": "A",
          "text": "Use Amazon FSx for Windows File Server"
        },
        {
          "id": "B",
          "text": "Use Amazon Elastic File System (Amazon EFS)"
        },
        {
          "id": "C",
          "text": "Use AWS Storage Gateway in file gateway mode."
        },
        {
          "id": "D",
          "text": "Deploy a Windows file server on two On Demand instances across two Availability Zones."
        }
      ]
    },
    {
      "id": "207",
      "question": "A company is designing a new service that will run on Amazon EC2 instance behind an Elastic Load Balancer. However, many of the web service clients can only reach IP addresses whitelisted on their firewalls. What should a solution architect recommend to meet the clients' needs? What should a solution architect recommend to meet the clients' needs?",
      "image": "",
      "explaination": "",
      "correct": [
        "A"
      ],
      "choices": [
        {
          "id": "A",
          "text": "A Network Load Balancer with an associated Elastic IP address."
        },
        {
          "id": "B",
          "text": "An Application Load Balancer with an a associated Elastic IP address"
        },
        {
          "id": "C",
          "text": "An A record in an Amazon Route 53 hosted zone pointing to an Elastic IP address"
        },
        {
          "id": "D",
          "text": "An EC2 instance with a public IP address running as a proxy in front of the load balancer"
        }
      ]
    }
  ]}
;

var QuizCode = Quiz["QuizCode"];
var QuizTitle = Quiz["QuizTitle"];
var QuizDescription = Quiz["QuizDescription"];
var QuizQuestions = Quiz['QuizQuestions'];

</script>
<!-- JS quiz variables - end -->

<!-- JS quiz functions - start -->
<script>

var 
    QuizCurrentQuestions = 0 ,
    QuizScore = [] ,
    QuizScoreSum = 0 ,
    QuizScorePercent = 0 ,
	  QuizSubmit = true ,
    QuizPicked ;

jQuery(document).ready(function ($) {

    function htmlEncode(value) {
        return $(document.createElement('div')).text(value).html();
    }

    function setPager(){
        $("#QuizPagerSelect").val(QuizCurrentQuestions+1);
    }

    function getExplaination(){
      $("#QuizExplainationBlock").empty();
      if (QuizQuestions[QuizCurrentQuestions].hasOwnProperty('explaination') && QuizQuestions[QuizCurrentQuestions]['explaination'] != "") {
        $(document.createElement('div')).addClass('col explaination').attr('id', 'QuizExplainationCol').appendTo('#QuizExplainationBlock');
        $(document.createElement('h2')).text('Explaination').appendTo('#QuizExplainationCol');
        $(document.createElement('p')).text(QuizQuestions[QuizCurrentQuestions]['explaination']).appendTo('#QuizExplainationCol');
      }
    }

    function setQuestionImage(){
      $("#QuizImageBlock").empty();
      if (QuizQuestions[QuizCurrentQuestions].hasOwnProperty('image') && QuizQuestions[QuizCurrentQuestions]['image'] != "") {
          $(document.createElement('img')).addClass('question-image').attr('id', 'QuizQuestionImage').attr('src', QuizQuestions[QuizCurrentQuestions]['image']).attr('alt', htmlEncode(QuizQuestions[QuizCurrentQuestions]['question'])).appendTo('#QuizImageBlock');
      }
    }

    function checkAnswer(choices) {
        var QuizCorrectAnswersCount = 0
        for (var i = 0; i < choices.length; i++) {
            $('#AnswerBlock'+choices[i].id).removeClass('btn-success');
            $('#AnswerBlock'+choices[i].id).removeClass('btn-outline-danger');
        }

        // mark checked answer
        if (!!localStorage.getItem('SelectedAnswerStore'+QuizCurrentQuestions)){
            var SelectedAnswerStoreArray = localStorage.getItem('SelectedAnswerStore'+QuizCurrentQuestions).split(',');
            for (var SelectedAnswer of SelectedAnswerStoreArray) {
                if(!QuizQuestions[QuizCurrentQuestions]['correct'].includes(SelectedAnswer)){
                    $('#AnswerInput'+SelectedAnswer).attr('checked', 'checked');
                    $('#AnswerBlock'+SelectedAnswer).addClass('btn-outline-danger');
                } else {
                    $('#AnswerBlock'+SelectedAnswer).addClass('btn-success');
                    QuizCorrectAnswersCount++;
                }
            }
        }

        // calculate score
        if ( QuizCorrectAnswersCount == QuizQuestions[QuizCurrentQuestions]['correct'].length ){
            QuizScore[QuizCurrentQuestions] = 1;
            // display explaination
            getExplaination();

        } else if ( QuizCorrectAnswersCount < QuizQuestions[QuizCurrentQuestions]['correct'].length ){
            QuizScore[QuizCurrentQuestions] = 0;
        } else {
            QuizScore[QuizCurrentQuestions] = 0;
        }
        QuizScoreSum = QuizScore.reduce(function(a, b){ return a + b; }, 0);
        QuizScorePercent = (QuizScoreSum/QuizQuestions.length)*100
    }
    
    function getSelectedAnswers(){
        var SelectedAnswers = $("input[name='QuizAnswer"+QuizCurrentQuestions+"']:checked")
        if (!!SelectedAnswers){
            var SelectedAnswersArray = []
            for (var SelectedAnswer of SelectedAnswers) {
                SelectedAnswersArray.push(SelectedAnswer.value);
            }
            localStorage.setItem('SelectedAnswerStore'+QuizCurrentQuestions, SelectedAnswersArray.join(','));
        }
    }

	  function addChoices(choices) {
      var CorrectAnswersCount = QuizQuestions[QuizCurrentQuestions]['correct'].length
      
      if (typeof choices !== "undefined" && $.type(choices) == "array") {
        $('#ChoiceBlock').empty();
          if( CorrectAnswersCount > 1 ){
              for (var i = 0; i < choices.length; i++) {
                  $(document.createElement('div')).addClass('custom-control').addClass('custom-checkbox').attr('id', 'AnswerBlock' + choices[i].id).appendTo('#ChoiceBlock');
                  $(document.createElement('input')).addClass('custom-control-input').attr('name', 'QuizAnswer'+QuizCurrentQuestions).attr('type', 'checkbox').attr('id', 'AnswerInput' + choices[i].id).attr('value', choices[i].id).appendTo('#AnswerBlock' + choices[i].id);
                  $(document.createElement('label')).addClass('custom-control-label').attr('id', 'AnswerLabel' + choices[i].id).attr('for', 'AnswerInput' + choices[i].id).appendTo('#AnswerBlock' + choices[i].id);
                  $(document.createElement('b')).text('[ ' + choices[i].id + ' ]  ').appendTo('#AnswerLabel' + choices[i].id);
                  $(document.createElement('span')).text(choices[i].text).appendTo('#AnswerLabel' + choices[i].id);
              }
          } else {
              for (var i = 0; i < choices.length; i++) {
                  $(document.createElement('div')).addClass('custom-control').addClass('custom-radio').attr('id', 'AnswerBlock' + choices[i].id).appendTo('#ChoiceBlock');
                  $(document.createElement('input')).addClass('custom-control-input').attr('name', 'QuizAnswer'+QuizCurrentQuestions).attr('type', 'radio').attr('required', '').attr('id', 'AnswerInput' + choices[i].id).attr('value', choices[i].id).appendTo('#AnswerBlock' + choices[i].id);
                  $(document.createElement('label')).addClass('custom-control-label').attr('id', 'AnswerLabel' + choices[i].id).attr('for', 'AnswerInput' + choices[i].id).appendTo('#AnswerBlock' + choices[i].id);
                  $(document.createElement('b')).text('[ ' + choices[i].id + ' ]  ').appendTo('#AnswerLabel' + choices[i].id);
                  $(document.createElement('span')).text(choices[i].text).appendTo('#AnswerLabel' + choices[i].id);
              }
          }

          if (!!localStorage.getItem('SelectedAnswerStore'+QuizCurrentQuestions)){
            var SelectedAnswerStoreArray = localStorage.getItem('SelectedAnswerStore'+QuizCurrentQuestions).split(',');
            for (var SelectedAnswer of SelectedAnswerStoreArray) {
                $('#AnswerInput'+SelectedAnswer).attr('checked', 'checked');
            }
          }
        }
      }

    function setButtons(choices) {
        $(document.createElement('div')).addClass('col').attr('id', 'ButtonCol1').appendTo('#QuizButton');
        $(document.createElement('div')).addClass('col').attr('id', 'ButtonCol2').appendTo('#QuizButton');
        $(document.createElement('div')).addClass('col').attr('id', 'ButtonCol3').appendTo('#QuizButton');

        switch (QuizCurrentQuestions) {
            case QuizQuestions.length-1:
                $(document.createElement('button')).addClass('btn btn-block').addClass('btn-secondary').attr('id', 'ButtonPrev').text('Prev').appendTo('#ButtonCol1');
                $(document.createElement('button')).addClass('btn btn-block').addClass('btn-outline-secondary').attr('id', 'ButtonCheck').text('Check').appendTo('#ButtonCol2');
                $(document.createElement('button')).addClass('btn btn-block').addClass('btn-success').attr('id', 'ButtonFinish').attr('type', 'submit').text('Finish').appendTo('#ButtonCol3');
                break;
            case 0:
                $(document.createElement('button')).addClass('btn btn-block').addClass('btn-light').attr('id', 'ButtonPrev').text('Prev').appendTo('#ButtonCol1');
                $(document.createElement('button')).addClass('btn btn-block').addClass('btn-outline-secondary').attr('id', 'ButtonCheck').text('Check').appendTo('#ButtonCol2');
                $(document.createElement('button')).addClass('btn btn-block').addClass('btn-primary').attr('id', 'ButtonNext').attr('type', 'submit').text('Next').appendTo('#ButtonCol3');
                $('#ButtonPrev').attr('disabled', 'disabled');
                break;
            default:
                $(document.createElement('button')).addClass('btn btn-block').addClass('btn-secondary').attr('id', 'ButtonPrev').text('Prev').appendTo('#ButtonCol1');
                $(document.createElement('button')).addClass('btn btn-block').addClass('btn-outline-secondary').attr('id', 'ButtonCheck').text('Check').appendTo('#ButtonCol2');
                $(document.createElement('button')).addClass('btn btn-block').addClass('btn-primary').attr('id', 'ButtonNext').attr('type', 'submit').text('Next').appendTo('#ButtonCol3');
        }

        $('#ButtonNext').on('click', function () {
            getSelectedAnswers();
            checkAnswer(QuizQuestions[QuizCurrentQuestions]['choices']);
            QuizCurrentQuestions++; 
            getQuestion(); 
        });
        $('#ButtonPrev').on('click', function () {
            getSelectedAnswers();
            checkAnswer(QuizQuestions[QuizCurrentQuestions]['choices']);
            QuizCurrentQuestions--;
            getQuestion();
        });
        $('#ButtonCheck').on('click', function () {
            getSelectedAnswers();
            checkAnswer(QuizQuestions[QuizCurrentQuestions]['choices']);
        });
        $('#ButtonFinish').on('click', function () {
            getSelectedAnswers();
            checkAnswer(QuizQuestions[QuizCurrentQuestions]['choices']);
            getResult();
        });
    }

    function getResult() {
        $('#QuizExplanation').empty();
        $('#QuizButton').empty();
        $('#QuizQuestion').empty();
        $('#QuizPager').empty();
        $('#QuizContent').empty();
        $(document.createElement('hr')).addClass('mb-4').appendTo('#QuizContent');
        if ( QuizScorePercent > 80 ) {
            $(document.createElement('h2')).addClass('text-center text-success').text('Congratulations!').appendTo('#QuizContent');
            $(document.createElement('h4')).addClass('text-center text-secondary').text('You scored '+QuizScorePercent.toFixed(2)+'%').appendTo('#QuizContent');
        } else {
            $(document.createElement('h2')).addClass('text-center text-danger').text('Try Again').appendTo('#QuizContent');
            $(document.createElement('h4')).addClass('text-center text-secondary').text('You scored '+QuizScorePercent.toFixed(2)+'%').appendTo('#QuizContent');
        }
        $(document.createElement('br')).appendTo('#QuizContent');
        $(document.createElement('div')).addClass('row').attr('id', 'QuizStartRow1').appendTo('#QuizContent');
        $(document.createElement('div')).addClass('col').attr('id', 'QuizStartCol11').appendTo('#QuizStartRow1');
        $(document.createElement('div')).addClass('col').attr('id', 'QuizStartCol12').appendTo('#QuizStartRow1');
        $(document.createElement('div')).addClass('col').attr('id', 'QuizStartCol13').appendTo('#QuizStartRow1');
        $(document.createElement('button')).addClass('btn btn-block btn-outline-secondary').attr('id', 'ButtonRevisit').text('Revisit').appendTo('#QuizStartCol12');
        $('#ButtonRevisit').on('click', function () {
            startQuiz(QuizCurrentQuestions);
        });
        $(document.createElement('button')).addClass('btn btn-block btn-primary').attr('id', 'ButtonStart').text('Start Over').appendTo('#QuizStartCol12');
        $('#ButtonStart').on('click', function () {
            localStorage.clear();
            window.location.reload();
        });
        $(document.createElement('hr')).addClass('mb-4').appendTo('#QuizContent');
    }

    function setupPager(){
      $(document.createElement('div')).addClass('row').attr('id', 'QuizPagerRow').appendTo('#QuizContent');
      $(document.createElement('div')).addClass('col-2 pager-left').attr('id', 'QuizPagerColLeft').appendTo('#QuizPagerRow');
      $(document.createElement('div')).addClass('col pager-right').attr('id', 'QuizPagerColRight').appendTo('#QuizPagerRow');

      $(document.createElement('button')).addClass('btn btn-outline-secondary btn-xs pager-left-button').attr('id', 'ButtonScore').text('Score').appendTo('#QuizPagerColLeft');
      
      $(document.createElement('div')).addClass('pager-right').attr('id', 'QuizPager').text('Question ').appendTo('#QuizPagerColRight');
      $(document.createElement('select')).attr('name', 'QuizPagerSelect').attr('id', 'QuizPagerSelect').appendTo('#QuizPager');
      for (i = 1; i < (QuizQuestions.length+1); i++) {
        $("#QuizPagerSelect").append($("<option>").attr('value',i).text(i));
      }
      $(document.createElement('span')).addClass('pager-right').attr('id', 'QuizPagerText').text(' of ' + QuizQuestions.length).appendTo('#QuizPager');
      $(document.createElement('button')).addClass('btn btn-outline-secondary btn-xs pager-right-button').attr('id', 'ButtonJump').text('Go').appendTo('#QuizPager');
      $('#ButtonJump').on('click', function () {
          getSelectedAnswers();
          checkAnswer(QuizQuestions[QuizCurrentQuestions]['choices']);
          QuizCurrentQuestions = Number($("#QuizPagerSelect").val())-1;
          getQuestion(); 
      });
      $('#ButtonScore').on('click', function () {
            getSelectedAnswers();
            checkAnswer(QuizQuestions[QuizCurrentQuestions]['choices']);
            getResult();
      });
    }

    function getQuestion() {
        $('#QuizExplainationBlock').empty();
        $('#QuizButton').empty();
        setPager();
        $('#QuizQuestion').text(QuizQuestions[QuizCurrentQuestions]['question']);
        //add image if present
        setQuestionImage();
        addChoices(QuizQuestions[QuizCurrentQuestions]['choices']);
        setButtons();
    }

    function startQuiz(CurrentQuestion) {
      $('#QuizHeader').empty();
      $('#QuizContent').empty();

      if (typeof QuizTitle !== "undefined" && $.type(QuizTitle) === "string") {
        $(document.createElement('h3')).text(QuizTitle).appendTo('#QuizHeader');
        $('#PageTitle').text(QuizTitle);
      }
      if (typeof QuizDescription !== "undefined" && $.type(QuizDescription) === "string") {
        $(document.createElement('p')).addClass('lead').text(QuizDescription).appendTo('#QuizHeader');
      }
      if ( typeof CurrentQuestion !== "undefined" ){
          QuizCurrentQuestions = CurrentQuestion
      }

      //add pager and questions
      if (typeof QuizQuestions !== "undefined" && $.type(QuizQuestions) === "array") {
        //set pager
        setupPager();
        setPager();

        // add line
        $(document.createElement('hr')).addClass('mb-4').appendTo('#QuizContent');

        //add first question
        $(document.createElement('p')).attr('id', 'QuizQuestion').text(QuizQuestions[0]['question']).appendTo('#QuizContent');

        //add image block
        $(document.createElement('div')).attr('id', 'QuizImageBlock').appendTo('#QuizContent');
        setQuestionImage();

        //choices block
        $(document.createElement('div')).attr('id', 'ChoiceBlock').appendTo('#QuizContent');
        addChoices(QuizQuestions[QuizCurrentQuestions]['choices']);
        
        //add explaination block
        $(document.createElement('div')).addClass('row').attr('id', 'QuizExplainationBlock').appendTo('#QuizContent');

        // button blocks
        $(document.createElement('hr')).addClass('mb-4').appendTo('#QuizContent');
        $(document.createElement('div')).addClass('row').attr('id', 'QuizButton').appendTo('#QuizContent');
        setButtons();
      }
	  }

    function initQuiz(Quiz){
        if (typeof QuizTitle !== "undefined" && $.type(QuizTitle) === "string") {
            $(document.createElement('h2')).text(QuizTitle).appendTo('#QuizStartBlock');
            $('#PageTitle').text(QuizTitle);
        }
        if (typeof QuizDescription !== "undefined" && $.type(QuizDescription) === "string") {
            $(document.createElement('h4')).text(QuizDescription).appendTo('#QuizStartBlock');
        }
        
        $(document.createElement('hr')).addClass('mb-4').appendTo('#QuizStartBlock');
        $(document.createElement('p')).text('This set contains '+QuizQuestions.length+' questions.').appendTo('#QuizStartBlock');
        /*
        $(document.createElement('div')).addClass('row').attr('id', 'QuizStartRow1').appendTo('#QuizStartBlock');
        $(document.createElement('div')).addClass('col').attr('id', 'QuizStartCol11').appendTo('#QuizStartRow1');
        $(document.createElement('div')).addClass('col').attr('id', 'QuizStartCol12').appendTo('#QuizStartRow1');
        $(document.createElement('div')).addClass('col').attr('id', 'QuizStartCol13').appendTo('#QuizStartRow1');
        $(document.createElement('button')).addClass('btn btn-block').addClass('btn-primary').attr('id', 'ButtonStart').text('Start').appendTo('#QuizStartCol12');
        */
        $(document.createElement('button')).addClass('btn mr-2 btn-lg').addClass('btn-primary').attr('id', 'ButtonStart').text('Start').appendTo('#QuizStartBlock');
        $('#ButtonStart').on('click', function () {
          startQuiz();
        });
    }

    initQuiz();
});



</script>
<!-- JS quiz functions - end -->

</head>

<body class="bg-light">
    <div class="container">
        <div id="QuizHeader" class="py-4 text-center"></div>
            <div class="row">
                <div id="QuizContent" class="col">
                  <div class="jumbotron" id="QuizStartBlock">
                </div>
            </div>
    </div>
    <div class="footer py-4 text-center">
        <p class="text-secondary">Â© 2020 - faizmazlan.github.io</p>
    </div>

</body>
</html>
